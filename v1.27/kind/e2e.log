  I0417 06:33:10.809886      30 e2e.go:117] Starting e2e run "2f2b4a38-48a4-49d0-90b5-0f5f94ee4d80" on Ginkgo node 1
  Apr 17 06:33:10.827: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1681713190 - will randomize all specs

Will run 378 of 7207 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:148
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Apr 17 06:33:10.923: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 06:33:10.923: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Apr 17 06:33:10.940: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Apr 17 06:33:10.942: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kindnet' (0 seconds elapsed)
  Apr 17 06:33:10.942: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  Apr 17 06:33:10.942: INFO: e2e test version: v1.27.0
  Apr 17 06:33:10.942: INFO: kube-apiserver version: v1.27.0
  Apr 17 06:33:10.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 06:33:10.944: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.022 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should patch a pod status [Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 04/17/23 06:33:11.084
  Apr 17 06:33:11.084: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pods @ 04/17/23 06:33:11.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:33:11.089
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:33:11.09
  STEP: Create a pod @ 04/17/23 06:33:11.091
  STEP: patching /status @ 04/17/23 06:33:19.105
  Apr 17 06:33:19.108: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Apr 17 06:33:19.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1248" for this suite. @ 04/17/23 06:33:19.11
â€¢ [8.028 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]
test/e2e/kubectl/kubectl.go:1735
  STEP: Creating a kubernetes client @ 04/17/23 06:33:19.111
  Apr 17 06:33:19.111: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 06:33:19.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:33:19.116
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:33:19.117
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/17/23 06:33:19.118
  Apr 17 06:33:19.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2870 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 17 06:33:19.166: INFO: stderr: ""
  Apr 17 06:33:19.166: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 04/17/23 06:33:19.166
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/17/23 06:33:29.22
  Apr 17 06:33:29.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2870 get pod e2e-test-httpd-pod -o json'
  Apr 17 06:33:29.260: INFO: stderr: ""
  Apr 17 06:33:29.260: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-04-17T06:33:19Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2870\",\n        \"resourceVersion\": \"40197\",\n        \"uid\": \"fab8e6af-1656-4241-9ca5-52cb71cda6ed\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-548kp\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"c3-worker2\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-548kp\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-17T06:33:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-17T06:33:25Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-17T06:33:25Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-17T06:33:19Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://33f640f62b48e828573eb87c9f0bfdb22e25f7fa9b31cfa6ca28170033c5e86a\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-17T06:33:25Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.18.0.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.2.5\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.2.5\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-17T06:33:19Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 04/17/23 06:33:29.26
  Apr 17 06:33:29.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2870 replace -f -'
  Apr 17 06:33:29.427: INFO: stderr: ""
  Apr 17 06:33:29.427: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-4 @ 04/17/23 06:33:29.427
  Apr 17 06:33:29.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2870 delete pods e2e-test-httpd-pod'
  Apr 17 06:33:34.391: INFO: stderr: ""
  Apr 17 06:33:34.391: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 17 06:33:34.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2870" for this suite. @ 04/17/23 06:33:34.393
â€¢ [15.283 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 04/17/23 06:33:34.395
  Apr 17 06:33:34.395: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pods @ 04/17/23 06:33:34.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:33:34.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:33:34.401
  STEP: creating the pod @ 04/17/23 06:33:34.402
  STEP: submitting the pod to kubernetes @ 04/17/23 06:33:34.402
  STEP: verifying QOS class is set on the pod @ 04/17/23 06:33:34.405
  Apr 17 06:33:34.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6087" for this suite. @ 04/17/23 06:33:34.407
â€¢ [0.013 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
test/e2e/network/endpointslice.go:104
  STEP: Creating a kubernetes client @ 04/17/23 06:33:34.409
  Apr 17 06:33:34.409: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename endpointslice @ 04/17/23 06:33:34.409
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:33:34.413
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:33:34.413
  Apr 17 06:33:38.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-7414" for this suite. @ 04/17/23 06:33:38.429
â€¢ [4.022 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 04/17/23 06:33:38.431
  Apr 17 06:33:38.431: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/17/23 06:33:38.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:33:38.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:33:38.436
  Apr 17 06:33:44.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Cleaning up the secret @ 04/17/23 06:33:44.451
  STEP: Cleaning up the configmap @ 04/17/23 06:33:44.453
  STEP: Cleaning up the pod @ 04/17/23 06:33:44.454
  STEP: Destroying namespace "emptydir-wrapper-5184" for this suite. @ 04/17/23 06:33:44.457
â€¢ [6.028 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]
test/e2e/kubectl/kubectl.go:1775
  STEP: Creating a kubernetes client @ 04/17/23 06:33:44.459
  Apr 17 06:33:44.459: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 06:33:44.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:33:44.463
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:33:44.464
  STEP: starting the proxy server @ 04/17/23 06:33:44.465
  Apr 17 06:33:44.465: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-9926 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 04/17/23 06:33:44.496
  Apr 17 06:33:44.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9926" for this suite. @ 04/17/23 06:33:44.508
â€¢ [0.052 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 04/17/23 06:33:44.511
  Apr 17 06:33:44.511: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename crd-watch @ 04/17/23 06:33:44.512
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:33:44.515
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:33:44.516
  Apr 17 06:33:44.518: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Creating first CR  @ 04/17/23 06:33:47.037
  Apr 17 06:33:47.039: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-17T06:33:47Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-17T06:33:47Z]] name:name1 resourceVersion:40325 uid:05c797ed-c19c-4c79-9a95-30d92b070144] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Creating second CR @ 04/17/23 06:33:57.04
  Apr 17 06:33:57.043: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-17T06:33:57Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-17T06:33:57Z]] name:name2 resourceVersion:40353 uid:9fe7ca60-6002-42b9-84fd-b0183c8cdfe2] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying first CR @ 04/17/23 06:34:07.044
  Apr 17 06:34:07.047: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-17T06:33:47Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-17T06:34:07Z]] name:name1 resourceVersion:40370 uid:05c797ed-c19c-4c79-9a95-30d92b070144] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying second CR @ 04/17/23 06:34:17.048
  Apr 17 06:34:17.051: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-17T06:33:57Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-17T06:34:17Z]] name:name2 resourceVersion:40388 uid:9fe7ca60-6002-42b9-84fd-b0183c8cdfe2] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting first CR @ 04/17/23 06:34:27.052
  Apr 17 06:34:27.055: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-17T06:33:47Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-17T06:34:07Z]] name:name1 resourceVersion:40404 uid:05c797ed-c19c-4c79-9a95-30d92b070144] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting second CR @ 04/17/23 06:34:37.056
  Apr 17 06:34:37.060: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-17T06:33:57Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-17T06:34:17Z]] name:name2 resourceVersion:40420 uid:9fe7ca60-6002-42b9-84fd-b0183c8cdfe2] num:map[num1:9223372036854775807 num2:1000000]]}
  Apr 17 06:34:47.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-6005" for this suite. @ 04/17/23 06:34:47.567
â€¢ [63.057 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]
test/e2e/apps/replica_set.go:131
  STEP: Creating a kubernetes client @ 04/17/23 06:34:47.569
  Apr 17 06:34:47.569: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename replicaset @ 04/17/23 06:34:47.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:34:47.573
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:34:47.574
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 04/17/23 06:34:47.575
  STEP: When a replicaset with a matching selector is created @ 04/17/23 06:34:55.588
  STEP: Then the orphan pod is adopted @ 04/17/23 06:34:55.589
  STEP: When the matched label of one of its pods change @ 04/17/23 06:34:56.592
  Apr 17 06:34:56.593: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/17/23 06:34:56.596
  Apr 17 06:34:57.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6647" for this suite. @ 04/17/23 06:34:57.6
â€¢ [10.033 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]
test/e2e/storage/subpath.go:106
  STEP: Creating a kubernetes client @ 04/17/23 06:34:57.601
  Apr 17 06:34:57.601: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename subpath @ 04/17/23 06:34:57.602
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:34:57.605
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:34:57.606
  STEP: Setting up data @ 04/17/23 06:34:57.607
  STEP: Creating pod pod-subpath-test-projected-8n6k @ 04/17/23 06:34:57.609
  STEP: Creating a pod to test atomic-volume-subpath @ 04/17/23 06:34:57.609
  STEP: Saw pod success @ 04/17/23 06:35:21.641
  Apr 17 06:35:21.642: INFO: Trying to get logs from node c3-worker2 pod pod-subpath-test-projected-8n6k container test-container-subpath-projected-8n6k: <nil>
  STEP: delete the pod @ 04/17/23 06:35:21.652
  STEP: Deleting pod pod-subpath-test-projected-8n6k @ 04/17/23 06:35:21.655
  Apr 17 06:35:21.655: INFO: Deleting pod "pod-subpath-test-projected-8n6k" in namespace "subpath-8375"
  Apr 17 06:35:21.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-8375" for this suite. @ 04/17/23 06:35:21.657
â€¢ [24.058 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 04/17/23 06:35:21.659
  Apr 17 06:35:21.659: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename proxy @ 04/17/23 06:35:21.66
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:35:21.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:35:21.665
  STEP: starting an echo server on multiple ports @ 04/17/23 06:35:21.669
  STEP: creating replication controller proxy-service-g9kpc in namespace proxy-5240 @ 04/17/23 06:35:21.669
  I0417 06:35:21.671960      30 runners.go:194] Created replication controller with name: proxy-service-g9kpc, namespace: proxy-5240, replica count: 1
  I0417 06:35:22.723154      30 runners.go:194] proxy-service-g9kpc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  I0417 06:35:23.723556      30 runners.go:194] proxy-service-g9kpc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 17 06:35:23.725: INFO: setup took 2.058325596s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 04/17/23 06:35:23.725
  Apr 17 06:35:23.727: INFO: (0) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 2.085905ms)
  Apr 17 06:35:23.727: INFO: (0) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 2.326018ms)
  Apr 17 06:35:23.727: INFO: (0) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 2.370433ms)
  Apr 17 06:35:23.727: INFO: (0) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 2.382256ms)
  Apr 17 06:35:23.727: INFO: (0) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 2.480034ms)
  Apr 17 06:35:23.727: INFO: (0) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 2.474513ms)
  Apr 17 06:35:23.727: INFO: (0) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 2.521254ms)
  Apr 17 06:35:23.727: INFO: (0) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 2.465857ms)
  Apr 17 06:35:23.727: INFO: (0) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 2.482559ms)
  Apr 17 06:35:23.727: INFO: (0) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 2.517095ms)
  Apr 17 06:35:23.727: INFO: (0) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 2.463022ms)
  Apr 17 06:35:23.730: INFO: (0) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 5.232091ms)
  Apr 17 06:35:23.730: INFO: (0) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 5.31448ms)
  Apr 17 06:35:23.730: INFO: (0) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 5.611162ms)
  Apr 17 06:35:23.731: INFO: (0) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 5.760509ms)
  Apr 17 06:35:23.731: INFO: (0) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 5.666889ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.906921ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 1.892263ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.933622ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.947449ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.929795ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.915267ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.951747ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.976955ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 2.005039ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.977918ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.96836ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 2.026621ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.972086ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 2.017955ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 2.083882ms)
  Apr 17 06:35:23.733: INFO: (1) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 2.011132ms)
  Apr 17 06:35:23.734: INFO: (2) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.39778ms)
  Apr 17 06:35:23.734: INFO: (2) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.562167ms)
  Apr 17 06:35:23.734: INFO: (2) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.583569ms)
  Apr 17 06:35:23.734: INFO: (2) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.591112ms)
  Apr 17 06:35:23.734: INFO: (2) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.554693ms)
  Apr 17 06:35:23.734: INFO: (2) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.559282ms)
  Apr 17 06:35:23.734: INFO: (2) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.618817ms)
  Apr 17 06:35:23.735: INFO: (2) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 1.758925ms)
  Apr 17 06:35:23.735: INFO: (2) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.822569ms)
  Apr 17 06:35:23.735: INFO: (2) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.825655ms)
  Apr 17 06:35:23.735: INFO: (2) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.831636ms)
  Apr 17 06:35:23.735: INFO: (2) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.857255ms)
  Apr 17 06:35:23.735: INFO: (2) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.900889ms)
  Apr 17 06:35:23.735: INFO: (2) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.879267ms)
  Apr 17 06:35:23.735: INFO: (2) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.93244ms)
  Apr 17 06:35:23.735: INFO: (2) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.909957ms)
  Apr 17 06:35:23.736: INFO: (3) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.166325ms)
  Apr 17 06:35:23.736: INFO: (3) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.321103ms)
  Apr 17 06:35:23.736: INFO: (3) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.329931ms)
  Apr 17 06:35:23.736: INFO: (3) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.343276ms)
  Apr 17 06:35:23.736: INFO: (3) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.361651ms)
  Apr 17 06:35:23.736: INFO: (3) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.505458ms)
  Apr 17 06:35:23.736: INFO: (3) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.608436ms)
  Apr 17 06:35:23.737: INFO: (3) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.798742ms)
  Apr 17 06:35:23.737: INFO: (3) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.791038ms)
  Apr 17 06:35:23.737: INFO: (3) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.843458ms)
  Apr 17 06:35:23.737: INFO: (3) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.833399ms)
  Apr 17 06:35:23.737: INFO: (3) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.880871ms)
  Apr 17 06:35:23.737: INFO: (3) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 1.910328ms)
  Apr 17 06:35:23.737: INFO: (3) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.885901ms)
  Apr 17 06:35:23.737: INFO: (3) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.907332ms)
  Apr 17 06:35:23.737: INFO: (3) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.962277ms)
  Apr 17 06:35:23.738: INFO: (4) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.429131ms)
  Apr 17 06:35:23.738: INFO: (4) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.530246ms)
  Apr 17 06:35:23.738: INFO: (4) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.616932ms)
  Apr 17 06:35:23.738: INFO: (4) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.632322ms)
  Apr 17 06:35:23.738: INFO: (4) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.628775ms)
  Apr 17 06:35:23.738: INFO: (4) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.666648ms)
  Apr 17 06:35:23.738: INFO: (4) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 1.669083ms)
  Apr 17 06:35:23.738: INFO: (4) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.732095ms)
  Apr 17 06:35:23.739: INFO: (4) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.783323ms)
  Apr 17 06:35:23.739: INFO: (4) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.863537ms)
  Apr 17 06:35:23.739: INFO: (4) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.858237ms)
  Apr 17 06:35:23.739: INFO: (4) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.856173ms)
  Apr 17 06:35:23.739: INFO: (4) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.903465ms)
  Apr 17 06:35:23.739: INFO: (4) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.882604ms)
  Apr 17 06:35:23.739: INFO: (4) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.870631ms)
  Apr 17 06:35:23.739: INFO: (4) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.910799ms)
  Apr 17 06:35:23.740: INFO: (5) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.524234ms)
  Apr 17 06:35:23.740: INFO: (5) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.586264ms)
  Apr 17 06:35:23.740: INFO: (5) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.627814ms)
  Apr 17 06:35:23.740: INFO: (5) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.701646ms)
  Apr 17 06:35:23.740: INFO: (5) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.689282ms)
  Apr 17 06:35:23.740: INFO: (5) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.737895ms)
  Apr 17 06:35:23.741: INFO: (5) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.886321ms)
  Apr 17 06:35:23.741: INFO: (5) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.850632ms)
  Apr 17 06:35:23.741: INFO: (5) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 1.878817ms)
  Apr 17 06:35:23.741: INFO: (5) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.860562ms)
  Apr 17 06:35:23.741: INFO: (5) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.883005ms)
  Apr 17 06:35:23.741: INFO: (5) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.88075ms)
  Apr 17 06:35:23.741: INFO: (5) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.952228ms)
  Apr 17 06:35:23.741: INFO: (5) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.97397ms)
  Apr 17 06:35:23.741: INFO: (5) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 2.002956ms)
  Apr 17 06:35:23.741: INFO: (5) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.995431ms)
  Apr 17 06:35:23.742: INFO: (6) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.382702ms)
  Apr 17 06:35:23.742: INFO: (6) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.39774ms)
  Apr 17 06:35:23.742: INFO: (6) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.478306ms)
  Apr 17 06:35:23.742: INFO: (6) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.565564ms)
  Apr 17 06:35:23.742: INFO: (6) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.597666ms)
  Apr 17 06:35:23.742: INFO: (6) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.752704ms)
  Apr 17 06:35:23.743: INFO: (6) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.895849ms)
  Apr 17 06:35:23.743: INFO: (6) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 2.084693ms)
  Apr 17 06:35:23.743: INFO: (6) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 2.244671ms)
  Apr 17 06:35:23.743: INFO: (6) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 2.267595ms)
  Apr 17 06:35:23.743: INFO: (6) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 2.237207ms)
  Apr 17 06:35:23.743: INFO: (6) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 2.228921ms)
  Apr 17 06:35:23.743: INFO: (6) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 2.241064ms)
  Apr 17 06:35:23.743: INFO: (6) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 2.275681ms)
  Apr 17 06:35:23.743: INFO: (6) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 2.250492ms)
  Apr 17 06:35:23.743: INFO: (6) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 2.269318ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.58987ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.632773ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.633194ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.749909ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.751422ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 1.878055ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.915246ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.920768ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.920447ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.928493ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.96855ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 2.026441ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.964762ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.979079ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.983939ms)
  Apr 17 06:35:23.745: INFO: (7) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.990421ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.459329ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.512531ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.510538ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.618626ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.660747ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.642912ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.644395ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.686617ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.700033ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 1.837537ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.868036ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.887223ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.870641ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.971926ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.920407ms)
  Apr 17 06:35:23.747: INFO: (8) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.920397ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.67753ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.660586ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.68809ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.799053ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.820244ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.843118ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 1.886892ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.889357ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.880039ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.922832ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.924514ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.937549ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.92208ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.90696ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.918734ms)
  Apr 17 06:35:23.749: INFO: (9) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.924685ms)
  Apr 17 06:35:23.752: INFO: (10) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 2.929971ms)
  Apr 17 06:35:23.752: INFO: (10) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 3.008081ms)
  Apr 17 06:35:23.752: INFO: (10) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 3.059109ms)
  Apr 17 06:35:23.752: INFO: (10) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 3.172408ms)
  Apr 17 06:35:23.752: INFO: (10) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 3.193869ms)
  Apr 17 06:35:23.753: INFO: (10) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 3.690104ms)
  Apr 17 06:35:23.753: INFO: (10) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 3.913945ms)
  Apr 17 06:35:23.753: INFO: (10) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 3.871743ms)
  Apr 17 06:35:23.753: INFO: (10) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 3.975944ms)
  Apr 17 06:35:23.753: INFO: (10) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 4.111715ms)
  Apr 17 06:35:23.753: INFO: (10) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 4.126594ms)
  Apr 17 06:35:23.753: INFO: (10) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 4.119912ms)
  Apr 17 06:35:23.753: INFO: (10) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 4.127757ms)
  Apr 17 06:35:23.753: INFO: (10) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 4.123799ms)
  Apr 17 06:35:23.753: INFO: (10) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 4.155069ms)
  Apr 17 06:35:23.753: INFO: (10) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 4.12953ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.347103ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.563199ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 1.791278ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.858096ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.898835ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.926348ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.980212ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.938411ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.959192ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.98922ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.971074ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 2.019498ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 2.038394ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 2.014077ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 2.011582ms)
  Apr 17 06:35:23.755: INFO: (11) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 2.049034ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.165755ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.430023ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.468226ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.487433ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.460201ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.481912ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.795236ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.801368ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.939674ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.944754ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.96886ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.996433ms)
  Apr 17 06:35:23.757: INFO: (12) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 2.023185ms)
  Apr 17 06:35:23.758: INFO: (12) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 2.083981ms)
  Apr 17 06:35:23.758: INFO: (12) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 2.078651ms)
  Apr 17 06:35:23.758: INFO: (12) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 2.068592ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.265306ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.672259ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.786338ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.821336ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.843488ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.878526ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.879298ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.91656ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.861293ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 1.885399ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.925176ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.881972ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.886241ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.93771ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.915888ms)
  Apr 17 06:35:23.759: INFO: (13) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.897452ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.040503ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.585843ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.757383ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.753295ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.770138ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 1.798292ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.774085ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.778523ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.805986ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.820846ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.881041ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.871513ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.896801ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.911991ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.889197ms)
  Apr 17 06:35:23.761: INFO: (14) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.913493ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.44431ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.463017ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.476883ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.49626ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.510207ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.504456ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.671137ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.768144ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 1.716434ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.742645ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.731904ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.732605ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.782011ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.784295ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.837698ms)
  Apr 17 06:35:23.763: INFO: (15) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.909135ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.273341ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.287769ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.27286ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.334129ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.325602ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.344548ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.367252ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.539062ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.706936ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.704371ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.884157ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.924244ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 2.006482ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 2.001222ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 2.042141ms)
  Apr 17 06:35:23.765: INFO: (16) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 2.02555ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.325982ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.388402ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.391148ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.413501ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 1.430965ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.585121ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.611672ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.640267ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 1.755199ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.872404ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.838459ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.903294ms)
  Apr 17 06:35:23.767: INFO: (17) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.969572ms)
  Apr 17 06:35:23.768: INFO: (17) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.985161ms)
  Apr 17 06:35:23.768: INFO: (17) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 2.01041ms)
  Apr 17 06:35:23.768: INFO: (17) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.969211ms)
  Apr 17 06:35:23.769: INFO: (18) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.730171ms)
  Apr 17 06:35:23.769: INFO: (18) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.826506ms)
  Apr 17 06:35:23.769: INFO: (18) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.776811ms)
  Apr 17 06:35:23.769: INFO: (18) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 1.803502ms)
  Apr 17 06:35:23.770: INFO: (18) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 1.959693ms)
  Apr 17 06:35:23.770: INFO: (18) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 2.017584ms)
  Apr 17 06:35:23.770: INFO: (18) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 1.987376ms)
  Apr 17 06:35:23.770: INFO: (18) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 2.017814ms)
  Apr 17 06:35:23.770: INFO: (18) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 2.001152ms)
  Apr 17 06:35:23.770: INFO: (18) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 2.013105ms)
  Apr 17 06:35:23.770: INFO: (18) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 2.019768ms)
  Apr 17 06:35:23.770: INFO: (18) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 2.081627ms)
  Apr 17 06:35:23.770: INFO: (18) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 2.08816ms)
  Apr 17 06:35:23.770: INFO: (18) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 2.100033ms)
  Apr 17 06:35:23.770: INFO: (18) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 2.100283ms)
  Apr 17 06:35:23.770: INFO: (18) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 2.116785ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">test<... (200; 1.807149ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname1/proxy/: tls baz (200; 1.828179ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname1/proxy/: foo (200; 1.855582ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:443/proxy/tlsrewritem... (200; 1.831145ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/services/proxy-service-g9kpc:portname2/proxy/: bar (200; 1.94269ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:462/proxy/: tls qux (200; 1.965835ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 1.97892ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname2/proxy/: bar (200; 1.991724ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/services/https:proxy-service-g9kpc:tlsportname2/proxy/: tls qux (200; 2.016342ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/services/http:proxy-service-g9kpc:portname1/proxy/: foo (200; 2.054445ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn/proxy/rewriteme">test</a> (200; 2.047903ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/: <a href="/api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:1080/proxy/rewriteme">... (200; 2.038013ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:160/proxy/: foo (200; 2.044736ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/pods/https:proxy-service-g9kpc-dstcn:460/proxy/: tls baz (200; 2.083851ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/pods/http:proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 2.115783ms)
  Apr 17 06:35:23.772: INFO: (19) /api/v1/namespaces/proxy-5240/pods/proxy-service-g9kpc-dstcn:162/proxy/: bar (200; 2.09326ms)
  Apr 17 06:35:23.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController proxy-service-g9kpc in namespace proxy-5240, will wait for the garbage collector to delete the pods @ 04/17/23 06:35:23.773
  Apr 17 06:35:23.826: INFO: Deleting ReplicationController proxy-service-g9kpc took: 1.97436ms
  Apr 17 06:35:23.926: INFO: Terminating ReplicationController proxy-service-g9kpc pods took: 100.309579ms
  STEP: Destroying namespace "proxy-5240" for this suite. @ 04/17/23 06:35:26.428
â€¢ [4.770 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:175
  STEP: Creating a kubernetes client @ 04/17/23 06:35:26.43
  Apr 17 06:35:26.430: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 06:35:26.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:35:26.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:35:26.436
  STEP: Creating configMap with name configmap-test-upd-79325d6b-d59f-4103-b542-8520ad4bf50e @ 04/17/23 06:35:26.439
  STEP: Creating the pod @ 04/17/23 06:35:26.44
  STEP: Waiting for pod with text data @ 04/17/23 06:35:30.449
  STEP: Waiting for pod with binary data @ 04/17/23 06:35:30.459
  Apr 17 06:35:30.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-482" for this suite. @ 04/17/23 06:35:30.462
â€¢ [4.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 04/17/23 06:35:30.464
  Apr 17 06:35:30.464: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 06:35:30.464
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:35:30.468
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:35:30.47
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-1609 @ 04/17/23 06:35:30.471
  STEP: changing the ExternalName service to type=NodePort @ 04/17/23 06:35:30.472
  STEP: creating replication controller externalname-service in namespace services-1609 @ 04/17/23 06:35:30.477
  I0417 06:35:30.479632      30 runners.go:194] Created replication controller with name: externalname-service, namespace: services-1609, replica count: 2
  I0417 06:35:33.531964      30 runners.go:194] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 17 06:35:33.532: INFO: Creating new exec pod
  Apr 17 06:35:36.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-1609 exec execpodgfj6t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 17 06:35:36.664: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 17 06:35:36.664: INFO: stdout: "externalname-service-gwd8q"
  Apr 17 06:35:36.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-1609 exec execpodgfj6t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.51.187 80'
  Apr 17 06:35:36.765: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.51.187 80\nConnection to 10.96.51.187 80 port [tcp/http] succeeded!\n"
  Apr 17 06:35:36.765: INFO: stdout: "externalname-service-7j6xz"
  Apr 17 06:35:36.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-1609 exec execpodgfj6t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.18.0.3 30324'
  Apr 17 06:35:36.828: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.18.0.3 30324\nConnection to 172.18.0.3 30324 port [tcp/*] succeeded!\n"
  Apr 17 06:35:36.828: INFO: stdout: "externalname-service-7j6xz"
  Apr 17 06:35:36.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-1609 exec execpodgfj6t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.18.0.4 30324'
  Apr 17 06:35:36.944: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.18.0.4 30324\nConnection to 172.18.0.4 30324 port [tcp/*] succeeded!\n"
  Apr 17 06:35:36.944: INFO: stdout: "externalname-service-gwd8q"
  Apr 17 06:35:36.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 17 06:35:36.945: INFO: Cleaning up the ExternalName to NodePort test service
  STEP: Destroying namespace "services-1609" for this suite. @ 04/17/23 06:35:36.951
â€¢ [6.489 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]
test/e2e/apimachinery/webhook.go:300
  STEP: Creating a kubernetes client @ 04/17/23 06:35:36.953
  Apr 17 06:35:36.953: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 06:35:36.953
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:35:36.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:35:36.958
  STEP: Setting up server cert @ 04/17/23 06:35:36.965
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 06:35:37.203
  STEP: Deploying the webhook pod @ 04/17/23 06:35:37.206
  STEP: Wait for the deployment to be ready @ 04/17/23 06:35:37.21
  Apr 17 06:35:37.212: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 06:35:39.216
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 06:35:39.219
  Apr 17 06:35:40.219: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 04/17/23 06:35:40.22
  STEP: Creating a custom resource definition that should be denied by the webhook @ 04/17/23 06:35:40.227
  Apr 17 06:35:40.227: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 06:35:40.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7222" for this suite. @ 04/17/23 06:35:40.244
  STEP: Destroying namespace "webhook-markers-4230" for this suite. @ 04/17/23 06:35:40.245
â€¢ [3.294 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 04/17/23 06:35:40.248
  Apr 17 06:35:40.248: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename field-validation @ 04/17/23 06:35:40.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:35:40.252
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:35:40.253
  Apr 17 06:35:40.254: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  W0417 06:35:42.776359      30 warnings.go:70] unknown field "alpha"
  W0417 06:35:42.776376      30 warnings.go:70] unknown field "beta"
  W0417 06:35:42.776379      30 warnings.go:70] unknown field "delta"
  W0417 06:35:42.776381      30 warnings.go:70] unknown field "epsilon"
  W0417 06:35:42.776384      30 warnings.go:70] unknown field "gamma"
  Apr 17 06:35:42.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8651" for this suite. @ 04/17/23 06:35:42.786
â€¢ [2.541 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 04/17/23 06:35:42.789
  Apr 17 06:35:42.789: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename var-expansion @ 04/17/23 06:35:42.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:35:42.793
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:35:42.795
  STEP: Creating a pod to test substitution in container's args @ 04/17/23 06:35:42.796
  STEP: Saw pod success @ 04/17/23 06:35:44.801
  Apr 17 06:35:44.802: INFO: Trying to get logs from node c3-worker2 pod var-expansion-c2991010-9d21-4e10-b453-b4f24c75df30 container dapi-container: <nil>
  STEP: delete the pod @ 04/17/23 06:35:44.805
  Apr 17 06:35:44.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-837" for this suite. @ 04/17/23 06:35:44.81
â€¢ [2.022 seconds]
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
test/e2e/apps/daemon_set.go:374
  STEP: Creating a kubernetes client @ 04/17/23 06:35:44.811
  Apr 17 06:35:44.811: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename daemonsets @ 04/17/23 06:35:44.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:35:44.816
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:35:44.817
  Apr 17 06:35:44.823: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/17/23 06:35:44.825
  Apr 17 06:35:44.826: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 06:35:44.827: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 06:35:44.827: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 06:35:45.828: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 06:35:45.829: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 17 06:35:45.829: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Update daemon pods image. @ 04/17/23 06:35:45.834
  STEP: Check that daemon pods images are updated. @ 04/17/23 06:35:45.839
  Apr 17 06:35:45.840: INFO: Wrong image for pod: daemon-set-67rsf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 17 06:35:45.840: INFO: Wrong image for pod: daemon-set-qm9bj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 17 06:35:45.841: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 06:35:46.843: INFO: Wrong image for pod: daemon-set-qm9bj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 17 06:35:46.844: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 06:35:47.842: INFO: Wrong image for pod: daemon-set-qm9bj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 17 06:35:47.842: INFO: Pod daemon-set-tkzb2 is not available
  Apr 17 06:35:47.843: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 06:35:48.844: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 06:35:49.843: INFO: Pod daemon-set-lhr2h is not available
  Apr 17 06:35:49.844: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 04/17/23 06:35:49.844
  Apr 17 06:35:49.845: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 06:35:49.846: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 17 06:35:49.846: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 06:35:50.848: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 06:35:50.849: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 17 06:35:50.849: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/17/23 06:35:50.854
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7667, will wait for the garbage collector to delete the pods @ 04/17/23 06:35:50.854
  Apr 17 06:35:50.907: INFO: Deleting DaemonSet.extensions daemon-set took: 2.251444ms
  Apr 17 06:35:51.007: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.537879ms
  Apr 17 06:35:52.509: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 06:35:52.509: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 17 06:35:52.510: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"40979"},"items":null}

  Apr 17 06:35:52.511: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"40979"},"items":null}

  Apr 17 06:35:52.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7667" for this suite. @ 04/17/23 06:35:52.515
â€¢ [7.705 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 04/17/23 06:35:52.517
  Apr 17 06:35:52.517: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename dns @ 04/17/23 06:35:52.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:35:52.521
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:35:52.522
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 04/17/23 06:35:52.523
  Apr 17 06:35:52.526: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-6301  c5c289cf-a2b7-47d2-9e72-d6044575a68d 40984 0 2023-04-17 06:35:52 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-17 06:35:52 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j4n5p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j4n5p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  STEP: Verifying customized DNS suffix list is configured on pod... @ 04/17/23 06:35:54.529
  Apr 17 06:35:54.529: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6301 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 06:35:54.529: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 06:35:54.529: INFO: ExecWithOptions: Clientset creation
  Apr 17 06:35:54.529: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-6301/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 04/17/23 06:35:54.602
  Apr 17 06:35:54.603: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6301 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 06:35:54.603: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 06:35:54.603: INFO: ExecWithOptions: Clientset creation
  Apr 17 06:35:54.603: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-6301/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 17 06:35:54.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 17 06:35:54.660: INFO: Deleting pod test-dns-nameservers...
  STEP: Destroying namespace "dns-6301" for this suite. @ 04/17/23 06:35:54.663
â€¢ [2.148 seconds]
------------------------------
SSSS
------------------------------
[sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]
test/e2e/common/node/runtimeclass.go:189
  STEP: Creating a kubernetes client @ 04/17/23 06:35:54.665
  Apr 17 06:35:54.665: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename runtimeclass @ 04/17/23 06:35:54.665
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:35:54.669
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:35:54.67
  STEP: getting /apis @ 04/17/23 06:35:54.671
  STEP: getting /apis/node.k8s.io @ 04/17/23 06:35:54.673
  STEP: getting /apis/node.k8s.io/v1 @ 04/17/23 06:35:54.673
  STEP: creating @ 04/17/23 06:35:54.674
  STEP: watching @ 04/17/23 06:35:54.678
  Apr 17 06:35:54.678: INFO: starting watch
  STEP: getting @ 04/17/23 06:35:54.679
  STEP: listing @ 04/17/23 06:35:54.68
  STEP: patching @ 04/17/23 06:35:54.681
  STEP: updating @ 04/17/23 06:35:54.682
  Apr 17 06:35:54.683: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 04/17/23 06:35:54.683
  STEP: deleting a collection @ 04/17/23 06:35:54.686
  Apr 17 06:35:54.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-7557" for this suite. @ 04/17/23 06:35:54.691
â€¢ [0.027 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 04/17/23 06:35:54.693
  Apr 17 06:35:54.693: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubelet-test @ 04/17/23 06:35:54.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:35:54.696
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:35:54.697
  Apr 17 06:35:56.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1833" for this suite. @ 04/17/23 06:35:56.707
â€¢ [2.016 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]
test/e2e/apps/daemon_set.go:864
  STEP: Creating a kubernetes client @ 04/17/23 06:35:56.709
  Apr 17 06:35:56.709: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename daemonsets @ 04/17/23 06:35:56.709
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:35:56.713
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:35:56.714
  STEP: Creating simple DaemonSet "daemon-set" @ 04/17/23 06:35:56.72
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/17/23 06:35:56.721
  Apr 17 06:35:56.722: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 06:35:56.723: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 06:35:56.723: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 06:35:57.725: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 06:35:57.726: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 17 06:35:57.726: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Getting /status @ 04/17/23 06:35:57.729
  Apr 17 06:35:57.731: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 04/17/23 06:35:57.731
  Apr 17 06:35:57.734: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 04/17/23 06:35:57.734
  Apr 17 06:35:57.735: INFO: Observed &DaemonSet event: ADDED
  Apr 17 06:35:57.735: INFO: Observed &DaemonSet event: MODIFIED
  Apr 17 06:35:57.735: INFO: Observed &DaemonSet event: MODIFIED
  Apr 17 06:35:57.735: INFO: Observed &DaemonSet event: MODIFIED
  Apr 17 06:35:57.735: INFO: Found daemon set daemon-set in namespace daemonsets-3302 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 17 06:35:57.735: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 04/17/23 06:35:57.735
  STEP: watching for the daemon set status to be patched @ 04/17/23 06:35:57.737
  Apr 17 06:35:57.738: INFO: Observed &DaemonSet event: ADDED
  Apr 17 06:35:57.738: INFO: Observed &DaemonSet event: MODIFIED
  Apr 17 06:35:57.738: INFO: Observed &DaemonSet event: MODIFIED
  Apr 17 06:35:57.738: INFO: Observed &DaemonSet event: MODIFIED
  Apr 17 06:35:57.738: INFO: Observed daemon set daemon-set in namespace daemonsets-3302 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 17 06:35:57.738: INFO: Observed &DaemonSet event: MODIFIED
  Apr 17 06:35:57.738: INFO: Found daemon set daemon-set in namespace daemonsets-3302 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Apr 17 06:35:57.739: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 04/17/23 06:35:57.74
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3302, will wait for the garbage collector to delete the pods @ 04/17/23 06:35:57.74
  Apr 17 06:35:57.792: INFO: Deleting DaemonSet.extensions daemon-set took: 1.456493ms
  Apr 17 06:35:57.892: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.26251ms
  Apr 17 06:36:01.494: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 06:36:01.494: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 17 06:36:01.495: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"41118"},"items":null}

  Apr 17 06:36:01.496: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"41118"},"items":null}

  Apr 17 06:36:01.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3302" for this suite. @ 04/17/23 06:36:01.502
â€¢ [4.796 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:124
  STEP: Creating a kubernetes client @ 04/17/23 06:36:01.504
  Apr 17 06:36:01.504: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 06:36:01.505
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:36:01.508
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:36:01.509
  STEP: Creating configMap with name configmap-test-upd-9ad0e86f-b9b2-4171-a60d-55908be79685 @ 04/17/23 06:36:01.511
  STEP: Creating the pod @ 04/17/23 06:36:01.513
  STEP: Updating configmap configmap-test-upd-9ad0e86f-b9b2-4171-a60d-55908be79685 @ 04/17/23 06:36:03.522
  STEP: waiting to observe update in volume @ 04/17/23 06:36:03.524
  Apr 17 06:37:31.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9926" for this suite. @ 04/17/23 06:37:31.707
â€¢ [90.205 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
test/e2e/apimachinery/resource_quota.go:76
  STEP: Creating a kubernetes client @ 04/17/23 06:37:31.709
  Apr 17 06:37:31.709: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename resourcequota @ 04/17/23 06:37:31.71
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:37:31.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:37:31.715
  STEP: Counting existing ResourceQuota @ 04/17/23 06:37:31.716
  STEP: Creating a ResourceQuota @ 04/17/23 06:37:36.717
  STEP: Ensuring resource quota status is calculated @ 04/17/23 06:37:36.719
  Apr 17 06:37:38.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1865" for this suite. @ 04/17/23 06:37:38.723
â€¢ [7.015 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 04/17/23 06:37:38.725
  Apr 17 06:37:38.725: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-runtime @ 04/17/23 06:37:38.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:37:38.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:37:38.731
  STEP: create the container @ 04/17/23 06:37:38.732
  W0417 06:37:38.734474      30 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 04/17/23 06:37:38.734
  STEP: get the container status @ 04/17/23 06:37:41.74
  STEP: the container should be terminated @ 04/17/23 06:37:41.741
  STEP: the termination message should be set @ 04/17/23 06:37:41.741
  Apr 17 06:37:41.741: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/17/23 06:37:41.741
  Apr 17 06:37:41.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-517" for this suite. @ 04/17/23 06:37:41.746
â€¢ [3.022 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 04/17/23 06:37:41.748
  Apr 17 06:37:41.748: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename var-expansion @ 04/17/23 06:37:41.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:37:41.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:37:41.753
  Apr 17 06:37:43.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 17 06:37:43.760: INFO: Deleting pod "var-expansion-b03dc182-ce3d-440d-8c29-6095b9066129" in namespace "var-expansion-4929"
  Apr 17 06:37:43.762: INFO: Wait up to 5m0s for pod "var-expansion-b03dc182-ce3d-440d-8c29-6095b9066129" to be fully deleted
  STEP: Destroying namespace "var-expansion-4929" for this suite. @ 04/17/23 06:37:45.765
â€¢ [4.020 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:109
  STEP: Creating a kubernetes client @ 04/17/23 06:37:45.767
  Apr 17 06:37:45.767: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 06:37:45.768
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:37:45.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:37:45.773
  STEP: Creating configMap with name projected-configmap-test-volume-map-8fd6a093-044c-4ea2-b7e8-318ddedf910a @ 04/17/23 06:37:45.774
  STEP: Creating a pod to test consume configMaps @ 04/17/23 06:37:45.775
  STEP: Saw pod success @ 04/17/23 06:37:47.783
  Apr 17 06:37:47.784: INFO: Trying to get logs from node c3-worker pod pod-projected-configmaps-8f76f8d2-a166-4371-8493-b412b6ddfbfb container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 06:37:47.792
  Apr 17 06:37:47.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-613" for this suite. @ 04/17/23 06:37:47.798
â€¢ [2.032 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:458
  STEP: Creating a kubernetes client @ 04/17/23 06:37:47.8
  Apr 17 06:37:47.800: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename init-container @ 04/17/23 06:37:47.8
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:37:47.804
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:37:47.805
  STEP: creating the pod @ 04/17/23 06:37:47.806
  Apr 17 06:37:47.806: INFO: PodSpec: initContainers in spec.initContainers
  Apr 17 06:37:50.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-95" for this suite. @ 04/17/23 06:37:50.762
â€¢ [2.964 seconds]
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]
test/e2e/kubectl/kubectl.go:830
  STEP: Creating a kubernetes client @ 04/17/23 06:37:50.764
  Apr 17 06:37:50.764: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 06:37:50.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:37:50.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:37:50.769
  STEP: validating api versions @ 04/17/23 06:37:50.77
  Apr 17 06:37:50.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4965 api-versions'
  Apr 17 06:37:50.809: INFO: stderr: ""
  Apr 17 06:37:50.809: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\nmygroup.example.com/v1\nmygroup.example.com/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Apr 17 06:37:50.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4965" for this suite. @ 04/17/23 06:37:50.81
â€¢ [0.048 seconds]
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]
test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 04/17/23 06:37:50.812
  Apr 17 06:37:50.812: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename sched-pred @ 04/17/23 06:37:50.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:37:50.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:37:50.816
  Apr 17 06:37:50.817: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 17 06:37:50.819: INFO: Waiting for terminating namespaces to be deleted...
  Apr 17 06:37:50.820: INFO: 
  Logging pods the apiserver thinks is on node c3-worker before test
  Apr 17 06:37:50.826: INFO: pod-init-ab9d9299-c019-4717-836a-d9a01c64e5ea from init-container-95 started at 2023-04-17 06:37:47 +0000 UTC (1 container statuses recorded)
  Apr 17 06:37:50.826: INFO: 	Container run1 ready: false, restart count 0
  Apr 17 06:37:50.826: INFO: kindnet-plq69 from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 06:37:50.826: INFO: 	Container kindnet-cni ready: true, restart count 0
  Apr 17 06:37:50.826: INFO: kube-proxy-6r2kb from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 06:37:50.826: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 17 06:37:50.826: INFO: sonobuoy from sonobuoy started at 2023-04-17 06:33:09 +0000 UTC (1 container statuses recorded)
  Apr 17 06:37:50.826: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 17 06:37:50.826: INFO: sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-7tzl9 from sonobuoy started at 2023-04-17 06:33:10 +0000 UTC (2 container statuses recorded)
  Apr 17 06:37:50.826: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 06:37:50.826: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 17 06:37:50.826: INFO: 
  Logging pods the apiserver thinks is on node c3-worker2 before test
  Apr 17 06:37:50.832: INFO: kindnet-br9l4 from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 06:37:50.832: INFO: 	Container kindnet-cni ready: true, restart count 0
  Apr 17 06:37:50.832: INFO: kube-proxy-stm68 from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 06:37:50.832: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 17 06:37:50.832: INFO: sonobuoy-e2e-job-e91f319b048a45eb from sonobuoy started at 2023-04-17 06:33:10 +0000 UTC (2 container statuses recorded)
  Apr 17 06:37:50.832: INFO: 	Container e2e ready: true, restart count 0
  Apr 17 06:37:50.832: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 06:37:50.832: INFO: sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-svr2p from sonobuoy started at 2023-04-17 06:33:10 +0000 UTC (2 container statuses recorded)
  Apr 17 06:37:50.832: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 06:37:50.832: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 04/17/23 06:37:50.832
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.1756a57ddb58d0ac], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling..] @ 04/17/23 06:37:50.84
  Apr 17 06:37:51.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8604" for this suite. @ 04/17/23 06:37:51.842
â€¢ [1.032 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]
test/e2e/apps/replica_set.go:165
  STEP: Creating a kubernetes client @ 04/17/23 06:37:51.844
  Apr 17 06:37:51.844: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename replicaset @ 04/17/23 06:37:51.845
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:37:51.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:37:51.85
  STEP: Create a ReplicaSet @ 04/17/23 06:37:51.851
  STEP: Verify that the required pods have come up @ 04/17/23 06:37:51.852
  Apr 17 06:37:51.853: INFO: Pod name sample-pod: Found 0 pods out of 3
  Apr 17 06:37:56.855: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 04/17/23 06:37:56.855
  Apr 17 06:37:56.856: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 04/17/23 06:37:56.856
  STEP: DeleteCollection of the ReplicaSets @ 04/17/23 06:37:56.857
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 04/17/23 06:37:56.859
  Apr 17 06:37:56.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4529" for this suite. @ 04/17/23 06:37:56.862
â€¢ [5.019 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 04/17/23 06:37:56.864
  Apr 17 06:37:56.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 06:37:56.864
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:37:56.868
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:37:56.869
  STEP: Creating secret with name s-test-opt-del-dbeaf5e8-adb8-4ab3-bc0d-aad3e692896d @ 04/17/23 06:37:56.871
  STEP: Creating secret with name s-test-opt-upd-e1e81693-ab31-4cfc-b1d9-9d5ce996a346 @ 04/17/23 06:37:56.872
  STEP: Creating the pod @ 04/17/23 06:37:56.874
  STEP: Deleting secret s-test-opt-del-dbeaf5e8-adb8-4ab3-bc0d-aad3e692896d @ 04/17/23 06:37:58.886
  STEP: Updating secret s-test-opt-upd-e1e81693-ab31-4cfc-b1d9-9d5ce996a346 @ 04/17/23 06:37:58.888
  STEP: Creating secret with name s-test-opt-create-4a17610f-feea-4c59-bccf-f144f5297b8f @ 04/17/23 06:37:58.89
  STEP: waiting to observe update in volume @ 04/17/23 06:37:58.892
  Apr 17 06:39:23.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8844" for this suite. @ 04/17/23 06:39:23.074
â€¢ [86.213 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]
test/e2e/apimachinery/resource_quota.go:232
  STEP: Creating a kubernetes client @ 04/17/23 06:39:23.077
  Apr 17 06:39:23.077: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename resourcequota @ 04/17/23 06:39:23.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:39:23.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:39:23.083
  STEP: Counting existing ResourceQuota @ 04/17/23 06:39:23.084
  STEP: Creating a ResourceQuota @ 04/17/23 06:39:28.086
  STEP: Ensuring resource quota status is calculated @ 04/17/23 06:39:28.087
  STEP: Creating a Pod that fits quota @ 04/17/23 06:39:30.09
  STEP: Ensuring ResourceQuota status captures the pod usage @ 04/17/23 06:39:30.095
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 04/17/23 06:39:32.097
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 04/17/23 06:39:32.098
  STEP: Ensuring a pod cannot update its resource requirements @ 04/17/23 06:39:32.099
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 04/17/23 06:39:32.101
  STEP: Deleting the pod @ 04/17/23 06:39:34.105
  STEP: Ensuring resource quota status released the pod usage @ 04/17/23 06:39:34.107
  Apr 17 06:39:36.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-652" for this suite. @ 04/17/23 06:39:36.11
â€¢ [13.035 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:808
  STEP: Creating a kubernetes client @ 04/17/23 06:39:36.112
  Apr 17 06:39:36.112: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename svcaccounts @ 04/17/23 06:39:36.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:39:36.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:39:36.118
  STEP: Creating ServiceAccount "e2e-sa-klldg"  @ 04/17/23 06:39:36.119
  Apr 17 06:39:36.121: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-klldg"  @ 04/17/23 06:39:36.121
  Apr 17 06:39:36.122: INFO: AutomountServiceAccountToken: true
  Apr 17 06:39:36.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2899" for this suite. @ 04/17/23 06:39:36.124
â€¢ [0.013 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 04/17/23 06:39:36.125
  Apr 17 06:39:36.125: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename dns @ 04/17/23 06:39:36.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:39:36.129
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:39:36.13
  STEP: Creating a test headless service @ 04/17/23 06:39:36.131
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2003.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-2003.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2003.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-2003.svc.cluster.local;sleep 1; done
   @ 04/17/23 06:39:36.132
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-2003.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-2003.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-2003.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-2003.svc.cluster.local;sleep 1; done
   @ 04/17/23 06:39:36.132
  STEP: creating a pod to probe DNS @ 04/17/23 06:39:36.132
  STEP: submitting the pod to kubernetes @ 04/17/23 06:39:36.132
  STEP: retrieving the pod @ 04/17/23 06:39:46.146
  STEP: looking for the results for each expected name from probers @ 04/17/23 06:39:46.147
  Apr 17 06:39:46.148: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:39:46.150: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:39:46.153: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:39:46.154: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:39:46.156: INFO: Lookups using dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local]

  Apr 17 06:39:51.158: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:39:51.159: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:39:51.162: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:39:51.163: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:39:51.165: INFO: Lookups using dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local]

  Apr 17 06:39:56.158: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:39:56.159: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:39:56.163: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:39:56.164: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:39:56.166: INFO: Lookups using dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local]

  Apr 17 06:40:01.158: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:40:01.160: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:40:01.162: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:40:01.163: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:40:01.164: INFO: Lookups using dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local]

  Apr 17 06:40:06.159: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:40:06.160: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:40:06.163: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:40:06.164: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local from pod dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62: the server could not find the requested resource (get pods dns-test-b16398c5-52c1-4708-8103-9b39dd857c62)
  Apr 17 06:40:06.166: INFO: Lookups using dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-2003.svc.cluster.local]

  Apr 17 06:40:11.164: INFO: DNS probes using dns-2003/dns-test-b16398c5-52c1-4708-8103-9b39dd857c62 succeeded

  Apr 17 06:40:11.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 06:40:11.165
  STEP: deleting the test headless service @ 04/17/23 06:40:11.169
  STEP: Destroying namespace "dns-2003" for this suite. @ 04/17/23 06:40:11.171
â€¢ [35.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]
test/e2e/common/storage/empty_dir.go:227
  STEP: Creating a kubernetes client @ 04/17/23 06:40:11.174
  Apr 17 06:40:11.174: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 06:40:11.174
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:11.178
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:11.179
  STEP: Creating Pod @ 04/17/23 06:40:11.18
  STEP: Reading file content from the nginx-container @ 04/17/23 06:40:13.186
  Apr 17 06:40:13.186: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-6124 PodName:pod-sharedvolume-f0ab5804-d989-4de3-8981-8d1c057beaa4 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 06:40:13.186: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 06:40:13.186: INFO: ExecWithOptions: Clientset creation
  Apr 17 06:40:13.186: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-6124/pods/pod-sharedvolume-f0ab5804-d989-4de3-8981-8d1c057beaa4/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Apr 17 06:40:13.262: INFO: Exec stderr: ""
  Apr 17 06:40:13.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6124" for this suite. @ 04/17/23 06:40:13.263
â€¢ [2.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 04/17/23 06:40:13.266
  Apr 17 06:40:13.266: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubelet-test @ 04/17/23 06:40:13.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:13.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:13.272
  Apr 17 06:40:17.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6732" for this suite. @ 04/17/23 06:40:17.28
â€¢ [4.016 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:341
  STEP: Creating a kubernetes client @ 04/17/23 06:40:17.282
  Apr 17 06:40:17.282: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 06:40:17.283
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:17.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:17.287
  STEP: creating a replication controller @ 04/17/23 06:40:17.288
  Apr 17 06:40:17.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 create -f -'
  Apr 17 06:40:17.721: INFO: stderr: ""
  Apr 17 06:40:17.721: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/17/23 06:40:17.721
  Apr 17 06:40:17.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 17 06:40:17.764: INFO: stderr: ""
  Apr 17 06:40:17.764: INFO: stdout: "update-demo-nautilus-76t8k update-demo-nautilus-nxrl5 "
  Apr 17 06:40:17.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 get pods update-demo-nautilus-76t8k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 17 06:40:17.804: INFO: stderr: ""
  Apr 17 06:40:17.804: INFO: stdout: ""
  Apr 17 06:40:17.804: INFO: update-demo-nautilus-76t8k is created but not running
  Apr 17 06:40:22.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 17 06:40:22.848: INFO: stderr: ""
  Apr 17 06:40:22.848: INFO: stdout: "update-demo-nautilus-76t8k update-demo-nautilus-nxrl5 "
  Apr 17 06:40:22.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 get pods update-demo-nautilus-76t8k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 17 06:40:22.887: INFO: stderr: ""
  Apr 17 06:40:22.887: INFO: stdout: ""
  Apr 17 06:40:22.887: INFO: update-demo-nautilus-76t8k is created but not running
  Apr 17 06:40:27.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 17 06:40:27.934: INFO: stderr: ""
  Apr 17 06:40:27.934: INFO: stdout: "update-demo-nautilus-76t8k update-demo-nautilus-nxrl5 "
  Apr 17 06:40:27.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 get pods update-demo-nautilus-76t8k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 17 06:40:27.976: INFO: stderr: ""
  Apr 17 06:40:27.976: INFO: stdout: "true"
  Apr 17 06:40:27.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 get pods update-demo-nautilus-76t8k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 17 06:40:28.015: INFO: stderr: ""
  Apr 17 06:40:28.015: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 17 06:40:28.015: INFO: validating pod update-demo-nautilus-76t8k
  Apr 17 06:40:28.017: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 17 06:40:28.017: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 17 06:40:28.017: INFO: update-demo-nautilus-76t8k is verified up and running
  Apr 17 06:40:28.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 get pods update-demo-nautilus-nxrl5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 17 06:40:28.056: INFO: stderr: ""
  Apr 17 06:40:28.056: INFO: stdout: "true"
  Apr 17 06:40:28.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 get pods update-demo-nautilus-nxrl5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 17 06:40:28.095: INFO: stderr: ""
  Apr 17 06:40:28.095: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 17 06:40:28.095: INFO: validating pod update-demo-nautilus-nxrl5
  Apr 17 06:40:28.097: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 17 06:40:28.097: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 17 06:40:28.097: INFO: update-demo-nautilus-nxrl5 is verified up and running
  STEP: using delete to clean up resources @ 04/17/23 06:40:28.097
  Apr 17 06:40:28.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 delete --grace-period=0 --force -f -'
  Apr 17 06:40:28.138: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 17 06:40:28.138: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 17 06:40:28.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 get rc,svc -l name=update-demo --no-headers'
  Apr 17 06:40:28.181: INFO: stderr: "No resources found in kubectl-8897 namespace.\n"
  Apr 17 06:40:28.181: INFO: stdout: ""
  Apr 17 06:40:28.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8897 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 17 06:40:28.223: INFO: stderr: ""
  Apr 17 06:40:28.223: INFO: stdout: ""
  Apr 17 06:40:28.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8897" for this suite. @ 04/17/23 06:40:28.269
â€¢ [11.007 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:87
  STEP: Creating a kubernetes client @ 04/17/23 06:40:28.289
  Apr 17 06:40:28.289: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 06:40:28.289
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:28.455
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:28.457
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 04/17/23 06:40:28.458
  STEP: Saw pod success @ 04/17/23 06:40:32.486
  Apr 17 06:40:32.487: INFO: Trying to get logs from node c3-worker2 pod pod-38dc6794-5c32-4616-afa1-5dec5822119d container test-container: <nil>
  STEP: delete the pod @ 04/17/23 06:40:32.496
  Apr 17 06:40:32.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1748" for this suite. @ 04/17/23 06:40:32.501
â€¢ [4.213 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:164
  STEP: Creating a kubernetes client @ 04/17/23 06:40:32.503
  Apr 17 06:40:32.503: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename security-context @ 04/17/23 06:40:32.503
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:32.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:32.508
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/17/23 06:40:32.509
  STEP: Saw pod success @ 04/17/23 06:40:36.517
  Apr 17 06:40:36.518: INFO: Trying to get logs from node c3-worker pod security-context-d4cb8c40-a6fb-4fbd-b278-cae55bba3b58 container test-container: <nil>
  STEP: delete the pod @ 04/17/23 06:40:36.521
  Apr 17 06:40:36.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-9495" for this suite. @ 04/17/23 06:40:36.526
â€¢ [4.025 seconds]
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]
test/e2e/apps/deployment.go:485
  STEP: Creating a kubernetes client @ 04/17/23 06:40:36.528
  Apr 17 06:40:36.528: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename deployment @ 04/17/23 06:40:36.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:36.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:36.533
  STEP: creating a Deployment @ 04/17/23 06:40:36.535
  Apr 17 06:40:36.535: INFO: Creating simple deployment test-deployment-ftvq6
  Apr 17 06:40:36.538: INFO: new replicaset for deployment "test-deployment-ftvq6" is yet to be created
  STEP: Getting /status @ 04/17/23 06:40:38.543
  Apr 17 06:40:38.545: INFO: Deployment test-deployment-ftvq6 has Conditions: [{Available True 2023-04-17 06:40:37 +0000 UTC 2023-04-17 06:40:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-17 06:40:37 +0000 UTC 2023-04-17 06:40:36 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-ftvq6-5994cf9475" has successfully progressed.}]
  STEP: updating Deployment Status @ 04/17/23 06:40:38.545
  Apr 17 06:40:38.548: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 6, 40, 37, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 6, 40, 37, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 6, 40, 37, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 6, 40, 36, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-ftvq6-5994cf9475\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 04/17/23 06:40:38.548
  Apr 17 06:40:38.548: INFO: Observed &Deployment event: ADDED
  Apr 17 06:40:38.548: INFO: Observed Deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-17 06:40:36 +0000 UTC 2023-04-17 06:40:36 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-ftvq6-5994cf9475"}
  Apr 17 06:40:38.548: INFO: Observed &Deployment event: MODIFIED
  Apr 17 06:40:38.548: INFO: Observed Deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-17 06:40:36 +0000 UTC 2023-04-17 06:40:36 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-ftvq6-5994cf9475"}
  Apr 17 06:40:38.548: INFO: Observed Deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-17 06:40:36 +0000 UTC 2023-04-17 06:40:36 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 17 06:40:38.548: INFO: Observed &Deployment event: MODIFIED
  Apr 17 06:40:38.549: INFO: Observed Deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-17 06:40:36 +0000 UTC 2023-04-17 06:40:36 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 17 06:40:38.549: INFO: Observed Deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-17 06:40:36 +0000 UTC 2023-04-17 06:40:36 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-ftvq6-5994cf9475" is progressing.}
  Apr 17 06:40:38.549: INFO: Observed &Deployment event: MODIFIED
  Apr 17 06:40:38.549: INFO: Observed Deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-17 06:40:37 +0000 UTC 2023-04-17 06:40:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 17 06:40:38.549: INFO: Observed Deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-17 06:40:37 +0000 UTC 2023-04-17 06:40:36 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-ftvq6-5994cf9475" has successfully progressed.}
  Apr 17 06:40:38.549: INFO: Observed &Deployment event: MODIFIED
  Apr 17 06:40:38.549: INFO: Observed Deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-17 06:40:37 +0000 UTC 2023-04-17 06:40:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 17 06:40:38.549: INFO: Observed Deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-17 06:40:37 +0000 UTC 2023-04-17 06:40:36 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-ftvq6-5994cf9475" has successfully progressed.}
  Apr 17 06:40:38.549: INFO: Found Deployment test-deployment-ftvq6 in namespace deployment-1307 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 17 06:40:38.549: INFO: Deployment test-deployment-ftvq6 has an updated status
  STEP: patching the Statefulset Status @ 04/17/23 06:40:38.549
  Apr 17 06:40:38.549: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 17 06:40:38.551: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 04/17/23 06:40:38.551
  Apr 17 06:40:38.552: INFO: Observed &Deployment event: ADDED
  Apr 17 06:40:38.552: INFO: Observed deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-17 06:40:36 +0000 UTC 2023-04-17 06:40:36 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-ftvq6-5994cf9475"}
  Apr 17 06:40:38.552: INFO: Observed &Deployment event: MODIFIED
  Apr 17 06:40:38.552: INFO: Observed deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-17 06:40:36 +0000 UTC 2023-04-17 06:40:36 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-ftvq6-5994cf9475"}
  Apr 17 06:40:38.552: INFO: Observed deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-17 06:40:36 +0000 UTC 2023-04-17 06:40:36 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 17 06:40:38.552: INFO: Observed &Deployment event: MODIFIED
  Apr 17 06:40:38.552: INFO: Observed deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-17 06:40:36 +0000 UTC 2023-04-17 06:40:36 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 17 06:40:38.552: INFO: Observed deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-17 06:40:36 +0000 UTC 2023-04-17 06:40:36 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-ftvq6-5994cf9475" is progressing.}
  Apr 17 06:40:38.552: INFO: Observed &Deployment event: MODIFIED
  Apr 17 06:40:38.552: INFO: Observed deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-17 06:40:37 +0000 UTC 2023-04-17 06:40:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 17 06:40:38.552: INFO: Observed deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-17 06:40:37 +0000 UTC 2023-04-17 06:40:36 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-ftvq6-5994cf9475" has successfully progressed.}
  Apr 17 06:40:38.552: INFO: Observed &Deployment event: MODIFIED
  Apr 17 06:40:38.552: INFO: Observed deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-17 06:40:37 +0000 UTC 2023-04-17 06:40:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 17 06:40:38.552: INFO: Observed deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-17 06:40:37 +0000 UTC 2023-04-17 06:40:36 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-ftvq6-5994cf9475" has successfully progressed.}
  Apr 17 06:40:38.552: INFO: Observed deployment test-deployment-ftvq6 in namespace deployment-1307 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 17 06:40:38.552: INFO: Observed &Deployment event: MODIFIED
  Apr 17 06:40:38.552: INFO: Found deployment test-deployment-ftvq6 in namespace deployment-1307 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Apr 17 06:40:38.552: INFO: Deployment test-deployment-ftvq6 has a patched status
  Apr 17 06:40:38.553: INFO: Deployment "test-deployment-ftvq6":
  &Deployment{ObjectMeta:{test-deployment-ftvq6  deployment-1307  4a1f5888-84bd-4a8e-8a63-670fb1dc4580 42104 1 2023-04-17 06:40:36 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-17 06:40:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 06:40:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status} {e2e.test Update apps/v1 2023-04-17 06:40:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0019dbea8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 17 06:40:38.554: INFO: New ReplicaSet "test-deployment-ftvq6-5994cf9475" of Deployment "test-deployment-ftvq6":
  &ReplicaSet{ObjectMeta:{test-deployment-ftvq6-5994cf9475  deployment-1307  19f43b9b-0e59-48a2-93d1-a2454d651319 42101 1 2023-04-17 06:40:36 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:5994cf9475] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-ftvq6 4a1f5888-84bd-4a8e-8a63-670fb1dc4580 0xc005d0d280 0xc005d0d281}] [] [{kube-controller-manager Update apps/v1 2023-04-17 06:40:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4a1f5888-84bd-4a8e-8a63-670fb1dc4580\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 06:40:37 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 5994cf9475,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:5994cf9475] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005d0d328 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 17 06:40:38.555: INFO: Pod "test-deployment-ftvq6-5994cf9475-sqz2t" is available:
  &Pod{ObjectMeta:{test-deployment-ftvq6-5994cf9475-sqz2t test-deployment-ftvq6-5994cf9475- deployment-1307  22d870dc-b198-4a50-a462-b9f9d9508a46 42100 0 2023-04-17 06:40:36 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:5994cf9475] map[] [{apps/v1 ReplicaSet test-deployment-ftvq6-5994cf9475 19f43b9b-0e59-48a2-93d1-a2454d651319 0xc005d0d6e0 0xc005d0d6e1}] [] [{kube-controller-manager Update v1 2023-04-17 06:40:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"19f43b9b-0e59-48a2-93d1-a2454d651319\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 06:40:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.25\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mjtjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mjtjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 06:40:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 06:40:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 06:40:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 06:40:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.25,StartTime:2023-04-17 06:40:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 06:40:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://1ac3fddece18429497fd30d6c6fbced2b4782035f070ca33b1ab52d4bc0cf25c,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.25,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 06:40:38.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1307" for this suite. @ 04/17/23 06:40:38.556
â€¢ [2.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]
test/e2e/storage/csi_inline.go:131
  STEP: Creating a kubernetes client @ 04/17/23 06:40:38.559
  Apr 17 06:40:38.559: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/17/23 06:40:38.559
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:38.563
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:38.564
  STEP: creating @ 04/17/23 06:40:38.565
  STEP: getting @ 04/17/23 06:40:38.569
  STEP: listing in namespace @ 04/17/23 06:40:38.57
  STEP: patching @ 04/17/23 06:40:38.571
  STEP: deleting @ 04/17/23 06:40:38.573
  Apr 17 06:40:38.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-5960" for this suite. @ 04/17/23 06:40:38.577
â€¢ [0.019 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]
test/e2e/kubectl/kubectl.go:1027
  STEP: Creating a kubernetes client @ 04/17/23 06:40:38.579
  Apr 17 06:40:38.579: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 06:40:38.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:38.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:38.583
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/17/23 06:40:38.584
  Apr 17 06:40:38.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1370 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 17 06:40:38.626: INFO: stderr: ""
  Apr 17 06:40:38.626: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 04/17/23 06:40:38.626
  Apr 17 06:40:38.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1370 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-4"}]}} --dry-run=server'
  Apr 17 06:40:38.667: INFO: stderr: ""
  Apr 17 06:40:38.667: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/17/23 06:40:38.667
  Apr 17 06:40:38.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1370 delete pods e2e-test-httpd-pod'
  Apr 17 06:40:41.977: INFO: stderr: ""
  Apr 17 06:40:41.977: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 17 06:40:41.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1370" for this suite. @ 04/17/23 06:40:41.978
â€¢ [3.401 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
test/e2e/scheduling/limit_range.go:61
  STEP: Creating a kubernetes client @ 04/17/23 06:40:41.98
  Apr 17 06:40:41.980: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename limitrange @ 04/17/23 06:40:41.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:41.983
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:41.984
  STEP: Creating a LimitRange @ 04/17/23 06:40:41.985
  STEP: Setting up watch @ 04/17/23 06:40:41.985
  STEP: Submitting a LimitRange @ 04/17/23 06:40:42.087
  STEP: Verifying LimitRange creation was observed @ 04/17/23 06:40:42.089
  STEP: Fetching the LimitRange to ensure it has proper values @ 04/17/23 06:40:42.089
  Apr 17 06:40:42.090: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 17 06:40:42.090: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 04/17/23 06:40:42.09
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 04/17/23 06:40:42.091
  Apr 17 06:40:42.092: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 17 06:40:42.092: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 04/17/23 06:40:42.092
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 04/17/23 06:40:42.093
  Apr 17 06:40:42.094: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Apr 17 06:40:42.094: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 04/17/23 06:40:42.094
  STEP: Failing to create a Pod with more than max resources @ 04/17/23 06:40:42.095
  STEP: Updating a LimitRange @ 04/17/23 06:40:42.096
  STEP: Verifying LimitRange updating is effective @ 04/17/23 06:40:42.098
  STEP: Creating a Pod with less than former min resources @ 04/17/23 06:40:44.099
  STEP: Failing to create a Pod with more than max resources @ 04/17/23 06:40:44.101
  STEP: Deleting a LimitRange @ 04/17/23 06:40:44.103
  STEP: Verifying the LimitRange was deleted @ 04/17/23 06:40:44.104
  Apr 17 06:40:49.107: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 04/17/23 06:40:49.107
  Apr 17 06:40:49.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-4343" for this suite. @ 04/17/23 06:40:49.111
â€¢ [7.133 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 04/17/23 06:40:49.114
  Apr 17 06:40:49.114: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename watch @ 04/17/23 06:40:49.114
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:49.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:49.119
  STEP: creating a watch on configmaps @ 04/17/23 06:40:49.121
  STEP: creating a new configmap @ 04/17/23 06:40:49.121
  STEP: modifying the configmap once @ 04/17/23 06:40:49.123
  STEP: closing the watch once it receives two notifications @ 04/17/23 06:40:49.125
  Apr 17 06:40:49.125: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3250  bad9a304-3944-4709-95dd-797650d2e88a 42235 0 2023-04-17 06:40:49 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-17 06:40:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 06:40:49.125: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3250  bad9a304-3944-4709-95dd-797650d2e88a 42236 0 2023-04-17 06:40:49 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-17 06:40:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 04/17/23 06:40:49.125
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 04/17/23 06:40:49.127
  STEP: deleting the configmap @ 04/17/23 06:40:49.127
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 04/17/23 06:40:49.129
  Apr 17 06:40:49.129: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3250  bad9a304-3944-4709-95dd-797650d2e88a 42237 0 2023-04-17 06:40:49 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-17 06:40:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 06:40:49.129: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3250  bad9a304-3944-4709-95dd-797650d2e88a 42238 0 2023-04-17 06:40:49 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-17 06:40:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 06:40:49.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3250" for this suite. @ 04/17/23 06:40:49.13
â€¢ [0.017 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:208
  STEP: Creating a kubernetes client @ 04/17/23 06:40:49.132
  Apr 17 06:40:49.132: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 06:40:49.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:49.136
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:49.137
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 06:40:49.138
  STEP: Saw pod success @ 04/17/23 06:40:53.145
  Apr 17 06:40:53.146: INFO: Trying to get logs from node c3-worker2 pod downwardapi-volume-1f426b9a-5422-479d-92d0-a7696acefa7e container client-container: <nil>
  STEP: delete the pod @ 04/17/23 06:40:53.149
  Apr 17 06:40:53.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5552" for this suite. @ 04/17/23 06:40:53.153
â€¢ [4.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]
test/e2e/apimachinery/webhook.go:284
  STEP: Creating a kubernetes client @ 04/17/23 06:40:53.155
  Apr 17 06:40:53.155: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 06:40:53.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:53.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:53.161
  STEP: Setting up server cert @ 04/17/23 06:40:53.166
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 06:40:53.407
  STEP: Deploying the webhook pod @ 04/17/23 06:40:53.409
  STEP: Wait for the deployment to be ready @ 04/17/23 06:40:53.413
  Apr 17 06:40:53.414: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 06:40:55.418
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 06:40:55.421
  Apr 17 06:40:56.421: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 17 06:40:56.422: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5344-crds.webhook.example.com via the AdmissionRegistration API @ 04/17/23 06:40:56.926
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/17/23 06:40:56.933
  Apr 17 06:40:58.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3191" for this suite. @ 04/17/23 06:40:59.464
  STEP: Destroying namespace "webhook-markers-5097" for this suite. @ 04/17/23 06:40:59.465
â€¢ [6.311 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:74
  STEP: Creating a kubernetes client @ 04/17/23 06:40:59.467
  Apr 17 06:40:59.467: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 06:40:59.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:40:59.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:40:59.472
  STEP: Creating configMap with name configmap-test-volume-e6d79880-7c03-4361-b524-ff95e4b95491 @ 04/17/23 06:40:59.473
  STEP: Creating a pod to test consume configMaps @ 04/17/23 06:40:59.474
  STEP: Saw pod success @ 04/17/23 06:41:03.482
  Apr 17 06:41:03.483: INFO: Trying to get logs from node c3-worker pod pod-configmaps-935d7026-fe6e-4ddb-b1c3-c2e911e2a738 container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 06:41:03.485
  Apr 17 06:41:03.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9142" for this suite. @ 04/17/23 06:41:03.491
â€¢ [4.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:334
  STEP: Creating a kubernetes client @ 04/17/23 06:41:03.493
  Apr 17 06:41:03.493: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename init-container @ 04/17/23 06:41:03.493
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:41:03.497
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:41:03.498
  STEP: creating the pod @ 04/17/23 06:41:03.499
  Apr 17 06:41:03.499: INFO: PodSpec: initContainers in spec.initContainers
  Apr 17 06:41:46.913: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-09d9277d-aa11-41e1-8da4-b7d29a565593", GenerateName:"", Namespace:"init-container-3078", SelfLink:"", UID:"ff61d105-121a-487d-8659-c60a25981e69", ResourceVersion:"42523", Generation:0, CreationTimestamp:time.Date(2023, time.April, 17, 6, 41, 3, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"499285803"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 17, 6, 41, 3, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000db1ab8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 17, 6, 41, 46, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000db1b00), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-nhhkb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc004ef36c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-nhhkb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-nhhkb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-nhhkb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0053fafc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"c3-worker", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00034c540), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0053fb050)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0053fb070)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0053fb078), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0053fb07c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc001aaaf20), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 17, 6, 41, 3, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 17, 6, 41, 3, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 17, 6, 41, 3, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 17, 6, 41, 3, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.18.0.3", PodIP:"10.244.1.29", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.1.29"}}, StartTime:time.Date(2023, time.April, 17, 6, 41, 3, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00034c620)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00034c690)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937", ContainerID:"containerd://f6e716f9a2e89ca9aeb3819513de2cd73f0055252ac71908f49b05247a988207", Started:(*bool)(nil), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004ef3740), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(nil), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004ef3720), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc0053fb0ff), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:""}}
  Apr 17 06:41:46.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-3078" for this suite. @ 04/17/23 06:41:46.915
â€¢ [43.424 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 04/17/23 06:41:46.917
  Apr 17 06:41:46.917: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename deployment @ 04/17/23 06:41:46.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:41:46.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:41:46.923
  Apr 17 06:41:46.924: INFO: Creating simple deployment test-new-deployment
  Apr 17 06:41:46.928: INFO: deployment "test-new-deployment" doesn't have the required revision set
  STEP: getting scale subresource @ 04/17/23 06:41:48.934
  STEP: updating a scale subresource @ 04/17/23 06:41:48.934
  STEP: verifying the deployment Spec.Replicas was modified @ 04/17/23 06:41:48.936
  STEP: Patch a scale subresource @ 04/17/23 06:41:48.937
  Apr 17 06:41:48.943: INFO: Deployment "test-new-deployment":
  &Deployment{ObjectMeta:{test-new-deployment  deployment-9201  fff03bc1-d9b5-4d88-a67c-278cdcee27cf 42554 3 2023-04-17 06:41:46 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-17 06:41:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 06:41:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0058a9f58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-17 06:41:48 +0000 UTC,LastTransitionTime:2023-04-17 06:41:48 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-67bd4bf6dc" has successfully progressed.,LastUpdateTime:2023-04-17 06:41:48 +0000 UTC,LastTransitionTime:2023-04-17 06:41:46 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 17 06:41:48.944: INFO: New ReplicaSet "test-new-deployment-67bd4bf6dc" of Deployment "test-new-deployment":
  &ReplicaSet{ObjectMeta:{test-new-deployment-67bd4bf6dc  deployment-9201  71d1057b-afb6-496e-9acd-c0fa80c9af06 42557 2 2023-04-17 06:41:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment fff03bc1-d9b5-4d88-a67c-278cdcee27cf 0xc005426357 0xc005426358}] [] [{kube-controller-manager Update apps/v1 2023-04-17 06:41:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fff03bc1-d9b5-4d88-a67c-278cdcee27cf\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 06:41:48 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 67bd4bf6dc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0054263e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 17 06:41:48.945: INFO: Pod "test-new-deployment-67bd4bf6dc-cj8px" is available:
  &Pod{ObjectMeta:{test-new-deployment-67bd4bf6dc-cj8px test-new-deployment-67bd4bf6dc- deployment-9201  34c8ca4f-3542-4943-84d9-028cb0f56221 42546 0 2023-04-17 06:41:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet test-new-deployment-67bd4bf6dc 71d1057b-afb6-496e-9acd-c0fa80c9af06 0xc005869497 0xc005869498}] [] [{kube-controller-manager Update v1 2023-04-17 06:41:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"71d1057b-afb6-496e-9acd-c0fa80c9af06\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 06:41:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.27\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xvdcq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xvdcq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 06:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 06:41:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 06:41:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 06:41:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.27,StartTime:2023-04-17 06:41:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 06:41:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://e3ebe1a62caf387415ccd210bc2c4339014e13b70462c48a3fe8034285f78a3f,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.27,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 06:41:48.945: INFO: Pod "test-new-deployment-67bd4bf6dc-zl877" is not available:
  &Pod{ObjectMeta:{test-new-deployment-67bd4bf6dc-zl877 test-new-deployment-67bd4bf6dc- deployment-9201  03f7bf86-322b-4cb5-afcc-80ad3110f0e3 42556 0 2023-04-17 06:41:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet test-new-deployment-67bd4bf6dc 71d1057b-afb6-496e-9acd-c0fa80c9af06 0xc005869680 0xc005869681}] [] [{kube-controller-manager Update v1 2023-04-17 06:41:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"71d1057b-afb6-496e-9acd-c0fa80c9af06\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7pbwr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7pbwr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 06:41:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 06:41:48.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9201" for this suite. @ 04/17/23 06:41:48.946
â€¢ [2.031 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
test/e2e/apps/job.go:430
  STEP: Creating a kubernetes client @ 04/17/23 06:41:48.948
  Apr 17 06:41:48.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename job @ 04/17/23 06:41:48.949
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:41:48.952
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:41:48.953
  STEP: Creating a job @ 04/17/23 06:41:48.954
  STEP: Ensuring job reaches completions @ 04/17/23 06:41:48.956
  Apr 17 06:41:58.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3885" for this suite. @ 04/17/23 06:41:58.959
â€¢ [10.012 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:240
  STEP: Creating a kubernetes client @ 04/17/23 06:41:58.961
  Apr 17 06:41:58.961: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 06:41:58.961
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:41:58.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:41:58.967
  STEP: Creating configMap with name cm-test-opt-del-ae0b29a6-b38e-44cd-8228-4f226ef6dcda @ 04/17/23 06:41:58.969
  STEP: Creating configMap with name cm-test-opt-upd-946a75d1-340a-4981-b3ed-edbc41f40e3a @ 04/17/23 06:41:58.97
  STEP: Creating the pod @ 04/17/23 06:41:58.971
  STEP: Deleting configmap cm-test-opt-del-ae0b29a6-b38e-44cd-8228-4f226ef6dcda @ 04/17/23 06:42:00.985
  STEP: Updating configmap cm-test-opt-upd-946a75d1-340a-4981-b3ed-edbc41f40e3a @ 04/17/23 06:42:00.987
  STEP: Creating configMap with name cm-test-opt-create-83cc3db2-ba52-443c-84d7-6be74d731769 @ 04/17/23 06:42:00.989
  STEP: waiting to observe update in volume @ 04/17/23 06:42:00.99
  Apr 17 06:43:29.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7961" for this suite. @ 04/17/23 06:43:29.184
â€¢ [90.225 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:217
  STEP: Creating a kubernetes client @ 04/17/23 06:43:29.186
  Apr 17 06:43:29.186: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 06:43:29.186
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:43:29.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:43:29.191
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/17/23 06:43:29.193
  STEP: Saw pod success @ 04/17/23 06:43:33.202
  Apr 17 06:43:33.203: INFO: Trying to get logs from node c3-worker pod pod-1c5ca2a8-63f8-4861-833e-d93990493388 container test-container: <nil>
  STEP: delete the pod @ 04/17/23 06:43:33.205
  Apr 17 06:43:33.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2895" for this suite. @ 04/17/23 06:43:33.211
â€¢ [4.027 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance]
test/e2e/apimachinery/server_version.go:40
  STEP: Creating a kubernetes client @ 04/17/23 06:43:33.213
  Apr 17 06:43:33.213: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename server-version @ 04/17/23 06:43:33.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:43:33.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:43:33.218
  STEP: Request ServerVersion @ 04/17/23 06:43:33.219
  STEP: Confirm major version @ 04/17/23 06:43:33.219
  Apr 17 06:43:33.219: INFO: Major version: 1
  STEP: Confirm minor version @ 04/17/23 06:43:33.219
  Apr 17 06:43:33.219: INFO: cleanMinorVersion: 27
  Apr 17 06:43:33.219: INFO: Minor version: 27
  Apr 17 06:43:33.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-2576" for this suite. @ 04/17/23 06:43:33.22
â€¢ [0.009 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:423
  STEP: Creating a kubernetes client @ 04/17/23 06:43:33.222
  Apr 17 06:43:33.222: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 06:43:33.223
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:43:33.226
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:43:33.227
  STEP: Creating configMap with name configmap-test-volume-7fe01b87-9c1e-456e-8bfa-cf94217494eb @ 04/17/23 06:43:33.228
  STEP: Creating a pod to test consume configMaps @ 04/17/23 06:43:33.229
  STEP: Saw pod success @ 04/17/23 06:43:37.236
  Apr 17 06:43:37.237: INFO: Trying to get logs from node c3-worker pod pod-configmaps-ba5236c8-5aaa-4a82-8496-9b3708b32828 container configmap-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 06:43:37.24
  Apr 17 06:43:37.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1715" for this suite. @ 04/17/23 06:43:37.244
â€¢ [4.024 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 04/17/23 06:43:37.246
  Apr 17 06:43:37.246: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/17/23 06:43:37.247
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:43:37.25
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:43:37.251
  Apr 17 06:43:37.253: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/17/23 06:43:38.454
  Apr 17 06:43:38.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-2844 --namespace=crd-publish-openapi-2844 create -f -'
  Apr 17 06:43:40.809: INFO: stderr: ""
  Apr 17 06:43:40.809: INFO: stdout: "e2e-test-crd-publish-openapi-699-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 17 06:43:40.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-2844 --namespace=crd-publish-openapi-2844 delete e2e-test-crd-publish-openapi-699-crds test-cr'
  Apr 17 06:43:40.853: INFO: stderr: ""
  Apr 17 06:43:40.853: INFO: stdout: "e2e-test-crd-publish-openapi-699-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Apr 17 06:43:40.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-2844 --namespace=crd-publish-openapi-2844 apply -f -'
  Apr 17 06:43:40.959: INFO: stderr: ""
  Apr 17 06:43:40.959: INFO: stdout: "e2e-test-crd-publish-openapi-699-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 17 06:43:40.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-2844 --namespace=crd-publish-openapi-2844 delete e2e-test-crd-publish-openapi-699-crds test-cr'
  Apr 17 06:43:41.000: INFO: stderr: ""
  Apr 17 06:43:41.000: INFO: stdout: "e2e-test-crd-publish-openapi-699-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/17/23 06:43:41
  Apr 17 06:43:41.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-2844 explain e2e-test-crd-publish-openapi-699-crds'
  Apr 17 06:43:41.100: INFO: stderr: ""
  Apr 17 06:43:41.100: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-699-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Apr 17 06:43:42.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2844" for this suite. @ 04/17/23 06:43:42.295
â€¢ [5.051 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 04/17/23 06:43:42.297
  Apr 17 06:43:42.297: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-probe @ 04/17/23 06:43:42.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:43:42.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:43:42.302
  Apr 17 06:44:04.335: INFO: Container started at 2023-04-17 06:43:42 +0000 UTC, pod became ready at 2023-04-17 06:44:02 +0000 UTC
  Apr 17 06:44:04.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2097" for this suite. @ 04/17/23 06:44:04.336
â€¢ [22.041 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:370
  STEP: Creating a kubernetes client @ 04/17/23 06:44:04.34
  Apr 17 06:44:04.340: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename namespaces @ 04/17/23 06:44:04.34
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:44:04.344
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:44:04.345
  STEP: Updating Namespace "namespaces-233" @ 04/17/23 06:44:04.346
  Apr 17 06:44:04.349: INFO: Namespace "namespaces-233" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"2f2b4a38-48a4-49d0-90b5-0f5f94ee4d80", "kubernetes.io/metadata.name":"namespaces-233", "namespaces-233":"updated", "pod-security.kubernetes.io/enforce":"baseline"}
  Apr 17 06:44:04.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-233" for this suite. @ 04/17/23 06:44:04.35
â€¢ [0.012 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]
test/e2e/common/node/configmap.go:138
  STEP: Creating a kubernetes client @ 04/17/23 06:44:04.352
  Apr 17 06:44:04.352: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 06:44:04.352
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:44:04.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:44:04.356
  STEP: Creating configMap that has name configmap-test-emptyKey-e78276df-2b6f-498f-8b85-84747cdfb911 @ 04/17/23 06:44:04.357
  Apr 17 06:44:04.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8783" for this suite. @ 04/17/23 06:44:04.359
â€¢ [0.009 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 04/17/23 06:44:04.361
  Apr 17 06:44:04.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 06:44:04.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:44:04.365
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:44:04.366
  STEP: Creating secret with name secret-test-6fe1ad0c-67b8-408d-942b-75bf25308ada @ 04/17/23 06:44:04.367
  STEP: Creating a pod to test consume secrets @ 04/17/23 06:44:04.368
  STEP: Saw pod success @ 04/17/23 06:44:06.373
  Apr 17 06:44:06.374: INFO: Trying to get logs from node c3-worker pod pod-secrets-2cafc55d-d47a-4e50-accc-578ba3e4ccdf container secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 06:44:06.376
  Apr 17 06:44:06.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4525" for this suite. @ 04/17/23 06:44:06.381
â€¢ [2.022 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]
test/e2e/apimachinery/resource_quota.go:451
  STEP: Creating a kubernetes client @ 04/17/23 06:44:06.383
  Apr 17 06:44:06.383: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename resourcequota @ 04/17/23 06:44:06.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:44:06.388
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:44:06.389
  STEP: Counting existing ResourceQuota @ 04/17/23 06:44:06.39
  STEP: Creating a ResourceQuota @ 04/17/23 06:44:11.392
  STEP: Ensuring resource quota status is calculated @ 04/17/23 06:44:11.394
  STEP: Creating a ReplicaSet @ 04/17/23 06:44:13.397
  STEP: Ensuring resource quota status captures replicaset creation @ 04/17/23 06:44:13.401
  STEP: Deleting a ReplicaSet @ 04/17/23 06:44:15.404
  STEP: Ensuring resource quota status released usage @ 04/17/23 06:44:15.405
  Apr 17 06:44:17.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2662" for this suite. @ 04/17/23 06:44:17.409
â€¢ [11.028 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
test/e2e/apimachinery/webhook.go:272
  STEP: Creating a kubernetes client @ 04/17/23 06:44:17.411
  Apr 17 06:44:17.411: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 06:44:17.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:44:17.415
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:44:17.417
  STEP: Setting up server cert @ 04/17/23 06:44:17.422
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 06:44:17.542
  STEP: Deploying the webhook pod @ 04/17/23 06:44:17.545
  STEP: Wait for the deployment to be ready @ 04/17/23 06:44:17.549
  Apr 17 06:44:17.550: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 06:44:19.555
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 06:44:19.558
  Apr 17 06:44:20.558: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/17/23 06:44:20.559
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/17/23 06:44:20.566
  STEP: Creating a dummy validating-webhook-configuration object @ 04/17/23 06:44:20.571
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 04/17/23 06:44:20.574
  STEP: Creating a dummy mutating-webhook-configuration object @ 04/17/23 06:44:20.575
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 04/17/23 06:44:20.578
  Apr 17 06:44:20.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6475" for this suite. @ 04/17/23 06:44:20.592
  STEP: Destroying namespace "webhook-markers-196" for this suite. @ 04/17/23 06:44:20.594
â€¢ [3.184 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:127
  STEP: Creating a kubernetes client @ 04/17/23 06:44:20.595
  Apr 17 06:44:20.595: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 06:44:20.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:44:20.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:44:20.6
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/17/23 06:44:20.601
  STEP: Saw pod success @ 04/17/23 06:44:24.609
  Apr 17 06:44:24.610: INFO: Trying to get logs from node c3-worker pod pod-9aa8a3f0-1f59-4af5-8cd5-3fe5cb3c9221 container test-container: <nil>
  STEP: delete the pod @ 04/17/23 06:44:24.613
  Apr 17 06:44:24.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8785" for this suite. @ 04/17/23 06:44:24.618
â€¢ [4.024 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance]
test/e2e/network/service.go:3138
  STEP: Creating a kubernetes client @ 04/17/23 06:44:24.62
  Apr 17 06:44:24.620: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 06:44:24.62
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:44:24.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:44:24.625
  STEP: creating an Endpoint @ 04/17/23 06:44:24.627
  STEP: waiting for available Endpoint @ 04/17/23 06:44:24.629
  STEP: listing all Endpoints @ 04/17/23 06:44:24.63
  STEP: updating the Endpoint @ 04/17/23 06:44:24.63
  STEP: fetching the Endpoint @ 04/17/23 06:44:24.632
  STEP: patching the Endpoint @ 04/17/23 06:44:24.633
  STEP: fetching the Endpoint @ 04/17/23 06:44:24.636
  STEP: deleting the Endpoint by Collection @ 04/17/23 06:44:24.637
  STEP: waiting for Endpoint deletion @ 04/17/23 06:44:24.639
  STEP: fetching the Endpoint @ 04/17/23 06:44:24.639
  Apr 17 06:44:24.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6198" for this suite. @ 04/17/23 06:44:24.641
â€¢ [0.022 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 04/17/23 06:44:24.643
  Apr 17 06:44:24.643: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename cronjob @ 04/17/23 06:44:24.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:44:24.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:44:24.648
  STEP: Creating a ForbidConcurrent cronjob @ 04/17/23 06:44:24.649
  STEP: Ensuring a job is scheduled @ 04/17/23 06:44:24.651
  STEP: Ensuring exactly one is scheduled @ 04/17/23 06:45:00.652
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/17/23 06:45:00.654
  STEP: Ensuring no more jobs are scheduled @ 04/17/23 06:45:00.655
  STEP: Removing cronjob @ 04/17/23 06:50:00.658
  Apr 17 06:50:00.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5350" for this suite. @ 04/17/23 06:50:00.661
â€¢ [336.020 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]
test/e2e/apps/statefulset.go:316
  STEP: Creating a kubernetes client @ 04/17/23 06:50:00.664
  Apr 17 06:50:00.664: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename statefulset @ 04/17/23 06:50:00.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:50:00.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:50:00.669
  STEP: Creating service test in namespace statefulset-1083 @ 04/17/23 06:50:00.67
  STEP: Creating a new StatefulSet @ 04/17/23 06:50:00.672
  Apr 17 06:50:00.675: INFO: Found 0 stateful pods, waiting for 3
  Apr 17 06:50:10.681: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 17 06:50:10.681: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 17 06:50:10.681: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Apr 17 06:50:10.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-1083 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 17 06:50:10.797: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 17 06:50:10.797: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 17 06:50:10.797: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/17/23 06:50:20.804
  Apr 17 06:50:20.818: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/17/23 06:50:20.818
  STEP: Updating Pods in reverse ordinal order @ 04/17/23 06:50:30.824
  Apr 17 06:50:30.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-1083 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 17 06:50:30.960: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 17 06:50:30.960: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 17 06:50:30.960: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  STEP: Rolling back to a previous revision @ 04/17/23 06:50:50.967
  Apr 17 06:50:50.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-1083 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 17 06:50:51.088: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 17 06:50:51.088: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 17 06:50:51.088: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 17 06:51:01.108: INFO: Updating stateful set ss2
  STEP: Rolling back update in reverse ordinal order @ 04/17/23 06:51:11.112
  Apr 17 06:51:11.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-1083 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 17 06:51:11.216: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 17 06:51:11.216: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 17 06:51:11.216: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 17 06:51:21.224: INFO: Deleting all statefulset in ns statefulset-1083
  Apr 17 06:51:21.225: INFO: Scaling statefulset ss2 to 0
  Apr 17 06:51:31.232: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 17 06:51:31.233: INFO: Deleting statefulset ss2
  Apr 17 06:51:31.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1083" for this suite. @ 04/17/23 06:51:31.237
â€¢ [90.576 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
test/e2e/apps/statefulset.go:701
  STEP: Creating a kubernetes client @ 04/17/23 06:51:31.24
  Apr 17 06:51:31.240: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename statefulset @ 04/17/23 06:51:31.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:51:31.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:51:31.245
  STEP: Creating service test in namespace statefulset-3026 @ 04/17/23 06:51:31.246
  STEP: Creating stateful set ss in namespace statefulset-3026 @ 04/17/23 06:51:31.247
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3026 @ 04/17/23 06:51:31.249
  Apr 17 06:51:31.250: INFO: Found 0 stateful pods, waiting for 1
  Apr 17 06:51:41.253: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 04/17/23 06:51:41.253
  Apr 17 06:51:41.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-3026 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 17 06:51:41.369: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 17 06:51:41.369: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 17 06:51:41.369: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 17 06:51:41.370: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  Apr 17 06:51:51.373: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 17 06:51:51.373: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 17 06:51:51.378: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
  Apr 17 06:51:51.378: INFO: ss-0  c3-worker  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:51:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:51:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:51:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:51:31 +0000 UTC  }]
  Apr 17 06:51:51.378: INFO: 
  Apr 17 06:51:51.378: INFO: StatefulSet ss has not reached scale 3, at 1
  Apr 17 06:51:52.380: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.998962731s
  Apr 17 06:51:53.382: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99671527s
  Apr 17 06:51:54.383: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.994937359s
  Apr 17 06:51:55.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.993522335s
  Apr 17 06:51:56.387: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.991162031s
  Apr 17 06:51:57.389: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.989514264s
  Apr 17 06:51:58.391: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.987810832s
  Apr 17 06:51:59.392: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.986163905s
  Apr 17 06:52:00.394: INFO: Verifying statefulset ss doesn't scale past 3 for another 984.576296ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3026 @ 04/17/23 06:52:01.394
  Apr 17 06:52:01.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-3026 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 17 06:52:01.520: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 17 06:52:01.520: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 17 06:52:01.520: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 17 06:52:01.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-3026 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 17 06:52:01.633: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 17 06:52:01.633: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 17 06:52:01.633: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 17 06:52:01.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-3026 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 17 06:52:01.732: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 17 06:52:01.732: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 17 06:52:01.732: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 17 06:52:01.734: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 17 06:52:01.734: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 17 06:52:01.734: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 04/17/23 06:52:01.734
  Apr 17 06:52:01.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-3026 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 17 06:52:01.844: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 17 06:52:01.844: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 17 06:52:01.844: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 17 06:52:01.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-3026 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 17 06:52:01.947: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 17 06:52:01.947: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 17 06:52:01.947: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 17 06:52:01.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-3026 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 17 06:52:02.031: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 17 06:52:02.031: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 17 06:52:02.031: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 17 06:52:02.031: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 17 06:52:02.032: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
  Apr 17 06:52:12.035: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 17 06:52:12.035: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 17 06:52:12.035: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Apr 17 06:52:12.039: INFO: POD   NODE        PHASE    GRACE  CONDITIONS
  Apr 17 06:52:12.039: INFO: ss-0  c3-worker   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:51:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:51:31 +0000 UTC  }]
  Apr 17 06:52:12.039: INFO: ss-1  c3-worker2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:51:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:51:51 +0000 UTC  }]
  Apr 17 06:52:12.039: INFO: ss-2  c3-worker   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:51:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:51:51 +0000 UTC  }]
  Apr 17 06:52:12.039: INFO: 
  Apr 17 06:52:12.039: INFO: StatefulSet ss has not reached scale 0, at 3
  Apr 17 06:52:13.041: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.998706315s
  Apr 17 06:52:14.042: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.997505513s
  Apr 17 06:52:15.043: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.995952456s
  Apr 17 06:52:16.045: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.994770599s
  Apr 17 06:52:17.046: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.993297204s
  Apr 17 06:52:18.048: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.991868779s
  Apr 17 06:52:19.049: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.990264678s
  Apr 17 06:52:20.051: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.989079759s
  Apr 17 06:52:21.052: INFO: Verifying statefulset ss doesn't scale past 0 for another 987.301039ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3026 @ 04/17/23 06:52:22.052
  Apr 17 06:52:22.054: INFO: Scaling statefulset ss to 0
  Apr 17 06:52:22.057: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 17 06:52:22.058: INFO: Deleting all statefulset in ns statefulset-3026
  Apr 17 06:52:22.059: INFO: Scaling statefulset ss to 0
  Apr 17 06:52:22.063: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 17 06:52:22.063: INFO: Deleting statefulset ss
  Apr 17 06:52:22.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3026" for this suite. @ 04/17/23 06:52:22.068
â€¢ [50.829 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:54
  STEP: Creating a kubernetes client @ 04/17/23 06:52:22.07
  Apr 17 06:52:22.070: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 06:52:22.07
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:52:22.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:52:22.076
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 06:52:22.077
  STEP: Saw pod success @ 04/17/23 06:52:24.083
  Apr 17 06:52:24.084: INFO: Trying to get logs from node c3-worker pod downwardapi-volume-5a9627f3-24cb-45e9-9793-8f2d9ea3be05 container client-container: <nil>
  STEP: delete the pod @ 04/17/23 06:52:24.094
  Apr 17 06:52:24.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9068" for this suite. @ 04/17/23 06:52:24.1
â€¢ [2.032 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 04/17/23 06:52:24.102
  Apr 17 06:52:24.102: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename cronjob @ 04/17/23 06:52:24.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:52:24.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:52:24.108
  STEP: Creating a cronjob @ 04/17/23 06:52:24.109
  STEP: creating @ 04/17/23 06:52:24.109
  STEP: getting @ 04/17/23 06:52:24.111
  STEP: listing @ 04/17/23 06:52:24.112
  STEP: watching @ 04/17/23 06:52:24.113
  Apr 17 06:52:24.113: INFO: starting watch
  STEP: cluster-wide listing @ 04/17/23 06:52:24.114
  STEP: cluster-wide watching @ 04/17/23 06:52:24.114
  Apr 17 06:52:24.114: INFO: starting watch
  STEP: patching @ 04/17/23 06:52:24.115
  STEP: updating @ 04/17/23 06:52:24.117
  Apr 17 06:52:24.120: INFO: waiting for watch events with expected annotations
  Apr 17 06:52:24.120: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/17/23 06:52:24.12
  STEP: updating /status @ 04/17/23 06:52:24.122
  STEP: get /status @ 04/17/23 06:52:24.125
  STEP: deleting @ 04/17/23 06:52:24.126
  STEP: deleting a collection @ 04/17/23 06:52:24.13
  Apr 17 06:52:24.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-6600" for this suite. @ 04/17/23 06:52:24.134
â€¢ [0.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 04/17/23 06:52:24.136
  Apr 17 06:52:24.136: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename subjectreview @ 04/17/23 06:52:24.136
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:52:24.139
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:52:24.14
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-1391" @ 04/17/23 06:52:24.141
  Apr 17 06:52:24.143: INFO: saUsername: "system:serviceaccount:subjectreview-1391:e2e"
  Apr 17 06:52:24.143: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-1391"}
  Apr 17 06:52:24.143: INFO: saUID: "2df71936-3eeb-4657-89c0-7fa61c41c53c"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-1391:e2e" @ 04/17/23 06:52:24.143
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-1391:e2e" @ 04/17/23 06:52:24.143
  Apr 17 06:52:24.143: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-1391:e2e" api 'list' configmaps in "subjectreview-1391" namespace @ 04/17/23 06:52:24.143
  Apr 17 06:52:24.144: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-1391:e2e" @ 04/17/23 06:52:24.144
  Apr 17 06:52:24.145: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Apr 17 06:52:24.145: INFO: LocalSubjectAccessReview has been verified
  Apr 17 06:52:24.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-1391" for this suite. @ 04/17/23 06:52:24.146
â€¢ [0.012 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:85
  STEP: Creating a kubernetes client @ 04/17/23 06:52:24.148
  Apr 17 06:52:24.148: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 06:52:24.148
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:52:24.152
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:52:24.153
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 06:52:24.154
  STEP: Saw pod success @ 04/17/23 06:52:28.163
  Apr 17 06:52:28.164: INFO: Trying to get logs from node c3-worker pod downwardapi-volume-a25d3f81-1fae-4803-87d2-146631e364ff container client-container: <nil>
  STEP: delete the pod @ 04/17/23 06:52:28.166
  Apr 17 06:52:28.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6232" for this suite. @ 04/17/23 06:52:28.172
â€¢ [4.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 04/17/23 06:52:28.174
  Apr 17 06:52:28.174: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename deployment @ 04/17/23 06:52:28.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:52:28.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:52:28.18
  Apr 17 06:52:28.184: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  Apr 17 06:52:33.188: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/17/23 06:52:33.188
  Apr 17 06:52:33.188: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 04/17/23 06:52:33.192
  Apr 17 06:52:33.195: INFO: Deployment "test-cleanup-deployment":
  &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-6136  55fef8ba-4fd5-4a6e-8f33-c678470e8af1 44717 1 2023-04-17 06:52:33 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-04-17 06:52:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0007ffa18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

  Apr 17 06:52:33.196: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
  Apr 17 06:52:33.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6136" for this suite. @ 04/17/23 06:52:33.198
â€¢ [5.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support ephemeral VolumeLifecycleMode in CSIDriver API [Conformance]
test/e2e/storage/csi_inline.go:46
  STEP: Creating a kubernetes client @ 04/17/23 06:52:33.2
  Apr 17 06:52:33.200: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/17/23 06:52:33.201
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:52:33.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:52:33.206
  STEP: creating @ 04/17/23 06:52:33.207
  STEP: getting @ 04/17/23 06:52:33.211
  STEP: listing @ 04/17/23 06:52:33.213
  STEP: deleting @ 04/17/23 06:52:33.213
  Apr 17 06:52:33.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-3769" for this suite. @ 04/17/23 06:52:33.219
â€¢ [0.020 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]
test/e2e/instrumentation/core_events.go:57
  STEP: Creating a kubernetes client @ 04/17/23 06:52:33.221
  Apr 17 06:52:33.221: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename events @ 04/17/23 06:52:33.221
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:52:33.224
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:52:33.225
  STEP: creating a test event @ 04/17/23 06:52:33.226
  STEP: listing all events in all namespaces @ 04/17/23 06:52:33.227
  STEP: patching the test event @ 04/17/23 06:52:33.228
  STEP: fetching the test event @ 04/17/23 06:52:33.23
  STEP: updating the test event @ 04/17/23 06:52:33.231
  STEP: getting the test event @ 04/17/23 06:52:33.233
  STEP: deleting the test event @ 04/17/23 06:52:33.234
  STEP: listing all events in all namespaces @ 04/17/23 06:52:33.235
  Apr 17 06:52:33.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4081" for this suite. @ 04/17/23 06:52:33.238
â€¢ [0.019 seconds]
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]
test/e2e/apimachinery/garbage_collector.go:817
  STEP: Creating a kubernetes client @ 04/17/23 06:52:33.239
  Apr 17 06:52:33.239: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename gc @ 04/17/23 06:52:33.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:52:33.242
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:52:33.243
  Apr 17 06:52:33.251: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ee98d466-7e43-418d-a911-ea1c1f2493c1", Controller:(*bool)(0xc003d1230e), BlockOwnerDeletion:(*bool)(0xc003d1230f)}}
  Apr 17 06:52:33.253: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"feabfd03-1400-421b-adea-ab9616acfd55", Controller:(*bool)(0xc00561202e), BlockOwnerDeletion:(*bool)(0xc00561202f)}}
  Apr 17 06:52:33.255: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d97b41e8-1af7-4c63-b513-26696fdabd74", Controller:(*bool)(0xc003d1252a), BlockOwnerDeletion:(*bool)(0xc003d1252b)}}
  Apr 17 06:52:38.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3150" for this suite. @ 04/17/23 06:52:38.267
â€¢ [5.030 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 04/17/23 06:52:38.27
  Apr 17 06:52:38.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pods @ 04/17/23 06:52:38.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:52:38.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:52:38.275
  STEP: creating a Pod with a static label @ 04/17/23 06:52:38.278
  STEP: watching for Pod to be ready @ 04/17/23 06:52:38.281
  Apr 17 06:52:38.281: INFO: observed Pod pod-test in namespace pods-7262 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Apr 17 06:52:38.283: INFO: observed Pod pod-test in namespace pods-7262 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:38 +0000 UTC  }]
  Apr 17 06:52:38.288: INFO: observed Pod pod-test in namespace pods-7262 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:38 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:38 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:38 +0000 UTC  }]
  Apr 17 06:52:38.800: INFO: Found Pod pod-test in namespace pods-7262 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 06:52:38 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 04/17/23 06:52:38.801
  STEP: getting the Pod and ensuring that it's patched @ 04/17/23 06:52:38.805
  STEP: replacing the Pod's status Ready condition to False @ 04/17/23 06:52:38.806
  STEP: check the Pod again to ensure its Ready conditions are False @ 04/17/23 06:52:38.81
  STEP: deleting the Pod via a Collection with a LabelSelector @ 04/17/23 06:52:38.81
  STEP: watching for the Pod to be deleted @ 04/17/23 06:52:38.813
  Apr 17 06:52:38.813: INFO: observed event type MODIFIED
  Apr 17 06:52:40.803: INFO: observed event type MODIFIED
  Apr 17 06:52:40.944: INFO: observed event type MODIFIED
  Apr 17 06:52:41.805: INFO: observed event type MODIFIED
  Apr 17 06:52:41.808: INFO: observed event type MODIFIED
  Apr 17 06:52:41.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7262" for this suite. @ 04/17/23 06:52:41.812
â€¢ [3.544 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 04/17/23 06:52:41.814
  Apr 17 06:52:41.814: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 06:52:41.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:52:41.819
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:52:41.82
  STEP: Creating secret with name secret-test-map-6d748ed5-5a87-41a8-a311-dd63158981d0 @ 04/17/23 06:52:41.821
  STEP: Creating a pod to test consume secrets @ 04/17/23 06:52:41.822
  STEP: Saw pod success @ 04/17/23 06:52:45.832
  Apr 17 06:52:45.833: INFO: Trying to get logs from node c3-worker pod pod-secrets-5a421d25-1e2f-4da5-ba4a-d3c49a3d6ee0 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 06:52:45.835
  Apr 17 06:52:45.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3588" for this suite. @ 04/17/23 06:52:45.84
â€¢ [4.027 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 04/17/23 06:52:45.842
  Apr 17 06:52:45.842: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename dns @ 04/17/23 06:52:45.842
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:52:45.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:52:45.847
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7988.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7988.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 04/17/23 06:52:45.848
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7988.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7988.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 04/17/23 06:52:45.848
  STEP: creating a pod to probe /etc/hosts @ 04/17/23 06:52:45.848
  STEP: submitting the pod to kubernetes @ 04/17/23 06:52:45.848
  STEP: retrieving the pod @ 04/17/23 06:52:47.853
  STEP: looking for the results for each expected name from probers @ 04/17/23 06:52:47.854
  Apr 17 06:52:47.857: INFO: Unable to read jessie_hosts@dns-querier-1.dns-test-service.dns-7988.svc.cluster.local from pod dns-7988/dns-test-040ebd2a-ff1f-44b2-83b2-309210754631: the server could not find the requested resource (get pods dns-test-040ebd2a-ff1f-44b2-83b2-309210754631)
  Apr 17 06:52:47.859: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-7988/dns-test-040ebd2a-ff1f-44b2-83b2-309210754631: the server could not find the requested resource (get pods dns-test-040ebd2a-ff1f-44b2-83b2-309210754631)
  Apr 17 06:52:47.859: INFO: Lookups using dns-7988/dns-test-040ebd2a-ff1f-44b2-83b2-309210754631 failed for: [jessie_hosts@dns-querier-1.dns-test-service.dns-7988.svc.cluster.local jessie_hosts@dns-querier-1]

  Apr 17 06:52:52.865: INFO: DNS probes using dns-7988/dns-test-040ebd2a-ff1f-44b2-83b2-309210754631 succeeded

  Apr 17 06:52:52.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 06:52:52.866
  STEP: Destroying namespace "dns-7988" for this suite. @ 04/17/23 06:52:52.87
â€¢ [7.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
test/e2e/apimachinery/garbage_collector.go:638
  STEP: Creating a kubernetes client @ 04/17/23 06:52:52.873
  Apr 17 06:52:52.873: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename gc @ 04/17/23 06:52:52.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:52:52.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:52:52.877
  STEP: create the rc @ 04/17/23 06:52:52.879
  W0417 06:52:52.881378      30 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 04/17/23 06:52:58.883
  STEP: wait for the rc to be deleted @ 04/17/23 06:52:58.884
  Apr 17 06:52:59.890: INFO: 80 pods remaining
  Apr 17 06:52:59.890: INFO: 80 pods has nil DeletionTimestamp
  Apr 17 06:52:59.890: INFO: 
  Apr 17 06:53:00.891: INFO: 71 pods remaining
  Apr 17 06:53:00.891: INFO: 71 pods has nil DeletionTimestamp
  Apr 17 06:53:00.891: INFO: 
  Apr 17 06:53:01.890: INFO: 60 pods remaining
  Apr 17 06:53:01.890: INFO: 60 pods has nil DeletionTimestamp
  Apr 17 06:53:01.890: INFO: 
  Apr 17 06:53:02.889: INFO: 40 pods remaining
  Apr 17 06:53:02.889: INFO: 40 pods has nil DeletionTimestamp
  Apr 17 06:53:02.889: INFO: 
  Apr 17 06:53:03.888: INFO: 31 pods remaining
  Apr 17 06:53:03.888: INFO: 31 pods has nil DeletionTimestamp
  Apr 17 06:53:03.888: INFO: 
  Apr 17 06:53:04.889: INFO: 20 pods remaining
  Apr 17 06:53:04.889: INFO: 20 pods has nil DeletionTimestamp
  Apr 17 06:53:04.889: INFO: 
  STEP: Gathering metrics @ 04/17/23 06:53:05.887
  Apr 17 06:53:05.940: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 17 06:53:05.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8991" for this suite. @ 04/17/23 06:53:05.941
â€¢ [13.070 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:74
  STEP: Creating a kubernetes client @ 04/17/23 06:53:05.944
  Apr 17 06:53:05.944: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 06:53:05.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:53:05.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:53:05.951
  STEP: Creating configMap with name projected-configmap-test-volume-31f24271-d69d-45fb-bf2f-30a0e0da234e @ 04/17/23 06:53:05.953
  STEP: Creating a pod to test consume configMaps @ 04/17/23 06:53:05.954
  STEP: Saw pod success @ 04/17/23 06:53:09.961
  Apr 17 06:53:09.962: INFO: Trying to get logs from node c3-worker pod pod-projected-configmaps-4a77e754-35d3-4f60-862a-982577d8a3a5 container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 06:53:09.965
  Apr 17 06:53:09.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1755" for this suite. @ 04/17/23 06:53:09.97
â€¢ [4.029 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:497
  STEP: Creating a kubernetes client @ 04/17/23 06:53:09.972
  Apr 17 06:53:09.972: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 06:53:09.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:53:09.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:53:09.978
  STEP: Setting up server cert @ 04/17/23 06:53:09.984
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 06:53:10.189
  STEP: Deploying the webhook pod @ 04/17/23 06:53:10.192
  STEP: Wait for the deployment to be ready @ 04/17/23 06:53:10.196
  Apr 17 06:53:10.197: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 06:53:12.201
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 06:53:12.204
  Apr 17 06:53:13.204: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 04/17/23 06:53:13.206
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 04/17/23 06:53:13.213
  STEP: Creating a configMap that should not be mutated @ 04/17/23 06:53:13.215
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 04/17/23 06:53:13.218
  STEP: Creating a configMap that should be mutated @ 04/17/23 06:53:13.22
  Apr 17 06:53:13.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-435" for this suite. @ 04/17/23 06:53:13.238
  STEP: Destroying namespace "webhook-markers-3924" for this suite. @ 04/17/23 06:53:13.239
â€¢ [3.270 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:163
  STEP: Creating a kubernetes client @ 04/17/23 06:53:13.243
  Apr 17 06:53:13.243: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 06:53:13.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:53:13.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:53:13.249
  STEP: Creating the pod @ 04/17/23 06:53:13.25
  Apr 17 06:53:15.765: INFO: Successfully updated pod "annotationupdate7f0f8c82-651b-4593-94f2-814fe3dd137d"
  Apr 17 06:53:19.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6233" for this suite. @ 04/17/23 06:53:19.783
â€¢ [6.543 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:286
  STEP: Creating a kubernetes client @ 04/17/23 06:53:19.786
  Apr 17 06:53:19.786: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename field-validation @ 04/17/23 06:53:19.787
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:53:19.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:53:19.792
  Apr 17 06:53:19.794: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 06:53:22.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7109" for this suite. @ 04/17/23 06:53:22.329
â€¢ [2.545 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:262
  STEP: Creating a kubernetes client @ 04/17/23 06:53:22.331
  Apr 17 06:53:22.331: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 06:53:22.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:53:22.335
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:53:22.336
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 06:53:22.337
  STEP: Saw pod success @ 04/17/23 06:53:24.343
  Apr 17 06:53:24.344: INFO: Trying to get logs from node c3-worker2 pod downwardapi-volume-356cb3c1-40fe-4a25-b1a2-12f1cc940525 container client-container: <nil>
  STEP: delete the pod @ 04/17/23 06:53:24.353
  Apr 17 06:53:24.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1679" for this suite. @ 04/17/23 06:53:24.358
â€¢ [2.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:268
  STEP: Creating a kubernetes client @ 04/17/23 06:53:24.36
  Apr 17 06:53:24.360: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 06:53:24.36
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:53:24.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:53:24.366
  STEP: Creating a pod to test downward api env vars @ 04/17/23 06:53:24.367
  STEP: Saw pod success @ 04/17/23 06:53:28.375
  Apr 17 06:53:28.376: INFO: Trying to get logs from node c3-worker pod downward-api-ff941e9b-4d0a-4660-9836-8b6f972a2de0 container dapi-container: <nil>
  STEP: delete the pod @ 04/17/23 06:53:28.378
  Apr 17 06:53:28.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7896" for this suite. @ 04/17/23 06:53:28.383
â€¢ [4.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]
test/e2e/auth/service_accounts.go:161
  STEP: Creating a kubernetes client @ 04/17/23 06:53:28.386
  Apr 17 06:53:28.386: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename svcaccounts @ 04/17/23 06:53:28.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:53:28.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:53:28.391
  Apr 17 06:53:28.397: INFO: created pod pod-service-account-defaultsa
  Apr 17 06:53:28.397: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Apr 17 06:53:28.398: INFO: created pod pod-service-account-mountsa
  Apr 17 06:53:28.398: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Apr 17 06:53:28.399: INFO: created pod pod-service-account-nomountsa
  Apr 17 06:53:28.399: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Apr 17 06:53:28.401: INFO: created pod pod-service-account-defaultsa-mountspec
  Apr 17 06:53:28.401: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Apr 17 06:53:28.402: INFO: created pod pod-service-account-mountsa-mountspec
  Apr 17 06:53:28.402: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Apr 17 06:53:28.404: INFO: created pod pod-service-account-nomountsa-mountspec
  Apr 17 06:53:28.404: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Apr 17 06:53:28.405: INFO: created pod pod-service-account-defaultsa-nomountspec
  Apr 17 06:53:28.405: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Apr 17 06:53:28.407: INFO: created pod pod-service-account-mountsa-nomountspec
  Apr 17 06:53:28.407: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Apr 17 06:53:28.409: INFO: created pod pod-service-account-nomountsa-nomountspec
  Apr 17 06:53:28.409: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Apr 17 06:53:28.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-979" for this suite. @ 04/17/23 06:53:28.41
â€¢ [0.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 04/17/23 06:53:28.412
  Apr 17 06:53:28.412: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename disruption @ 04/17/23 06:53:28.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:53:28.415
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:53:28.416
  STEP: Creating a kubernetes client @ 04/17/23 06:53:28.417
  Apr 17 06:53:28.417: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename disruption-2 @ 04/17/23 06:53:28.418
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:53:28.421
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:53:28.422
  STEP: Waiting for the pdb to be processed @ 04/17/23 06:53:28.424
  STEP: Waiting for the pdb to be processed @ 04/17/23 06:53:30.429
  STEP: Waiting for the pdb to be processed @ 04/17/23 06:53:32.433
  STEP: listing a collection of PDBs across all namespaces @ 04/17/23 06:53:34.437
  STEP: listing a collection of PDBs in namespace disruption-8177 @ 04/17/23 06:53:34.438
  STEP: deleting a collection of PDBs @ 04/17/23 06:53:34.439
  STEP: Waiting for the PDB collection to be deleted @ 04/17/23 06:53:34.442
  Apr 17 06:53:34.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 17 06:53:34.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-6831" for this suite. @ 04/17/23 06:53:34.445
  STEP: Destroying namespace "disruption-8177" for this suite. @ 04/17/23 06:53:34.447
â€¢ [6.037 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]
test/e2e/apps/daemon_set.go:194
  STEP: Creating a kubernetes client @ 04/17/23 06:53:34.448
  Apr 17 06:53:34.448: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename daemonsets @ 04/17/23 06:53:34.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:53:34.453
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:53:34.454
  Apr 17 06:53:34.459: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 04/17/23 06:53:34.461
  Apr 17 06:53:34.462: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 06:53:34.462: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 04/17/23 06:53:34.462
  Apr 17 06:53:34.468: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 06:53:34.468: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 06:53:35.469: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 17 06:53:35.469: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 04/17/23 06:53:35.47
  Apr 17 06:53:35.475: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 17 06:53:35.475: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  Apr 17 06:53:36.478: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 06:53:36.478: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 04/17/23 06:53:36.478
  Apr 17 06:53:36.481: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 06:53:36.481: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 06:53:37.483: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 06:53:37.483: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 06:53:38.483: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 06:53:38.483: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 06:53:39.483: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 17 06:53:39.483: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/17/23 06:53:39.485
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-705, will wait for the garbage collector to delete the pods @ 04/17/23 06:53:39.485
  Apr 17 06:53:39.537: INFO: Deleting DaemonSet.extensions daemon-set took: 1.661131ms
  Apr 17 06:53:39.639: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.090292ms
  Apr 17 06:53:41.140: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 06:53:41.141: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 17 06:53:41.141: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"47133"},"items":null}

  Apr 17 06:53:41.142: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"47133"},"items":null}

  Apr 17 06:53:41.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-705" for this suite. @ 04/17/23 06:53:41.149
â€¢ [6.703 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance]
test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 04/17/23 06:53:41.151
  Apr 17 06:53:41.151: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pods @ 04/17/23 06:53:41.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:53:41.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:53:41.157
  STEP: Create set of pods @ 04/17/23 06:53:41.158
  Apr 17 06:53:41.161: INFO: created test-pod-1
  Apr 17 06:53:41.163: INFO: created test-pod-2
  Apr 17 06:53:41.165: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 04/17/23 06:53:41.165
  STEP: waiting for all pods to be deleted @ 04/17/23 06:53:43.177
  Apr 17 06:53:43.178: INFO: Pod quantity 3 is different from expected quantity 0
  Apr 17 06:53:44.179: INFO: Pod quantity 1 is different from expected quantity 0
  Apr 17 06:53:45.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3917" for this suite. @ 04/17/23 06:53:45.181
â€¢ [4.032 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 04/17/23 06:53:45.184
  Apr 17 06:53:45.184: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename sched-preemption @ 04/17/23 06:53:45.185
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:53:45.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:53:45.189
  Apr 17 06:53:45.193: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 17 06:54:45.203: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/17/23 06:54:45.204
  Apr 17 06:54:45.210: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 17 06:54:45.212: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 17 06:54:45.217: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 17 06:54:45.219: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/17/23 06:54:45.219
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 04/17/23 06:54:47.225
  Apr 17 06:54:49.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1457" for this suite. @ 04/17/23 06:54:49.253
â€¢ [64.070 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:523
  STEP: Creating a kubernetes client @ 04/17/23 06:54:49.255
  Apr 17 06:54:49.255: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-probe @ 04/17/23 06:54:49.255
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:54:49.259
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:54:49.26
  STEP: Creating pod test-grpc-216f1352-9f8a-465f-b05d-5e6b019ee4fb in namespace container-probe-8291 @ 04/17/23 06:54:49.261
  Apr 17 06:54:51.267: INFO: Started pod test-grpc-216f1352-9f8a-465f-b05d-5e6b019ee4fb in namespace container-probe-8291
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/17/23 06:54:51.267
  Apr 17 06:54:51.268: INFO: Initial restart count of pod test-grpc-216f1352-9f8a-465f-b05d-5e6b019ee4fb is 0
  Apr 17 06:58:51.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 06:58:51.566
  STEP: Destroying namespace "container-probe-8291" for this suite. @ 04/17/23 06:58:51.568
â€¢ [242.315 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 04/17/23 06:58:51.57
  Apr 17 06:58:51.570: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename tables @ 04/17/23 06:58:51.571
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:58:51.575
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:58:51.576
  Apr 17 06:58:51.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-6907" for this suite. @ 04/17/23 06:58:51.58
â€¢ [0.011 seconds]
------------------------------
S
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 04/17/23 06:58:51.581
  Apr 17 06:58:51.581: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-probe @ 04/17/23 06:58:51.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 06:58:51.585
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 06:58:51.586
  STEP: Creating pod liveness-54afdfad-2f62-4bc0-a946-e954daee40f7 in namespace container-probe-6656 @ 04/17/23 06:58:51.587
  Apr 17 06:58:53.593: INFO: Started pod liveness-54afdfad-2f62-4bc0-a946-e954daee40f7 in namespace container-probe-6656
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/17/23 06:58:53.593
  Apr 17 06:58:53.594: INFO: Initial restart count of pod liveness-54afdfad-2f62-4bc0-a946-e954daee40f7 is 0
  Apr 17 06:59:13.618: INFO: Restart count of pod container-probe-6656/liveness-54afdfad-2f62-4bc0-a946-e954daee40f7 is now 1 (20.024937217s elapsed)
  Apr 17 06:59:33.644: INFO: Restart count of pod container-probe-6656/liveness-54afdfad-2f62-4bc0-a946-e954daee40f7 is now 2 (40.050796389s elapsed)
  Apr 17 06:59:53.670: INFO: Restart count of pod container-probe-6656/liveness-54afdfad-2f62-4bc0-a946-e954daee40f7 is now 3 (1m0.07623306s elapsed)
  Apr 17 07:00:13.694: INFO: Restart count of pod container-probe-6656/liveness-54afdfad-2f62-4bc0-a946-e954daee40f7 is now 4 (1m20.100331967s elapsed)
  Apr 17 07:01:23.777: INFO: Restart count of pod container-probe-6656/liveness-54afdfad-2f62-4bc0-a946-e954daee40f7 is now 5 (2m30.183529641s elapsed)
  Apr 17 07:01:23.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 07:01:23.779
  STEP: Destroying namespace "container-probe-6656" for this suite. @ 04/17/23 07:01:23.782
â€¢ [152.202 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance]
test/e2e/common/node/podtemplates.go:176
  STEP: Creating a kubernetes client @ 04/17/23 07:01:23.784
  Apr 17 07:01:23.784: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename podtemplate @ 04/17/23 07:01:23.784
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:01:23.788
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:01:23.79
  STEP: Create a pod template @ 04/17/23 07:01:23.791
  STEP: Replace a pod template @ 04/17/23 07:01:23.793
  Apr 17 07:01:23.795: INFO: Found updated podtemplate annotation: "true"

  Apr 17 07:01:23.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-4287" for this suite. @ 04/17/23 07:01:23.796
â€¢ [0.014 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:198
  STEP: Creating a kubernetes client @ 04/17/23 07:01:23.798
  Apr 17 07:01:23.798: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/17/23 07:01:23.799
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:01:23.802
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:01:23.803
  STEP: fetching the /apis discovery document @ 04/17/23 07:01:23.804
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 04/17/23 07:01:23.805
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 04/17/23 07:01:23.805
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 04/17/23 07:01:23.805
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 04/17/23 07:01:23.805
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 04/17/23 07:01:23.805
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 04/17/23 07:01:23.805
  Apr 17 07:01:23.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-1353" for this suite. @ 04/17/23 07:01:23.807
â€¢ [0.010 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/rc.go:69
  STEP: Creating a kubernetes client @ 04/17/23 07:01:23.809
  Apr 17 07:01:23.809: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename replication-controller @ 04/17/23 07:01:23.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:01:23.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:01:23.813
  STEP: Creating replication controller my-hostname-basic-9f85d5d7-1bca-48ee-8fa3-34a9876bff96 @ 04/17/23 07:01:23.814
  Apr 17 07:01:23.817: INFO: Pod name my-hostname-basic-9f85d5d7-1bca-48ee-8fa3-34a9876bff96: Found 0 pods out of 1
  Apr 17 07:01:28.819: INFO: Pod name my-hostname-basic-9f85d5d7-1bca-48ee-8fa3-34a9876bff96: Found 1 pods out of 1
  Apr 17 07:01:28.819: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9f85d5d7-1bca-48ee-8fa3-34a9876bff96" are running
  Apr 17 07:01:28.819: INFO: Pod "my-hostname-basic-9f85d5d7-1bca-48ee-8fa3-34a9876bff96-wjghr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 07:01:23 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 07:01:24 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 07:01:24 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 07:01:23 +0000 UTC Reason: Message:}])
  Apr 17 07:01:28.819: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/17/23 07:01:28.819
  Apr 17 07:01:28.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7574" for this suite. @ 04/17/23 07:01:28.823
â€¢ [5.016 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:222
  STEP: Creating a kubernetes client @ 04/17/23 07:01:28.825
  Apr 17 07:01:28.825: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:01:28.826
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:01:28.83
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:01:28.831
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 07:01:28.832
  STEP: Saw pod success @ 04/17/23 07:01:32.841
  Apr 17 07:01:32.843: INFO: Trying to get logs from node c3-worker pod downwardapi-volume-f9e9bc11-5200-4567-a5c2-2066af38b6fc container client-container: <nil>
  STEP: delete the pod @ 04/17/23 07:01:32.851
  Apr 17 07:01:32.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7326" for this suite. @ 04/17/23 07:01:32.857
â€¢ [4.033 seconds]
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]
test/e2e/storage/subpath.go:92
  STEP: Creating a kubernetes client @ 04/17/23 07:01:32.859
  Apr 17 07:01:32.859: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename subpath @ 04/17/23 07:01:32.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:01:32.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:01:32.864
  STEP: Setting up data @ 04/17/23 07:01:32.865
  STEP: Creating pod pod-subpath-test-downwardapi-scv8 @ 04/17/23 07:01:32.868
  STEP: Creating a pod to test atomic-volume-subpath @ 04/17/23 07:01:32.868
  STEP: Saw pod success @ 04/17/23 07:01:56.9
  Apr 17 07:01:56.901: INFO: Trying to get logs from node c3-worker2 pod pod-subpath-test-downwardapi-scv8 container test-container-subpath-downwardapi-scv8: <nil>
  STEP: delete the pod @ 04/17/23 07:01:56.91
  STEP: Deleting pod pod-subpath-test-downwardapi-scv8 @ 04/17/23 07:01:56.913
  Apr 17 07:01:56.913: INFO: Deleting pod "pod-subpath-test-downwardapi-scv8" in namespace "subpath-9018"
  Apr 17 07:01:56.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9018" for this suite. @ 04/17/23 07:01:56.915
â€¢ [24.058 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:57
  STEP: Creating a kubernetes client @ 04/17/23 07:01:56.917
  Apr 17 07:01:56.917: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:01:56.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:01:56.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:01:56.923
  STEP: Creating configMap with name projected-configmap-test-volume-36789263-f0f4-4389-b51b-c14c2ffaf8f4 @ 04/17/23 07:01:56.924
  STEP: Creating a pod to test consume configMaps @ 04/17/23 07:01:56.925
  STEP: Saw pod success @ 04/17/23 07:01:58.931
  Apr 17 07:01:58.932: INFO: Trying to get logs from node c3-worker pod pod-projected-configmaps-7393de31-ed95-4141-bb29-611306a61953 container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 07:01:58.934
  Apr 17 07:01:58.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-33" for this suite. @ 04/17/23 07:01:58.94
â€¢ [2.025 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:46
  STEP: Creating a kubernetes client @ 04/17/23 07:01:58.942
  Apr 17 07:01:58.942: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 07:01:58.942
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:01:58.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:01:58.947
  STEP: Creating secret with name secret-test-77303dcf-ccaf-48f7-bb68-68a528ef4597 @ 04/17/23 07:01:58.948
  STEP: Creating a pod to test consume secrets @ 04/17/23 07:01:58.949
  STEP: Saw pod success @ 04/17/23 07:02:00.955
  Apr 17 07:02:00.956: INFO: Trying to get logs from node c3-worker pod pod-secrets-f45f95d0-bfe9-4eef-98ae-fe65fff3db89 container secret-env-test: <nil>
  STEP: delete the pod @ 04/17/23 07:02:00.958
  Apr 17 07:02:00.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7078" for this suite. @ 04/17/23 07:02:00.963
â€¢ [2.022 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]
test/e2e/apps/daemon_set.go:166
  STEP: Creating a kubernetes client @ 04/17/23 07:02:00.964
  Apr 17 07:02:00.964: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename daemonsets @ 04/17/23 07:02:00.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:02:00.969
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:02:00.97
  STEP: Creating simple DaemonSet "daemon-set" @ 04/17/23 07:02:00.975
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/17/23 07:02:00.977
  Apr 17 07:02:00.978: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 07:02:00.979: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 07:02:00.979: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 07:02:01.980: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 07:02:01.981: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 17 07:02:01.981: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 04/17/23 07:02:01.982
  Apr 17 07:02:01.986: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 07:02:01.987: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 17 07:02:01.987: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 07:02:02.989: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 07:02:02.990: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 17 07:02:02.990: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 07:02:03.988: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 07:02:03.989: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 17 07:02:03.989: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 07:02:04.989: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 07:02:04.990: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 17 07:02:04.990: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/17/23 07:02:04.991
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1513, will wait for the garbage collector to delete the pods @ 04/17/23 07:02:04.991
  Apr 17 07:02:05.044: INFO: Deleting DaemonSet.extensions daemon-set took: 1.556188ms
  Apr 17 07:02:05.144: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.803678ms
  Apr 17 07:02:06.745: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 07:02:06.745: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 17 07:02:06.747: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"48388"},"items":null}

  Apr 17 07:02:06.748: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"48388"},"items":null}

  Apr 17 07:02:06.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1513" for this suite. @ 04/17/23 07:02:06.752
â€¢ [5.789 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:77
  STEP: Creating a kubernetes client @ 04/17/23 07:02:06.754
  Apr 17 07:02:06.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename sysctl @ 04/17/23 07:02:06.755
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:02:06.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:02:06.76
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 04/17/23 07:02:06.761
  STEP: Watching for error events or started pod @ 04/17/23 07:02:06.763
  STEP: Waiting for pod completion @ 04/17/23 07:02:08.765
  STEP: Checking that the pod succeeded @ 04/17/23 07:02:10.77
  STEP: Getting logs from the pod @ 04/17/23 07:02:10.77
  STEP: Checking that the sysctl is actually updated @ 04/17/23 07:02:10.772
  Apr 17 07:02:10.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-6636" for this suite. @ 04/17/23 07:02:10.773
â€¢ [4.020 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:176
  STEP: Creating a kubernetes client @ 04/17/23 07:02:10.775
  Apr 17 07:02:10.775: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename crd-webhook @ 04/17/23 07:02:10.776
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:02:10.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:02:10.781
  STEP: Setting up server cert @ 04/17/23 07:02:10.782
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/17/23 07:02:11.017
  STEP: Deploying the custom resource conversion webhook pod @ 04/17/23 07:02:11.019
  STEP: Wait for the deployment to be ready @ 04/17/23 07:02:11.023
  Apr 17 07:02:11.025: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 07:02:13.03
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 07:02:13.033
  Apr 17 07:02:14.033: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 17 07:02:14.034: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Creating a v1 custom resource @ 04/17/23 07:02:16.564
  STEP: Create a v2 custom resource @ 04/17/23 07:02:16.57
  STEP: List CRs in v1 @ 04/17/23 07:02:16.59
  STEP: List CRs in v2 @ 04/17/23 07:02:16.592
  Apr 17 07:02:16.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-9276" for this suite. @ 04/17/23 07:02:17.109
â€¢ [6.335 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 04/17/23 07:02:17.111
  Apr 17 07:02:17.111: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 07:02:17.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:02:17.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:02:17.116
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7655 @ 04/17/23 07:02:17.118
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/17/23 07:02:17.12
  STEP: creating service externalsvc in namespace services-7655 @ 04/17/23 07:02:17.12
  STEP: creating replication controller externalsvc in namespace services-7655 @ 04/17/23 07:02:17.123
  I0417 07:02:17.125273      30 runners.go:194] Created replication controller with name: externalsvc, namespace: services-7655, replica count: 2
  I0417 07:02:20.178007      30 runners.go:194] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 04/17/23 07:02:20.179
  Apr 17 07:02:20.183: INFO: Creating new exec pod
  Apr 17 07:02:22.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-7655 exec execpod5cw24 -- /bin/sh -x -c nslookup clusterip-service.services-7655.svc.cluster.local'
  Apr 17 07:02:22.880: INFO: stderr: "+ nslookup clusterip-service.services-7655.svc.cluster.local\n"
  Apr 17 07:02:22.880: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nNon-authoritative answer:\nName:\tclusterip-service.services-7655.svc.cluster.local.DOMAINS\nAddress: 3.64.163.50\n\n"
  Apr 17 07:02:22.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-7655, will wait for the garbage collector to delete the pods @ 04/17/23 07:02:22.881
  Apr 17 07:02:22.935: INFO: Deleting ReplicationController externalsvc took: 2.181933ms
  Apr 17 07:02:23.036: INFO: Terminating ReplicationController externalsvc pods took: 100.985748ms
  Apr 17 07:02:24.841: INFO: Cleaning up the ClusterIP to ExternalName test service
  STEP: Destroying namespace "services-7655" for this suite. @ 04/17/23 07:02:24.843
â€¢ [7.734 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:187
  STEP: Creating a kubernetes client @ 04/17/23 07:02:24.845
  Apr 17 07:02:24.845: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 07:02:24.846
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:02:24.85
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:02:24.851
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/17/23 07:02:24.852
  STEP: Saw pod success @ 04/17/23 07:02:28.859
  Apr 17 07:02:28.861: INFO: Trying to get logs from node c3-worker pod pod-949c50f5-fe66-49b1-ba91-0ef76fce5db7 container test-container: <nil>
  STEP: delete the pod @ 04/17/23 07:02:28.863
  Apr 17 07:02:28.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4379" for this suite. @ 04/17/23 07:02:28.869
â€¢ [4.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]
test/e2e/apimachinery/resource_quota.go:887
  STEP: Creating a kubernetes client @ 04/17/23 07:02:28.871
  Apr 17 07:02:28.871: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename resourcequota @ 04/17/23 07:02:28.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:02:28.875
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:02:28.876
  STEP: Creating a ResourceQuota @ 04/17/23 07:02:28.877
  STEP: Getting a ResourceQuota @ 04/17/23 07:02:28.878
  STEP: Updating a ResourceQuota @ 04/17/23 07:02:28.879
  STEP: Verifying a ResourceQuota was modified @ 04/17/23 07:02:28.881
  STEP: Deleting a ResourceQuota @ 04/17/23 07:02:28.882
  STEP: Verifying the deleted ResourceQuota @ 04/17/23 07:02:28.883
  Apr 17 07:02:28.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2947" for this suite. @ 04/17/23 07:02:28.885
â€¢ [0.016 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 04/17/23 07:02:28.887
  Apr 17 07:02:28.887: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-runtime @ 04/17/23 07:02:28.888
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:02:28.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:02:28.895
  STEP: create the container @ 04/17/23 07:02:28.896
  W0417 07:02:28.898766      30 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/17/23 07:02:28.898
  STEP: get the container status @ 04/17/23 07:02:30.901
  STEP: the container should be terminated @ 04/17/23 07:02:30.902
  STEP: the termination message should be set @ 04/17/23 07:02:30.902
  Apr 17 07:02:30.902: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/17/23 07:02:30.902
  Apr 17 07:02:30.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7410" for this suite. @ 04/17/23 07:02:30.907
â€¢ [2.021 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:208
  STEP: Creating a kubernetes client @ 04/17/23 07:02:30.909
  Apr 17 07:02:30.909: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 07:02:30.909
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:02:30.913
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:02:30.914
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 07:02:30.915
  STEP: Saw pod success @ 04/17/23 07:02:34.923
  Apr 17 07:02:34.924: INFO: Trying to get logs from node c3-worker2 pod downwardapi-volume-0bdb42dc-09a7-4fe4-8ae1-acfd777cd507 container client-container: <nil>
  STEP: delete the pod @ 04/17/23 07:02:34.926
  Apr 17 07:02:34.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2310" for this suite. @ 04/17/23 07:02:34.932
â€¢ [4.024 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 04/17/23 07:02:34.934
  Apr 17 07:02:34.934: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 07:02:34.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:02:34.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:02:34.941
  Apr 17 07:02:34.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6285" for this suite. @ 04/17/23 07:02:34.961
â€¢ [0.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]
test/e2e/auth/service_accounts.go:78
  STEP: Creating a kubernetes client @ 04/17/23 07:02:34.964
  Apr 17 07:02:34.964: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename svcaccounts @ 04/17/23 07:02:34.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:02:34.969
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:02:34.97
  STEP: reading a file in the container @ 04/17/23 07:02:36.978
  Apr 17 07:02:36.978: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8568 pod-service-account-c74df3c6-8b2f-413f-beff-a253801d3b39 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 04/17/23 07:02:37.079
  Apr 17 07:02:37.080: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8568 pod-service-account-c74df3c6-8b2f-413f-beff-a253801d3b39 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 04/17/23 07:02:37.18
  Apr 17 07:02:37.180: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8568 pod-service-account-c74df3c6-8b2f-413f-beff-a253801d3b39 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Apr 17 07:02:37.305: INFO: Got root ca configmap in namespace "svcaccounts-8568"
  Apr 17 07:02:37.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8568" for this suite. @ 04/17/23 07:02:37.308
â€¢ [2.346 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:269
  STEP: Creating a kubernetes client @ 04/17/23 07:02:37.31
  Apr 17 07:02:37.310: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/17/23 07:02:37.311
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:02:37.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:02:37.316
  Apr 17 07:02:37.318: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:02:40.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5287" for this suite. @ 04/17/23 07:02:40.36
â€¢ [3.051 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 04/17/23 07:02:40.362
  Apr 17 07:02:40.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename sched-preemption @ 04/17/23 07:02:40.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:02:40.366
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:02:40.367
  Apr 17 07:02:40.372: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 17 07:03:40.382: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/17/23 07:03:40.384
  Apr 17 07:03:40.392: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 17 07:03:40.394: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 17 07:03:40.399: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 17 07:03:40.401: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/17/23 07:03:40.401
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 04/17/23 07:03:42.407
  Apr 17 07:03:48.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-6602" for this suite. @ 04/17/23 07:03:48.435
â€¢ [68.075 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:177
  STEP: Creating a kubernetes client @ 04/17/23 07:03:48.437
  Apr 17 07:03:48.437: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename init-container @ 04/17/23 07:03:48.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:03:48.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:03:48.443
  STEP: creating the pod @ 04/17/23 07:03:48.444
  Apr 17 07:03:48.444: INFO: PodSpec: initContainers in spec.initContainers
  Apr 17 07:03:53.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-7117" for this suite. @ 04/17/23 07:03:53.028
â€¢ [4.592 seconds]
------------------------------
SSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance]
test/e2e/common/node/podtemplates.go:122
  STEP: Creating a kubernetes client @ 04/17/23 07:03:53.03
  Apr 17 07:03:53.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename podtemplate @ 04/17/23 07:03:53.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:03:53.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:03:53.034
  STEP: Create set of pod templates @ 04/17/23 07:03:53.035
  Apr 17 07:03:53.037: INFO: created test-podtemplate-1
  Apr 17 07:03:53.039: INFO: created test-podtemplate-2
  Apr 17 07:03:53.041: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 04/17/23 07:03:53.041
  STEP: delete collection of pod templates @ 04/17/23 07:03:53.042
  Apr 17 07:03:53.042: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 04/17/23 07:03:53.045
  Apr 17 07:03:53.045: INFO: requesting list of pod templates to confirm quantity
  Apr 17 07:03:53.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-2211" for this suite. @ 04/17/23 07:03:53.047
â€¢ [0.019 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:272
  STEP: Creating a kubernetes client @ 04/17/23 07:03:53.049
  Apr 17 07:03:53.049: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename namespaces @ 04/17/23 07:03:53.049
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:03:53.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:03:53.053
  STEP: creating a Namespace @ 04/17/23 07:03:53.054
  STEP: patching the Namespace @ 04/17/23 07:03:53.057
  STEP: get the Namespace and ensuring it has the label @ 04/17/23 07:03:53.058
  Apr 17 07:03:53.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1020" for this suite. @ 04/17/23 07:03:53.06
  STEP: Destroying namespace "nspatchtest-b0d9e3e1-f042-4ce4-9074-9140a618a093-3558" for this suite. @ 04/17/23 07:03:53.061
â€¢ [0.014 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]
test/e2e/apimachinery/resource_quota.go:946
  STEP: Creating a kubernetes client @ 04/17/23 07:03:53.063
  Apr 17 07:03:53.063: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename resourcequota @ 04/17/23 07:03:53.064
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:03:53.067
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:03:53.067
  STEP: Creating a ResourceQuota @ 04/17/23 07:03:53.068
  STEP: Getting a ResourceQuota @ 04/17/23 07:03:53.07
  STEP: Listing all ResourceQuotas with LabelSelector @ 04/17/23 07:03:53.07
  STEP: Patching the ResourceQuota @ 04/17/23 07:03:53.071
  STEP: Deleting a Collection of ResourceQuotas @ 04/17/23 07:03:53.073
  STEP: Verifying the deleted ResourceQuota @ 04/17/23 07:03:53.075
  Apr 17 07:03:53.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9790" for this suite. @ 04/17/23 07:03:53.077
â€¢ [0.015 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:93
  STEP: Creating a kubernetes client @ 04/17/23 07:03:53.078
  Apr 17 07:03:53.078: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 07:03:53.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:03:53.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:03:53.083
  STEP: Creating configMap configmap-8012/configmap-test-bed1be74-3710-4259-896b-23e2df29bcf0 @ 04/17/23 07:03:53.083
  STEP: Creating a pod to test consume configMaps @ 04/17/23 07:03:53.085
  STEP: Saw pod success @ 04/17/23 07:03:57.092
  Apr 17 07:03:57.093: INFO: Trying to get logs from node c3-worker2 pod pod-configmaps-f0e09082-5565-4f7a-a4e6-e9495aa3a1c3 container env-test: <nil>
  STEP: delete the pod @ 04/17/23 07:03:57.096
  Apr 17 07:03:57.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8012" for this suite. @ 04/17/23 07:03:57.101
â€¢ [4.024 seconds]
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:135
  STEP: Creating a kubernetes client @ 04/17/23 07:03:57.102
  Apr 17 07:03:57.102: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/17/23 07:03:57.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:03:57.106
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:03:57.107
  STEP: create the container to handle the HTTPGet hook request. @ 04/17/23 07:03:57.11
  STEP: create the pod with lifecycle hook @ 04/17/23 07:03:59.117
  STEP: check poststart hook @ 04/17/23 07:04:01.126
  STEP: delete the pod with lifecycle hook @ 04/17/23 07:04:01.134
  Apr 17 07:04:03.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5192" for this suite. @ 04/17/23 07:04:03.141
â€¢ [6.041 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]
test/e2e/apimachinery/webhook.go:237
  STEP: Creating a kubernetes client @ 04/17/23 07:04:03.144
  Apr 17 07:04:03.144: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 07:04:03.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:04:03.148
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:04:03.149
  STEP: Setting up server cert @ 04/17/23 07:04:03.155
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 07:04:03.494
  STEP: Deploying the webhook pod @ 04/17/23 07:04:03.497
  STEP: Wait for the deployment to be ready @ 04/17/23 07:04:03.5
  Apr 17 07:04:03.502: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 07:04:05.505
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 07:04:05.508
  Apr 17 07:04:06.508: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 04/17/23 07:04:06.51
  STEP: create a namespace for the webhook @ 04/17/23 07:04:06.517
  STEP: create a configmap should be unconditionally rejected by the webhook @ 04/17/23 07:04:06.52
  Apr 17 07:04:06.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3497" for this suite. @ 04/17/23 07:04:06.541
  STEP: Destroying namespace "webhook-markers-4469" for this suite. @ 04/17/23 07:04:06.542
  STEP: Destroying namespace "fail-closed-namespace-2150" for this suite. @ 04/17/23 07:04:06.544
â€¢ [3.402 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 04/17/23 07:04:06.546
  Apr 17 07:04:06.546: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 07:04:06.546
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:04:06.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:04:06.55
  STEP: creating service nodeport-test with type=NodePort in namespace services-6912 @ 04/17/23 07:04:06.551
  STEP: creating replication controller nodeport-test in namespace services-6912 @ 04/17/23 07:04:06.554
  I0417 07:04:06.556185      30 runners.go:194] Created replication controller with name: nodeport-test, namespace: services-6912, replica count: 2
  I0417 07:04:09.607838      30 runners.go:194] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 17 07:04:09.607: INFO: Creating new exec pod
  Apr 17 07:04:12.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-6912 exec execpod62wbb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Apr 17 07:04:12.721: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Apr 17 07:04:12.721: INFO: stdout: "nodeport-test-xp4nb"
  Apr 17 07:04:12.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-6912 exec execpod62wbb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.163.251 80'
  Apr 17 07:04:12.828: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.163.251 80\nConnection to 10.96.163.251 80 port [tcp/http] succeeded!\n"
  Apr 17 07:04:12.828: INFO: stdout: "nodeport-test-xp4nb"
  Apr 17 07:04:12.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-6912 exec execpod62wbb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.18.0.3 31917'
  Apr 17 07:04:12.927: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.18.0.3 31917\nConnection to 172.18.0.3 31917 port [tcp/*] succeeded!\n"
  Apr 17 07:04:12.927: INFO: stdout: "nodeport-test-qpnpw"
  Apr 17 07:04:12.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-6912 exec execpod62wbb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.18.0.4 31917'
  Apr 17 07:04:13.035: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.18.0.4 31917\nConnection to 172.18.0.4 31917 port [tcp/*] succeeded!\n"
  Apr 17 07:04:13.035: INFO: stdout: ""
  Apr 17 07:04:14.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-6912 exec execpod62wbb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.18.0.4 31917'
  Apr 17 07:04:14.148: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.18.0.4 31917\nConnection to 172.18.0.4 31917 port [tcp/*] succeeded!\n"
  Apr 17 07:04:14.148: INFO: stdout: "nodeport-test-xp4nb"
  Apr 17 07:04:14.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6912" for this suite. @ 04/17/23 07:04:14.15
â€¢ [7.606 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:167
  STEP: Creating a kubernetes client @ 04/17/23 07:04:14.151
  Apr 17 07:04:14.152: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 07:04:14.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:04:14.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:04:14.157
  STEP: Creating a pod to test downward api env vars @ 04/17/23 07:04:14.158
  STEP: Saw pod success @ 04/17/23 07:04:16.164
  Apr 17 07:04:16.165: INFO: Trying to get logs from node c3-worker pod downward-api-8e3e07a1-9c58-440c-bcee-d6e1a9a993ec container dapi-container: <nil>
  STEP: delete the pod @ 04/17/23 07:04:16.167
  Apr 17 07:04:16.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8929" for this suite. @ 04/17/23 07:04:16.176
â€¢ [2.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:156
  STEP: Creating a kubernetes client @ 04/17/23 07:04:16.178
  Apr 17 07:04:16.178: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename runtimeclass @ 04/17/23 07:04:16.178
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:04:16.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:04:16.183
  STEP: Deleting RuntimeClass runtimeclass-6638-delete-me @ 04/17/23 07:04:16.185
  STEP: Waiting for the RuntimeClass to disappear @ 04/17/23 07:04:16.186
  Apr 17 07:04:16.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6638" for this suite. @ 04/17/23 07:04:16.191
â€¢ [0.015 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
test/e2e/apimachinery/garbage_collector.go:538
  STEP: Creating a kubernetes client @ 04/17/23 07:04:16.192
  Apr 17 07:04:16.192: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename gc @ 04/17/23 07:04:16.193
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:04:16.196
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:04:16.197
  STEP: create the deployment @ 04/17/23 07:04:16.198
  W0417 07:04:16.199794      30 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/17/23 07:04:16.199
  STEP: delete the deployment @ 04/17/23 07:04:16.703
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 04/17/23 07:04:16.706
  STEP: Gathering metrics @ 04/17/23 07:04:17.212
  Apr 17 07:04:17.264: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 17 07:04:17.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7234" for this suite. @ 04/17/23 07:04:17.265
â€¢ [1.075 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]
test/e2e/apimachinery/webhook.go:249
  STEP: Creating a kubernetes client @ 04/17/23 07:04:17.267
  Apr 17 07:04:17.267: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 07:04:17.268
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:04:17.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:04:17.272
  STEP: Setting up server cert @ 04/17/23 07:04:17.278
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 07:04:17.724
  STEP: Deploying the webhook pod @ 04/17/23 07:04:17.726
  STEP: Wait for the deployment to be ready @ 04/17/23 07:04:17.729
  Apr 17 07:04:17.731: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/17/23 07:04:19.736
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 07:04:19.74
  Apr 17 07:04:20.740: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 04/17/23 07:04:20.742
  STEP: create a configmap that should be updated by the webhook @ 04/17/23 07:04:20.749
  Apr 17 07:04:20.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8395" for this suite. @ 04/17/23 07:04:20.766
  STEP: Destroying namespace "webhook-markers-917" for this suite. @ 04/17/23 07:04:20.767
â€¢ [3.502 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]
test/e2e/kubectl/kubectl.go:1800
  STEP: Creating a kubernetes client @ 04/17/23 07:04:20.769
  Apr 17 07:04:20.769: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 07:04:20.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:04:20.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:04:20.776
  STEP: Starting the proxy @ 04/17/23 07:04:20.777
  Apr 17 07:04:20.777: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1596 proxy --unix-socket=/tmp/kubectl-proxy-unix3061586835/test'
  STEP: retrieving proxy /api/ output @ 04/17/23 07:04:20.806
  Apr 17 07:04:20.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1596" for this suite. @ 04/17/23 07:04:20.808
â€¢ [0.041 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:486
  STEP: Creating a kubernetes client @ 04/17/23 07:04:20.81
  Apr 17 07:04:20.810: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename security-context-test @ 04/17/23 07:04:20.81
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:04:20.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:04:20.815
  Apr 17 07:04:24.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-111" for this suite. @ 04/17/23 07:04:24.825
â€¢ [4.017 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 04/17/23 07:04:24.828
  Apr 17 07:04:24.828: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/17/23 07:04:24.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:04:24.833
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:04:24.835
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 04/17/23 07:04:24.836
  Apr 17 07:04:24.836: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:04:26.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:04:30.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1795" for this suite. @ 04/17/23 07:04:30.931
â€¢ [6.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 04/17/23 07:04:30.933
  Apr 17 07:04:30.933: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pods @ 04/17/23 07:04:30.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:04:30.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:04:30.939
  STEP: creating the pod @ 04/17/23 07:04:30.94
  STEP: submitting the pod to kubernetes @ 04/17/23 07:04:30.94
  W0417 07:04:30.943222      30 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: verifying the pod is in kubernetes @ 04/17/23 07:04:32.947
  STEP: updating the pod @ 04/17/23 07:04:32.949
  Apr 17 07:04:33.454: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e90f92eb-b9f9-4c9a-b5e7-f1eedd0033d8"
  Apr 17 07:04:37.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9067" for this suite. @ 04/17/23 07:04:37.461
â€¢ [6.529 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 04/17/23 07:04:37.463
  Apr 17 07:04:37.463: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-runtime @ 04/17/23 07:04:37.464
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:04:37.468
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:04:37.469
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 04/17/23 07:04:37.473
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 04/17/23 07:04:56.506
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 04/17/23 07:04:56.507
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 04/17/23 07:04:56.509
  STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] @ 04/17/23 07:04:56.509
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 04/17/23 07:04:56.514
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 04/17/23 07:04:59.52
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 04/17/23 07:05:00.522
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 04/17/23 07:05:00.524
  STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] @ 04/17/23 07:05:00.524
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 04/17/23 07:05:00.529
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 04/17/23 07:05:01.532
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 04/17/23 07:05:03.537
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 04/17/23 07:05:03.539
  STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] @ 04/17/23 07:05:03.539
  Apr 17 07:05:03.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7423" for this suite. @ 04/17/23 07:05:03.546
â€¢ [26.084 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:95
  STEP: Creating a kubernetes client @ 04/17/23 07:05:03.548
  Apr 17 07:05:03.548: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 07:05:03.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:03.552
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:03.554
  STEP: creating secret secrets-6280/secret-test-a697eb5b-1138-42a3-813a-8a21e04d2e64 @ 04/17/23 07:05:03.555
  STEP: Creating a pod to test consume secrets @ 04/17/23 07:05:03.556
  STEP: Saw pod success @ 04/17/23 07:05:07.564
  Apr 17 07:05:07.565: INFO: Trying to get logs from node c3-worker pod pod-configmaps-5a281ecc-834d-4b4b-97ef-7be1f7e80c9f container env-test: <nil>
  STEP: delete the pod @ 04/17/23 07:05:07.568
  Apr 17 07:05:07.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6280" for this suite. @ 04/17/23 07:05:07.573
â€¢ [4.027 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]
test/e2e/common/node/secrets.go:140
  STEP: Creating a kubernetes client @ 04/17/23 07:05:07.575
  Apr 17 07:05:07.575: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 07:05:07.575
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:07.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:07.58
  STEP: Creating projection with secret that has name secret-emptykey-test-2b1c6eb3-0187-47a6-9468-c109bd46c43b @ 04/17/23 07:05:07.581
  Apr 17 07:05:07.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4040" for this suite. @ 04/17/23 07:05:07.583
â€¢ [0.010 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 04/17/23 07:05:07.585
  Apr 17 07:05:07.585: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename containers @ 04/17/23 07:05:07.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:07.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:07.589
  STEP: Creating a pod to test override command @ 04/17/23 07:05:07.59
  STEP: Saw pod success @ 04/17/23 07:05:11.597
  Apr 17 07:05:11.598: INFO: Trying to get logs from node c3-worker pod client-containers-b7b1de77-bfe1-4454-a631-bdec254772a0 container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 07:05:11.6
  Apr 17 07:05:11.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9064" for this suite. @ 04/17/23 07:05:11.605
â€¢ [4.022 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:91
  STEP: Creating a kubernetes client @ 04/17/23 07:05:11.606
  Apr 17 07:05:11.606: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 07:05:11.607
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:11.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:11.612
  STEP: Creating a pod to test downward api env vars @ 04/17/23 07:05:11.613
  STEP: Saw pod success @ 04/17/23 07:05:15.623
  Apr 17 07:05:15.624: INFO: Trying to get logs from node c3-worker pod downward-api-48d69e22-0d50-4244-8612-bf1cdab6f7cd container dapi-container: <nil>
  STEP: delete the pod @ 04/17/23 07:05:15.627
  Apr 17 07:05:15.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8263" for this suite. @ 04/17/23 07:05:15.633
â€¢ [4.028 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 04/17/23 07:05:15.635
  Apr 17 07:05:15.635: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename var-expansion @ 04/17/23 07:05:15.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:15.639
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:15.64
  STEP: Creating a pod to test substitution in volume subpath @ 04/17/23 07:05:15.64
  STEP: Saw pod success @ 04/17/23 07:05:19.648
  Apr 17 07:05:19.649: INFO: Trying to get logs from node c3-worker pod var-expansion-3a8b2d5b-ac1c-4141-a5bd-e21897f5d484 container dapi-container: <nil>
  STEP: delete the pod @ 04/17/23 07:05:19.651
  Apr 17 07:05:19.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-2130" for this suite. @ 04/17/23 07:05:19.657
â€¢ [4.023 seconds]
------------------------------
S
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 04/17/23 07:05:19.658
  Apr 17 07:05:19.658: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename var-expansion @ 04/17/23 07:05:19.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:19.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:19.663
  STEP: Creating a pod to test substitution in container's command @ 04/17/23 07:05:19.664
  STEP: Saw pod success @ 04/17/23 07:05:23.672
  Apr 17 07:05:23.673: INFO: Trying to get logs from node c3-worker pod var-expansion-7f42af1c-680e-468d-a31c-73caf24a18b0 container dapi-container: <nil>
  STEP: delete the pod @ 04/17/23 07:05:23.675
  Apr 17 07:05:23.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4525" for this suite. @ 04/17/23 07:05:23.679
â€¢ [4.023 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance]
test/e2e/common/node/lease.go:72
  STEP: Creating a kubernetes client @ 04/17/23 07:05:23.681
  Apr 17 07:05:23.681: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename lease-test @ 04/17/23 07:05:23.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:23.684
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:23.685
  Apr 17 07:05:23.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-6446" for this suite. @ 04/17/23 07:05:23.701
â€¢ [0.021 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2202
  STEP: Creating a kubernetes client @ 04/17/23 07:05:23.702
  Apr 17 07:05:23.702: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 07:05:23.703
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:23.705
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:23.706
  STEP: creating service in namespace services-4695 @ 04/17/23 07:05:23.707
  STEP: creating service affinity-nodeport in namespace services-4695 @ 04/17/23 07:05:23.707
  STEP: creating replication controller affinity-nodeport in namespace services-4695 @ 04/17/23 07:05:23.71
  I0417 07:05:23.712299      30 runners.go:194] Created replication controller with name: affinity-nodeport, namespace: services-4695, replica count: 3
  I0417 07:05:26.763980      30 runners.go:194] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 17 07:05:26.767: INFO: Creating new exec pod
  Apr 17 07:05:29.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4695 exec execpod-affinity47fvw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  Apr 17 07:05:29.884: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Apr 17 07:05:29.884: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:05:29.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4695 exec execpod-affinity47fvw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.105.19 80'
  Apr 17 07:05:30.000: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.105.19 80\nConnection to 10.96.105.19 80 port [tcp/http] succeeded!\n"
  Apr 17 07:05:30.000: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:05:30.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4695 exec execpod-affinity47fvw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.18.0.3 30730'
  Apr 17 07:05:30.116: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.18.0.3 30730\nConnection to 172.18.0.3 30730 port [tcp/*] succeeded!\n"
  Apr 17 07:05:30.116: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:05:30.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4695 exec execpod-affinity47fvw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.18.0.4 30730'
  Apr 17 07:05:30.236: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.18.0.4 30730\nConnection to 172.18.0.4 30730 port [tcp/*] succeeded!\n"
  Apr 17 07:05:30.236: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:05:30.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4695 exec execpod-affinity47fvw -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.18.0.3:30730/ ; done'
  Apr 17 07:05:30.378: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:30730/\n"
  Apr 17 07:05:30.378: INFO: stdout: "\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx\naffinity-nodeport-rrkqx"
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Received response from host: affinity-nodeport-rrkqx
  Apr 17 07:05:30.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 17 07:05:30.380: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-4695, will wait for the garbage collector to delete the pods @ 04/17/23 07:05:30.383
  Apr 17 07:05:30.437: INFO: Deleting ReplicationController affinity-nodeport took: 1.891192ms
  Apr 17 07:05:30.538: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.695251ms
  STEP: Destroying namespace "services-4695" for this suite. @ 04/17/23 07:05:32.144
â€¢ [8.443 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 04/17/23 07:05:32.146
  Apr 17 07:05:32.146: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-runtime @ 04/17/23 07:05:32.147
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:32.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:32.152
  STEP: create the container @ 04/17/23 07:05:32.153
  W0417 07:05:32.155876      30 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/17/23 07:05:32.155
  STEP: get the container status @ 04/17/23 07:05:35.163
  STEP: the container should be terminated @ 04/17/23 07:05:35.164
  STEP: the termination message should be set @ 04/17/23 07:05:35.164
  Apr 17 07:05:35.164: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 04/17/23 07:05:35.164
  Apr 17 07:05:35.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-6770" for this suite. @ 04/17/23 07:05:35.169
â€¢ [3.024 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 04/17/23 07:05:35.171
  Apr 17 07:05:35.171: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/17/23 07:05:35.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:35.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:35.177
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 04/17/23 07:05:35.178
  Apr 17 07:05:35.178: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:05:36.377: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:05:41.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-649" for this suite. @ 04/17/23 07:05:41.249
â€¢ [6.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 04/17/23 07:05:41.251
  Apr 17 07:05:41.251: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename field-validation @ 04/17/23 07:05:41.252
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:41.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:41.258
  STEP: apply creating a deployment @ 04/17/23 07:05:41.259
  Apr 17 07:05:41.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4459" for this suite. @ 04/17/23 07:05:41.264
â€¢ [0.014 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 04/17/23 07:05:41.266
  Apr 17 07:05:41.266: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/17/23 07:05:41.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:41.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:41.27
  STEP: Creating 50 configmaps @ 04/17/23 07:05:41.272
  STEP: Creating RC which spawns configmap-volume pods @ 04/17/23 07:05:41.518
  Apr 17 07:05:41.619: INFO: Pod name wrapped-volume-race-97c60dfb-1ccb-4d3c-8024-8640888019f1: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/17/23 07:05:41.619
  STEP: Creating RC which spawns configmap-volume pods @ 04/17/23 07:05:43.677
  Apr 17 07:05:43.684: INFO: Pod name wrapped-volume-race-6dfc41aa-4e66-4918-9d5a-acb0b0a9c372: Found 0 pods out of 5
  Apr 17 07:05:48.689: INFO: Pod name wrapped-volume-race-6dfc41aa-4e66-4918-9d5a-acb0b0a9c372: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/17/23 07:05:48.689
  STEP: Creating RC which spawns configmap-volume pods @ 04/17/23 07:05:48.696
  Apr 17 07:05:48.706: INFO: Pod name wrapped-volume-race-77a80651-5d05-406a-b1ee-8e21eb948413: Found 0 pods out of 5
  Apr 17 07:05:53.711: INFO: Pod name wrapped-volume-race-77a80651-5d05-406a-b1ee-8e21eb948413: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/17/23 07:05:53.712
  Apr 17 07:05:53.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController wrapped-volume-race-77a80651-5d05-406a-b1ee-8e21eb948413 in namespace emptydir-wrapper-1360, will wait for the garbage collector to delete the pods @ 04/17/23 07:05:53.719
  Apr 17 07:05:53.773: INFO: Deleting ReplicationController wrapped-volume-race-77a80651-5d05-406a-b1ee-8e21eb948413 took: 2.299229ms
  Apr 17 07:05:53.874: INFO: Terminating ReplicationController wrapped-volume-race-77a80651-5d05-406a-b1ee-8e21eb948413 pods took: 100.766856ms
  STEP: deleting ReplicationController wrapped-volume-race-6dfc41aa-4e66-4918-9d5a-acb0b0a9c372 in namespace emptydir-wrapper-1360, will wait for the garbage collector to delete the pods @ 04/17/23 07:05:56.175
  Apr 17 07:05:56.229: INFO: Deleting ReplicationController wrapped-volume-race-6dfc41aa-4e66-4918-9d5a-acb0b0a9c372 took: 2.354335ms
  Apr 17 07:05:56.330: INFO: Terminating ReplicationController wrapped-volume-race-6dfc41aa-4e66-4918-9d5a-acb0b0a9c372 pods took: 100.314666ms
  STEP: deleting ReplicationController wrapped-volume-race-97c60dfb-1ccb-4d3c-8024-8640888019f1 in namespace emptydir-wrapper-1360, will wait for the garbage collector to delete the pods @ 04/17/23 07:05:57.23
  Apr 17 07:05:57.284: INFO: Deleting ReplicationController wrapped-volume-race-97c60dfb-1ccb-4d3c-8024-8640888019f1 took: 1.996626ms
  Apr 17 07:05:57.384: INFO: Terminating ReplicationController wrapped-volume-race-97c60dfb-1ccb-4d3c-8024-8640888019f1 pods took: 100.870436ms
  STEP: Cleaning up the configMaps @ 04/17/23 07:05:58.185
  STEP: Destroying namespace "emptydir-wrapper-1360" for this suite. @ 04/17/23 07:05:58.251
â€¢ [16.987 seconds]
------------------------------
SS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:609
  STEP: Creating a kubernetes client @ 04/17/23 07:05:58.253
  Apr 17 07:05:58.253: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename security-context-test @ 04/17/23 07:05:58.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:05:58.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:05:58.258
  Apr 17 07:06:06.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-611" for this suite. @ 04/17/23 07:06:06.277
â€¢ [8.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]
test/e2e/network/ingressclass.go:266
  STEP: Creating a kubernetes client @ 04/17/23 07:06:06.279
  Apr 17 07:06:06.279: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename ingressclass @ 04/17/23 07:06:06.279
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:06:06.283
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:06:06.284
  STEP: getting /apis @ 04/17/23 07:06:06.285
  STEP: getting /apis/networking.k8s.io @ 04/17/23 07:06:06.287
  STEP: getting /apis/networking.k8s.iov1 @ 04/17/23 07:06:06.287
  STEP: creating @ 04/17/23 07:06:06.288
  STEP: getting @ 04/17/23 07:06:06.292
  STEP: listing @ 04/17/23 07:06:06.293
  STEP: watching @ 04/17/23 07:06:06.294
  Apr 17 07:06:06.294: INFO: starting watch
  STEP: patching @ 04/17/23 07:06:06.294
  STEP: updating @ 04/17/23 07:06:06.296
  Apr 17 07:06:06.297: INFO: waiting for watch events with expected annotations
  Apr 17 07:06:06.297: INFO: saw patched and updated annotations
  STEP: deleting @ 04/17/23 07:06:06.297
  STEP: deleting a collection @ 04/17/23 07:06:06.3
  Apr 17 07:06:06.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-7184" for this suite. @ 04/17/23 07:06:06.305
â€¢ [0.027 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 04/17/23 07:06:06.306
  Apr 17 07:06:06.306: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename dns @ 04/17/23 07:06:06.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:06:06.31
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:06:06.311
  STEP: Creating a test externalName service @ 04/17/23 07:06:06.312
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5604.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local; sleep 1; done
   @ 04/17/23 07:06:06.313
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5604.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local; sleep 1; done
   @ 04/17/23 07:06:06.313
  STEP: creating a pod to probe DNS @ 04/17/23 07:06:06.313
  STEP: submitting the pod to kubernetes @ 04/17/23 07:06:06.313
  STEP: retrieving the pod @ 04/17/23 07:06:08.319
  STEP: looking for the results for each expected name from probers @ 04/17/23 07:06:08.32
  Apr 17 07:06:08.323: INFO: DNS probes using dns-test-58fe96c2-31d4-4fe2-b4cf-d239fac6f6a3 succeeded

  STEP: changing the externalName to bar.example.com @ 04/17/23 07:06:08.323
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5604.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local; sleep 1; done
   @ 04/17/23 07:06:08.326
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5604.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local; sleep 1; done
   @ 04/17/23 07:06:08.326
  STEP: creating a second pod to probe DNS @ 04/17/23 07:06:08.326
  STEP: submitting the pod to kubernetes @ 04/17/23 07:06:08.326
  STEP: retrieving the pod @ 04/17/23 07:06:10.334
  STEP: looking for the results for each expected name from probers @ 04/17/23 07:06:10.335
  Apr 17 07:06:10.336: INFO: File wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local from pod  dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 17 07:06:10.337: INFO: File jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local from pod  dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 17 07:06:10.337: INFO: Lookups using dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e failed for: [wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local]

  Apr 17 07:06:15.344: INFO: File wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local from pod  dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 17 07:06:15.346: INFO: File jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local from pod  dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 17 07:06:15.346: INFO: Lookups using dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e failed for: [wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local]

  Apr 17 07:06:20.340: INFO: File wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local from pod  dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 17 07:06:20.341: INFO: File jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local from pod  dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 17 07:06:20.341: INFO: Lookups using dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e failed for: [wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local]

  Apr 17 07:06:25.343: INFO: File wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local from pod  dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 17 07:06:25.344: INFO: File jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local from pod  dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 17 07:06:25.344: INFO: Lookups using dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e failed for: [wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local]

  Apr 17 07:06:30.340: INFO: File wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local from pod  dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 17 07:06:30.341: INFO: File jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local from pod  dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 17 07:06:30.341: INFO: Lookups using dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e failed for: [wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local]

  Apr 17 07:06:35.341: INFO: File wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local from pod  dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 17 07:06:35.342: INFO: File jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local from pod  dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 17 07:06:35.342: INFO: Lookups using dns-5604/dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e failed for: [wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local]

  Apr 17 07:06:40.344: INFO: DNS probes using dns-test-44b0b7f1-bac3-4a04-be79-e10ff2cc5d4e succeeded

  STEP: changing the service to type=ClusterIP @ 04/17/23 07:06:40.344
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5604.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-5604.svc.cluster.local; sleep 1; done
   @ 04/17/23 07:06:40.348
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5604.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-5604.svc.cluster.local; sleep 1; done
   @ 04/17/23 07:06:40.348
  STEP: creating a third pod to probe DNS @ 04/17/23 07:06:40.348
  STEP: submitting the pod to kubernetes @ 04/17/23 07:06:40.349
  STEP: retrieving the pod @ 04/17/23 07:06:48.363
  STEP: looking for the results for each expected name from probers @ 04/17/23 07:06:48.364
  Apr 17 07:06:48.366: INFO: DNS probes using dns-test-48a58510-89a8-47c1-ac45-d20d4578b682 succeeded

  Apr 17 07:06:48.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 07:06:48.368
  STEP: deleting the pod @ 04/17/23 07:06:48.371
  STEP: deleting the pod @ 04/17/23 07:06:48.374
  STEP: deleting the test externalName service @ 04/17/23 07:06:48.377
  STEP: Destroying namespace "dns-5604" for this suite. @ 04/17/23 07:06:48.38
â€¢ [42.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 04/17/23 07:06:48.382
  Apr 17 07:06:48.382: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename deployment @ 04/17/23 07:06:48.382
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:06:48.386
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:06:48.386
  Apr 17 07:06:48.390: INFO: Pod name rollover-pod: Found 0 pods out of 1
  Apr 17 07:06:53.393: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/17/23 07:06:53.393
  Apr 17 07:06:53.393: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  Apr 17 07:06:55.395: INFO: Creating deployment "test-rollover-deployment"
  Apr 17 07:06:55.397: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  Apr 17 07:06:57.399: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Apr 17 07:06:57.401: INFO: Ensure that both replica sets have 1 created replica
  Apr 17 07:06:57.403: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Apr 17 07:06:57.406: INFO: Updating deployment test-rollover-deployment
  Apr 17 07:06:57.406: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  Apr 17 07:06:59.408: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Apr 17 07:06:59.410: INFO: Make sure deployment "test-rollover-deployment" is complete
  Apr 17 07:06:59.412: INFO: all replica sets need to contain the pod-template-hash label
  Apr 17 07:06:59.412: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 6, 58, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:07:01.415: INFO: all replica sets need to contain the pod-template-hash label
  Apr 17 07:07:01.415: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 6, 58, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:07:03.415: INFO: all replica sets need to contain the pod-template-hash label
  Apr 17 07:07:03.415: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 6, 58, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:07:05.416: INFO: all replica sets need to contain the pod-template-hash label
  Apr 17 07:07:05.416: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 6, 58, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:07:07.415: INFO: all replica sets need to contain the pod-template-hash label
  Apr 17 07:07:07.415: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 6, 58, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 6, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:07:09.416: INFO: 
  Apr 17 07:07:09.416: INFO: Ensure that both old replica sets have no replicas
  Apr 17 07:07:09.419: INFO: Deployment "test-rollover-deployment":
  &Deployment{ObjectMeta:{test-rollover-deployment  deployment-402  4c3e4e22-bcb0-4075-bb2c-b5b55ac4099f 50929 2 2023-04-17 07:06:55 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-17 07:06:57 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 07:07:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002da82f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-17 07:06:55 +0000 UTC,LastTransitionTime:2023-04-17 07:06:55 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-57777854c9" has successfully progressed.,LastUpdateTime:2023-04-17 07:07:08 +0000 UTC,LastTransitionTime:2023-04-17 07:06:55 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 17 07:07:09.420: INFO: New ReplicaSet "test-rollover-deployment-57777854c9" of Deployment "test-rollover-deployment":
  &ReplicaSet{ObjectMeta:{test-rollover-deployment-57777854c9  deployment-402  3e5f875f-5507-46b5-9747-3a5dc7e16e0d 50919 2 2023-04-17 07:06:57 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:57777854c9] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 4c3e4e22-bcb0-4075-bb2c-b5b55ac4099f 0xc0053c7217 0xc0053c7218}] [] [{kube-controller-manager Update apps/v1 2023-04-17 07:06:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4c3e4e22-bcb0-4075-bb2c-b5b55ac4099f\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 07:07:08 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 57777854c9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:57777854c9] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0053c72c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 17 07:07:09.420: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Apr 17 07:07:09.420: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-402  cbbaa591-ced5-433f-924c-2684f3835664 50928 2 2023-04-17 07:06:48 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 4c3e4e22-bcb0-4075-bb2c-b5b55ac4099f 0xc0053c70e7 0xc0053c70e8}] [] [{e2e.test Update apps/v1 2023-04-17 07:06:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 07:07:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4c3e4e22-bcb0-4075-bb2c-b5b55ac4099f\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-17 07:07:08 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0053c71a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 17 07:07:09.420: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-58779b56b4  deployment-402  bfeaee00-1ace-4ae4-b928-3ffa29372a8b 50887 2 2023-04-17 07:06:55 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:58779b56b4] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 4c3e4e22-bcb0-4075-bb2c-b5b55ac4099f 0xc0053c7367 0xc0053c7368}] [] [{kube-controller-manager Update apps/v1 2023-04-17 07:06:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4c3e4e22-bcb0-4075-bb2c-b5b55ac4099f\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 07:06:57 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 58779b56b4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:58779b56b4] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0053c7418 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 17 07:07:09.421: INFO: Pod "test-rollover-deployment-57777854c9-mjlrp" is available:
  &Pod{ObjectMeta:{test-rollover-deployment-57777854c9-mjlrp test-rollover-deployment-57777854c9- deployment-402  ac1b639b-f850-4453-b8b0-03f960d57115 50900 0 2023-04-17 07:06:57 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:57777854c9] map[] [{apps/v1 ReplicaSet test-rollover-deployment-57777854c9 3e5f875f-5507-46b5-9747-3a5dc7e16e0d 0xc002da87d7 0xc002da87d8}] [] [{kube-controller-manager Update v1 2023-04-17 07:06:57 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3e5f875f-5507-46b5-9747-3a5dc7e16e0d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:06:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.162\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dp8q7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dp8q7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:06:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:06:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:06:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.162,StartTime:2023-04-17 07:06:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:06:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://35137765dfa939a490f03b48c50da41dc25f8fe9f06ad5474b70e26db2f83563,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.162,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:07:09.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-402" for this suite. @ 04/17/23 07:07:09.422
â€¢ [21.043 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]
test/e2e/kubectl/kubectl.go:396
  STEP: Creating a kubernetes client @ 04/17/23 07:07:09.424
  Apr 17 07:07:09.424: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 07:07:09.425
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:07:09.429
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:07:09.43
  STEP: creating all guestbook components @ 04/17/23 07:07:09.431
  Apr 17 07:07:09.431: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Apr 17 07:07:09.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4648 create -f -'
  Apr 17 07:07:09.831: INFO: stderr: ""
  Apr 17 07:07:09.831: INFO: stdout: "service/agnhost-replica created\n"
  Apr 17 07:07:09.831: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Apr 17 07:07:09.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4648 create -f -'
  Apr 17 07:07:09.990: INFO: stderr: ""
  Apr 17 07:07:09.990: INFO: stdout: "service/agnhost-primary created\n"
  Apr 17 07:07:09.990: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Apr 17 07:07:09.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4648 create -f -'
  Apr 17 07:07:10.151: INFO: stderr: ""
  Apr 17 07:07:10.151: INFO: stdout: "service/frontend created\n"
  Apr 17 07:07:10.151: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.43
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Apr 17 07:07:10.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4648 create -f -'
  Apr 17 07:07:10.291: INFO: stderr: ""
  Apr 17 07:07:10.291: INFO: stdout: "deployment.apps/frontend created\n"
  Apr 17 07:07:10.291: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.43
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 17 07:07:10.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4648 create -f -'
  Apr 17 07:07:10.417: INFO: stderr: ""
  Apr 17 07:07:10.417: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Apr 17 07:07:10.417: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.43
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 17 07:07:10.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4648 create -f -'
  Apr 17 07:07:10.540: INFO: stderr: ""
  Apr 17 07:07:10.540: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 04/17/23 07:07:10.54
  Apr 17 07:07:10.540: INFO: Waiting for all frontend pods to be Running.
  Apr 17 07:07:15.594: INFO: Waiting for frontend to serve content.
  Apr 17 07:07:15.599: INFO: Trying to add a new entry to the guestbook.
  Apr 17 07:07:15.604: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 04/17/23 07:07:15.606
  Apr 17 07:07:15.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4648 delete --grace-period=0 --force -f -'
  Apr 17 07:07:15.651: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 17 07:07:15.651: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 04/17/23 07:07:15.651
  Apr 17 07:07:15.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4648 delete --grace-period=0 --force -f -'
  Apr 17 07:07:15.692: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 17 07:07:15.692: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/17/23 07:07:15.692
  Apr 17 07:07:15.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4648 delete --grace-period=0 --force -f -'
  Apr 17 07:07:15.735: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 17 07:07:15.735: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/17/23 07:07:15.735
  Apr 17 07:07:15.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4648 delete --grace-period=0 --force -f -'
  Apr 17 07:07:15.775: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 17 07:07:15.775: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/17/23 07:07:15.775
  Apr 17 07:07:15.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4648 delete --grace-period=0 --force -f -'
  Apr 17 07:07:15.815: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 17 07:07:15.815: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/17/23 07:07:15.815
  Apr 17 07:07:15.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4648 delete --grace-period=0 --force -f -'
  Apr 17 07:07:15.856: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 17 07:07:15.856: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Apr 17 07:07:15.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4648" for this suite. @ 04/17/23 07:07:15.857
â€¢ [6.435 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance]
test/e2e/apps/job.go:485
  STEP: Creating a kubernetes client @ 04/17/23 07:07:15.859
  Apr 17 07:07:15.859: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename job @ 04/17/23 07:07:15.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:07:15.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:07:15.864
  STEP: Creating a job @ 04/17/23 07:07:15.866
  STEP: Ensuring active pods == parallelism @ 04/17/23 07:07:15.867
  STEP: delete a job @ 04/17/23 07:07:17.87
  STEP: deleting Job.batch foo in namespace job-5533, will wait for the garbage collector to delete the pods @ 04/17/23 07:07:17.87
  Apr 17 07:07:17.924: INFO: Deleting Job.batch foo took: 1.811279ms
  Apr 17 07:07:18.024: INFO: Terminating Job.batch foo pods took: 100.757372ms
  STEP: Ensuring job was deleted @ 04/17/23 07:07:51.325
  Apr 17 07:07:51.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5533" for this suite. @ 04/17/23 07:07:51.328
â€¢ [35.470 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:528
  STEP: Creating a kubernetes client @ 04/17/23 07:07:51.33
  Apr 17 07:07:51.330: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename security-context-test @ 04/17/23 07:07:51.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:07:51.336
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:07:51.337
  Apr 17 07:07:55.354: INFO: Got logs for pod "busybox-privileged-false-fb797dcb-8d37-4476-9ec0-d8119439f083": "ip: RTNETLINK answers: Operation not permitted\n"
  Apr 17 07:07:55.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-1867" for this suite. @ 04/17/23 07:07:55.356
â€¢ [4.027 seconds]
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:129
  STEP: Creating a kubernetes client @ 04/17/23 07:07:55.357
  Apr 17 07:07:55.357: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename security-context @ 04/17/23 07:07:55.358
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:07:55.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:07:55.363
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/17/23 07:07:55.364
  STEP: Saw pod success @ 04/17/23 07:07:59.372
  Apr 17 07:07:59.373: INFO: Trying to get logs from node c3-worker pod security-context-d27220ea-4837-4021-9413-7c8062de5ccf container test-container: <nil>
  STEP: delete the pod @ 04/17/23 07:07:59.376
  Apr 17 07:07:59.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-5159" for this suite. @ 04/17/23 07:07:59.381
â€¢ [4.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 04/17/23 07:07:59.383
  Apr 17 07:07:59.383: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename endpointslicemirroring @ 04/17/23 07:07:59.384
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:07:59.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:07:59.389
  STEP: mirroring a new custom Endpoint @ 04/17/23 07:07:59.393
  Apr 17 07:07:59.395: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  STEP: mirroring an update to a custom Endpoint @ 04/17/23 07:08:01.397
  Apr 17 07:08:01.399: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  STEP: mirroring deletion of a custom Endpoint @ 04/17/23 07:08:03.402
  Apr 17 07:08:03.404: INFO: Waiting for 0 EndpointSlices to exist, got 1
  Apr 17 07:08:05.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-7135" for this suite. @ 04/17/23 07:08:05.407
â€¢ [6.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]
test/e2e/apimachinery/garbage_collector.go:379
  STEP: Creating a kubernetes client @ 04/17/23 07:08:05.41
  Apr 17 07:08:05.410: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename gc @ 04/17/23 07:08:05.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:08:05.414
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:08:05.416
  STEP: create the rc @ 04/17/23 07:08:05.418
  W0417 07:08:05.419912      30 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 04/17/23 07:08:11.422
  STEP: wait for the rc to be deleted @ 04/17/23 07:08:11.425
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 04/17/23 07:08:16.426
  STEP: Gathering metrics @ 04/17/23 07:08:46.433
  Apr 17 07:08:46.486: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 17 07:08:46.486: INFO: Deleting pod "simpletest.rc-22n76" in namespace "gc-1756"
  Apr 17 07:08:46.490: INFO: Deleting pod "simpletest.rc-29gr6" in namespace "gc-1756"
  Apr 17 07:08:46.493: INFO: Deleting pod "simpletest.rc-2l89r" in namespace "gc-1756"
  Apr 17 07:08:46.495: INFO: Deleting pod "simpletest.rc-2r6jk" in namespace "gc-1756"
  Apr 17 07:08:46.499: INFO: Deleting pod "simpletest.rc-2rtpr" in namespace "gc-1756"
  Apr 17 07:08:46.501: INFO: Deleting pod "simpletest.rc-2txpd" in namespace "gc-1756"
  Apr 17 07:08:46.504: INFO: Deleting pod "simpletest.rc-46gvp" in namespace "gc-1756"
  Apr 17 07:08:46.507: INFO: Deleting pod "simpletest.rc-4qr94" in namespace "gc-1756"
  Apr 17 07:08:46.510: INFO: Deleting pod "simpletest.rc-4wsjx" in namespace "gc-1756"
  Apr 17 07:08:46.512: INFO: Deleting pod "simpletest.rc-6626k" in namespace "gc-1756"
  Apr 17 07:08:46.515: INFO: Deleting pod "simpletest.rc-6fjmh" in namespace "gc-1756"
  Apr 17 07:08:46.518: INFO: Deleting pod "simpletest.rc-6l7z2" in namespace "gc-1756"
  Apr 17 07:08:46.520: INFO: Deleting pod "simpletest.rc-6vs8s" in namespace "gc-1756"
  Apr 17 07:08:46.523: INFO: Deleting pod "simpletest.rc-7gxsh" in namespace "gc-1756"
  Apr 17 07:08:46.526: INFO: Deleting pod "simpletest.rc-7ljxm" in namespace "gc-1756"
  Apr 17 07:08:46.528: INFO: Deleting pod "simpletest.rc-7pfpg" in namespace "gc-1756"
  Apr 17 07:08:46.531: INFO: Deleting pod "simpletest.rc-82x7q" in namespace "gc-1756"
  Apr 17 07:08:46.533: INFO: Deleting pod "simpletest.rc-8568h" in namespace "gc-1756"
  Apr 17 07:08:46.536: INFO: Deleting pod "simpletest.rc-8bh95" in namespace "gc-1756"
  Apr 17 07:08:46.540: INFO: Deleting pod "simpletest.rc-8gzld" in namespace "gc-1756"
  Apr 17 07:08:46.542: INFO: Deleting pod "simpletest.rc-8hwvc" in namespace "gc-1756"
  Apr 17 07:08:46.545: INFO: Deleting pod "simpletest.rc-8kqgf" in namespace "gc-1756"
  Apr 17 07:08:46.547: INFO: Deleting pod "simpletest.rc-8m62g" in namespace "gc-1756"
  Apr 17 07:08:46.551: INFO: Deleting pod "simpletest.rc-8mvhm" in namespace "gc-1756"
  Apr 17 07:08:46.553: INFO: Deleting pod "simpletest.rc-8px5d" in namespace "gc-1756"
  Apr 17 07:08:46.556: INFO: Deleting pod "simpletest.rc-8tdmg" in namespace "gc-1756"
  Apr 17 07:08:46.560: INFO: Deleting pod "simpletest.rc-97mnz" in namespace "gc-1756"
  Apr 17 07:08:46.562: INFO: Deleting pod "simpletest.rc-9k9lx" in namespace "gc-1756"
  Apr 17 07:08:46.565: INFO: Deleting pod "simpletest.rc-9qcdf" in namespace "gc-1756"
  Apr 17 07:08:46.567: INFO: Deleting pod "simpletest.rc-9r9kw" in namespace "gc-1756"
  Apr 17 07:08:46.569: INFO: Deleting pod "simpletest.rc-bb9qz" in namespace "gc-1756"
  Apr 17 07:08:46.572: INFO: Deleting pod "simpletest.rc-btrwz" in namespace "gc-1756"
  Apr 17 07:08:46.574: INFO: Deleting pod "simpletest.rc-bxjcc" in namespace "gc-1756"
  Apr 17 07:08:46.576: INFO: Deleting pod "simpletest.rc-bxtzr" in namespace "gc-1756"
  Apr 17 07:08:46.579: INFO: Deleting pod "simpletest.rc-dfnbq" in namespace "gc-1756"
  Apr 17 07:08:46.582: INFO: Deleting pod "simpletest.rc-f4s7f" in namespace "gc-1756"
  Apr 17 07:08:46.584: INFO: Deleting pod "simpletest.rc-g9tq5" in namespace "gc-1756"
  Apr 17 07:08:46.590: INFO: Deleting pod "simpletest.rc-gll82" in namespace "gc-1756"
  Apr 17 07:08:46.597: INFO: Deleting pod "simpletest.rc-gqjrz" in namespace "gc-1756"
  Apr 17 07:08:46.601: INFO: Deleting pod "simpletest.rc-gr9rs" in namespace "gc-1756"
  Apr 17 07:08:46.603: INFO: Deleting pod "simpletest.rc-hbgcz" in namespace "gc-1756"
  Apr 17 07:08:46.606: INFO: Deleting pod "simpletest.rc-hhffd" in namespace "gc-1756"
  Apr 17 07:08:46.609: INFO: Deleting pod "simpletest.rc-hx4kf" in namespace "gc-1756"
  Apr 17 07:08:46.615: INFO: Deleting pod "simpletest.rc-jbb2w" in namespace "gc-1756"
  Apr 17 07:08:46.618: INFO: Deleting pod "simpletest.rc-jf99q" in namespace "gc-1756"
  Apr 17 07:08:46.621: INFO: Deleting pod "simpletest.rc-jjfc6" in namespace "gc-1756"
  Apr 17 07:08:46.624: INFO: Deleting pod "simpletest.rc-jjggl" in namespace "gc-1756"
  Apr 17 07:08:46.627: INFO: Deleting pod "simpletest.rc-jnmmp" in namespace "gc-1756"
  Apr 17 07:08:46.630: INFO: Deleting pod "simpletest.rc-k8vkp" in namespace "gc-1756"
  Apr 17 07:08:46.633: INFO: Deleting pod "simpletest.rc-k9m76" in namespace "gc-1756"
  Apr 17 07:08:46.636: INFO: Deleting pod "simpletest.rc-kqq4z" in namespace "gc-1756"
  Apr 17 07:08:46.680: INFO: Deleting pod "simpletest.rc-kzmxh" in namespace "gc-1756"
  Apr 17 07:08:46.730: INFO: Deleting pod "simpletest.rc-l5kz5" in namespace "gc-1756"
  Apr 17 07:08:46.782: INFO: Deleting pod "simpletest.rc-ll29j" in namespace "gc-1756"
  Apr 17 07:08:46.830: INFO: Deleting pod "simpletest.rc-lqc8k" in namespace "gc-1756"
  Apr 17 07:08:46.881: INFO: Deleting pod "simpletest.rc-lsqbg" in namespace "gc-1756"
  Apr 17 07:08:46.931: INFO: Deleting pod "simpletest.rc-ltx27" in namespace "gc-1756"
  Apr 17 07:08:46.980: INFO: Deleting pod "simpletest.rc-m28nn" in namespace "gc-1756"
  Apr 17 07:08:47.030: INFO: Deleting pod "simpletest.rc-m2bbg" in namespace "gc-1756"
  Apr 17 07:08:47.080: INFO: Deleting pod "simpletest.rc-m8fr8" in namespace "gc-1756"
  Apr 17 07:08:47.132: INFO: Deleting pod "simpletest.rc-ndkqh" in namespace "gc-1756"
  Apr 17 07:08:47.180: INFO: Deleting pod "simpletest.rc-nkk6m" in namespace "gc-1756"
  Apr 17 07:08:47.231: INFO: Deleting pod "simpletest.rc-nkztq" in namespace "gc-1756"
  Apr 17 07:08:47.281: INFO: Deleting pod "simpletest.rc-p7lbp" in namespace "gc-1756"
  Apr 17 07:08:47.330: INFO: Deleting pod "simpletest.rc-p9pzd" in namespace "gc-1756"
  Apr 17 07:08:47.381: INFO: Deleting pod "simpletest.rc-pcs6w" in namespace "gc-1756"
  Apr 17 07:08:47.434: INFO: Deleting pod "simpletest.rc-pxpmw" in namespace "gc-1756"
  Apr 17 07:08:47.482: INFO: Deleting pod "simpletest.rc-q6c2c" in namespace "gc-1756"
  Apr 17 07:08:47.537: INFO: Deleting pod "simpletest.rc-qfv7m" in namespace "gc-1756"
  Apr 17 07:08:47.583: INFO: Deleting pod "simpletest.rc-qpntb" in namespace "gc-1756"
  Apr 17 07:08:47.630: INFO: Deleting pod "simpletest.rc-qsvt2" in namespace "gc-1756"
  Apr 17 07:08:47.680: INFO: Deleting pod "simpletest.rc-rgttd" in namespace "gc-1756"
  Apr 17 07:08:47.731: INFO: Deleting pod "simpletest.rc-rhm5p" in namespace "gc-1756"
  Apr 17 07:08:47.780: INFO: Deleting pod "simpletest.rc-s67nb" in namespace "gc-1756"
  Apr 17 07:08:47.830: INFO: Deleting pod "simpletest.rc-scvfb" in namespace "gc-1756"
  Apr 17 07:08:47.880: INFO: Deleting pod "simpletest.rc-spnx5" in namespace "gc-1756"
  Apr 17 07:08:47.930: INFO: Deleting pod "simpletest.rc-sw7r2" in namespace "gc-1756"
  Apr 17 07:08:47.980: INFO: Deleting pod "simpletest.rc-szhjh" in namespace "gc-1756"
  Apr 17 07:08:48.031: INFO: Deleting pod "simpletest.rc-t72kv" in namespace "gc-1756"
  Apr 17 07:08:48.080: INFO: Deleting pod "simpletest.rc-tpzrp" in namespace "gc-1756"
  Apr 17 07:08:48.130: INFO: Deleting pod "simpletest.rc-twb2n" in namespace "gc-1756"
  Apr 17 07:08:48.181: INFO: Deleting pod "simpletest.rc-vb5t7" in namespace "gc-1756"
  Apr 17 07:08:48.230: INFO: Deleting pod "simpletest.rc-w2wsj" in namespace "gc-1756"
  Apr 17 07:08:48.281: INFO: Deleting pod "simpletest.rc-w65s5" in namespace "gc-1756"
  Apr 17 07:08:48.330: INFO: Deleting pod "simpletest.rc-w7468" in namespace "gc-1756"
  Apr 17 07:08:48.380: INFO: Deleting pod "simpletest.rc-wc5tq" in namespace "gc-1756"
  Apr 17 07:08:48.432: INFO: Deleting pod "simpletest.rc-wpl9v" in namespace "gc-1756"
  Apr 17 07:08:48.480: INFO: Deleting pod "simpletest.rc-wrgtb" in namespace "gc-1756"
  Apr 17 07:08:48.535: INFO: Deleting pod "simpletest.rc-wwswc" in namespace "gc-1756"
  Apr 17 07:08:48.580: INFO: Deleting pod "simpletest.rc-x2rwv" in namespace "gc-1756"
  Apr 17 07:08:48.630: INFO: Deleting pod "simpletest.rc-x5wps" in namespace "gc-1756"
  Apr 17 07:08:48.680: INFO: Deleting pod "simpletest.rc-x8gbg" in namespace "gc-1756"
  Apr 17 07:08:48.731: INFO: Deleting pod "simpletest.rc-xpncj" in namespace "gc-1756"
  Apr 17 07:08:48.780: INFO: Deleting pod "simpletest.rc-xr8mz" in namespace "gc-1756"
  Apr 17 07:08:48.831: INFO: Deleting pod "simpletest.rc-xvv6t" in namespace "gc-1756"
  Apr 17 07:08:48.880: INFO: Deleting pod "simpletest.rc-z7zh5" in namespace "gc-1756"
  Apr 17 07:08:48.930: INFO: Deleting pod "simpletest.rc-zlx9l" in namespace "gc-1756"
  Apr 17 07:08:48.979: INFO: Deleting pod "simpletest.rc-zqpfl" in namespace "gc-1756"
  Apr 17 07:08:49.031: INFO: Deleting pod "simpletest.rc-zsfc5" in namespace "gc-1756"
  Apr 17 07:08:49.080: INFO: Deleting pod "simpletest.rc-zthwc" in namespace "gc-1756"
  Apr 17 07:08:49.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1756" for this suite. @ 04/17/23 07:08:49.179
â€¢ [43.819 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 04/17/23 07:08:49.23
  Apr 17 07:08:49.230: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename dns @ 04/17/23 07:08:49.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:08:49.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:08:49.236
  STEP: Creating a test headless service @ 04/17/23 07:08:49.237
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4006 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4006;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4006 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4006;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4006.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4006.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4006.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4006.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4006.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4006.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4006.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4006.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4006.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4006.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4006.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4006.svc;check="$$(dig +notcp +noall +answer +search 183.235.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.235.183_udp@PTR;check="$$(dig +tcp +noall +answer +search 183.235.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.235.183_tcp@PTR;sleep 1; done
   @ 04/17/23 07:08:49.242
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4006 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4006;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4006 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4006;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4006.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4006.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4006.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4006.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4006.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4006.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4006.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4006.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4006.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4006.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4006.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4006.svc;check="$$(dig +notcp +noall +answer +search 183.235.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.235.183_udp@PTR;check="$$(dig +tcp +noall +answer +search 183.235.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.235.183_tcp@PTR;sleep 1; done
   @ 04/17/23 07:08:49.242
  STEP: creating a pod to probe DNS @ 04/17/23 07:08:49.242
  STEP: submitting the pod to kubernetes @ 04/17/23 07:08:49.242
  STEP: retrieving the pod @ 04/17/23 07:08:51.248
  STEP: looking for the results for each expected name from probers @ 04/17/23 07:08:51.249
  Apr 17 07:08:51.250: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:51.252: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:51.252: INFO: Unable to read wheezy_udp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:51.253: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:51.254: INFO: Unable to read wheezy_udp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:51.255: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:51.262: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:51.263: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:51.264: INFO: Unable to read jessie_udp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:51.265: INFO: Unable to read jessie_tcp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:51.266: INFO: Unable to read jessie_udp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:51.267: INFO: Unable to read jessie_tcp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:51.271: INFO: Lookups using dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4006 wheezy_tcp@dns-test-service.dns-4006 wheezy_udp@dns-test-service.dns-4006.svc wheezy_tcp@dns-test-service.dns-4006.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4006 jessie_tcp@dns-test-service.dns-4006 jessie_udp@dns-test-service.dns-4006.svc jessie_tcp@dns-test-service.dns-4006.svc]

  Apr 17 07:08:56.274: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:56.275: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:56.276: INFO: Unable to read wheezy_udp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:56.277: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:56.278: INFO: Unable to read wheezy_udp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:56.279: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:56.284: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:56.285: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:56.286: INFO: Unable to read jessie_udp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:56.287: INFO: Unable to read jessie_tcp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:56.287: INFO: Unable to read jessie_udp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:56.288: INFO: Unable to read jessie_tcp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:08:56.293: INFO: Lookups using dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4006 wheezy_tcp@dns-test-service.dns-4006 wheezy_udp@dns-test-service.dns-4006.svc wheezy_tcp@dns-test-service.dns-4006.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4006 jessie_tcp@dns-test-service.dns-4006 jessie_udp@dns-test-service.dns-4006.svc jessie_tcp@dns-test-service.dns-4006.svc]

  Apr 17 07:09:01.273: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:01.274: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:01.275: INFO: Unable to read wheezy_udp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:01.276: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:01.277: INFO: Unable to read wheezy_udp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:01.278: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:01.285: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:01.286: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:01.286: INFO: Unable to read jessie_udp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:01.287: INFO: Unable to read jessie_tcp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:01.288: INFO: Unable to read jessie_udp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:01.289: INFO: Unable to read jessie_tcp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:01.294: INFO: Lookups using dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4006 wheezy_tcp@dns-test-service.dns-4006 wheezy_udp@dns-test-service.dns-4006.svc wheezy_tcp@dns-test-service.dns-4006.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4006 jessie_tcp@dns-test-service.dns-4006 jessie_udp@dns-test-service.dns-4006.svc jessie_tcp@dns-test-service.dns-4006.svc]

  Apr 17 07:09:06.273: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:06.274: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:06.275: INFO: Unable to read wheezy_udp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:06.276: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:06.277: INFO: Unable to read wheezy_udp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:06.278: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:06.284: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:06.284: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:06.285: INFO: Unable to read jessie_udp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:06.286: INFO: Unable to read jessie_tcp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:06.287: INFO: Unable to read jessie_udp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:06.288: INFO: Unable to read jessie_tcp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:06.292: INFO: Lookups using dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4006 wheezy_tcp@dns-test-service.dns-4006 wheezy_udp@dns-test-service.dns-4006.svc wheezy_tcp@dns-test-service.dns-4006.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4006 jessie_tcp@dns-test-service.dns-4006 jessie_udp@dns-test-service.dns-4006.svc jessie_tcp@dns-test-service.dns-4006.svc]

  Apr 17 07:09:11.274: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:11.275: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:11.276: INFO: Unable to read wheezy_udp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:11.277: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:11.278: INFO: Unable to read wheezy_udp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:11.279: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:11.285: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:11.286: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:11.287: INFO: Unable to read jessie_udp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:11.288: INFO: Unable to read jessie_tcp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:11.288: INFO: Unable to read jessie_udp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:11.289: INFO: Unable to read jessie_tcp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:11.294: INFO: Lookups using dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4006 wheezy_tcp@dns-test-service.dns-4006 wheezy_udp@dns-test-service.dns-4006.svc wheezy_tcp@dns-test-service.dns-4006.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4006 jessie_tcp@dns-test-service.dns-4006 jessie_udp@dns-test-service.dns-4006.svc jessie_tcp@dns-test-service.dns-4006.svc]

  Apr 17 07:09:16.274: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:16.275: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:16.277: INFO: Unable to read wheezy_udp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:16.278: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:16.279: INFO: Unable to read wheezy_udp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:16.279: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:16.286: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:16.287: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:16.288: INFO: Unable to read jessie_udp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:16.289: INFO: Unable to read jessie_tcp@dns-test-service.dns-4006 from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:16.290: INFO: Unable to read jessie_udp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:16.290: INFO: Unable to read jessie_tcp@dns-test-service.dns-4006.svc from pod dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b: the server could not find the requested resource (get pods dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b)
  Apr 17 07:09:16.296: INFO: Lookups using dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4006 wheezy_tcp@dns-test-service.dns-4006 wheezy_udp@dns-test-service.dns-4006.svc wheezy_tcp@dns-test-service.dns-4006.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4006 jessie_tcp@dns-test-service.dns-4006 jessie_udp@dns-test-service.dns-4006.svc jessie_tcp@dns-test-service.dns-4006.svc]

  Apr 17 07:09:21.295: INFO: DNS probes using dns-4006/dns-test-2bf8e9de-c472-4144-9f1a-ac8a878bba1b succeeded

  Apr 17 07:09:21.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 07:09:21.296
  STEP: deleting the test service @ 04/17/23 07:09:21.299
  STEP: deleting the test headless service @ 04/17/23 07:09:21.303
  STEP: Destroying namespace "dns-4006" for this suite. @ 04/17/23 07:09:21.306
â€¢ [32.078 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 04/17/23 07:09:21.308
  Apr 17 07:09:21.308: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename conformance-tests @ 04/17/23 07:09:21.308
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:09:21.312
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:09:21.313
  STEP: Getting node addresses @ 04/17/23 07:09:21.314
  Apr 17 07:09:21.314: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Apr 17 07:09:21.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-4022" for this suite. @ 04/17/23 07:09:21.317
â€¢ [0.010 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 04/17/23 07:09:21.319
  Apr 17 07:09:21.319: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/17/23 07:09:21.319
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:09:21.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:09:21.323
  Apr 17 07:09:21.324: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/17/23 07:09:22.516
  Apr 17 07:09:22.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-9985 --namespace=crd-publish-openapi-9985 create -f -'
  Apr 17 07:09:24.897: INFO: stderr: ""
  Apr 17 07:09:24.897: INFO: stdout: "e2e-test-crd-publish-openapi-9042-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 17 07:09:24.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-9985 --namespace=crd-publish-openapi-9985 delete e2e-test-crd-publish-openapi-9042-crds test-cr'
  Apr 17 07:09:24.940: INFO: stderr: ""
  Apr 17 07:09:24.940: INFO: stdout: "e2e-test-crd-publish-openapi-9042-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Apr 17 07:09:24.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-9985 --namespace=crd-publish-openapi-9985 apply -f -'
  Apr 17 07:09:25.059: INFO: stderr: ""
  Apr 17 07:09:25.059: INFO: stdout: "e2e-test-crd-publish-openapi-9042-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 17 07:09:25.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-9985 --namespace=crd-publish-openapi-9985 delete e2e-test-crd-publish-openapi-9042-crds test-cr'
  Apr 17 07:09:25.102: INFO: stderr: ""
  Apr 17 07:09:25.102: INFO: stdout: "e2e-test-crd-publish-openapi-9042-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/17/23 07:09:25.102
  Apr 17 07:09:25.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-9985 explain e2e-test-crd-publish-openapi-9042-crds'
  Apr 17 07:09:25.221: INFO: stderr: ""
  Apr 17 07:09:25.221: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-9042-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Apr 17 07:09:26.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9985" for this suite. @ 04/17/23 07:09:26.425
â€¢ [5.108 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 04/17/23 07:09:26.427
  Apr 17 07:09:26.427: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/17/23 07:09:26.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:09:26.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:09:26.432
  STEP: set up a multi version CRD @ 04/17/23 07:09:26.433
  Apr 17 07:09:26.433: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: rename a version @ 04/17/23 07:09:29.584
  STEP: check the new version name is served @ 04/17/23 07:09:29.591
  STEP: check the old version name is removed @ 04/17/23 07:09:30.28
  STEP: check the other version is not changed @ 04/17/23 07:09:30.933
  Apr 17 07:09:33.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7274" for this suite. @ 04/17/23 07:09:33.425
â€¢ [7.000 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 04/17/23 07:09:33.428
  Apr 17 07:09:33.428: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:09:33.429
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:09:33.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:09:33.434
  STEP: Creating secret with name projected-secret-test-3446cac4-5b51-457b-93d5-98e1069e936f @ 04/17/23 07:09:33.435
  STEP: Creating a pod to test consume secrets @ 04/17/23 07:09:33.436
  STEP: Saw pod success @ 04/17/23 07:09:37.446
  Apr 17 07:09:37.447: INFO: Trying to get logs from node c3-worker pod pod-projected-secrets-c34bf4f5-821d-4105-8cc1-b7390b4143f7 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 07:09:37.455
  Apr 17 07:09:37.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5815" for this suite. @ 04/17/23 07:09:37.46
â€¢ [4.034 seconds]
------------------------------
SSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
test/e2e/network/endpointslice.go:207
  STEP: Creating a kubernetes client @ 04/17/23 07:09:37.462
  Apr 17 07:09:37.462: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename endpointslice @ 04/17/23 07:09:37.463
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:09:37.466
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:09:37.467
  STEP: referencing a single matching pod @ 04/17/23 07:09:42.483
  STEP: referencing matching pods with named port @ 04/17/23 07:09:47.487
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 04/17/23 07:09:52.491
  STEP: recreating EndpointSlices after they've been deleted @ 04/17/23 07:09:57.495
  Apr 17 07:09:57.501: INFO: EndpointSlice for Service endpointslice-94/example-named-port not found
  Apr 17 07:10:07.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-94" for this suite. @ 04/17/23 07:10:07.507
â€¢ [30.047 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 04/17/23 07:10:07.509
  Apr 17 07:10:07.509: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:10:07.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:10:07.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:10:07.515
  STEP: Creating projection with secret that has name projected-secret-test-d6f779c3-e398-4ca7-938e-64068f2e34b9 @ 04/17/23 07:10:07.517
  STEP: Creating a pod to test consume secrets @ 04/17/23 07:10:07.518
  STEP: Saw pod success @ 04/17/23 07:10:11.525
  Apr 17 07:10:11.526: INFO: Trying to get logs from node c3-worker pod pod-projected-secrets-62bda35c-e73c-4c1f-9522-96098301e4db container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 07:10:11.529
  Apr 17 07:10:11.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2760" for this suite. @ 04/17/23 07:10:11.534
â€¢ [4.026 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]
test/e2e/kubectl/kubectl.go:1574
  STEP: Creating a kubernetes client @ 04/17/23 07:10:11.535
  Apr 17 07:10:11.535: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 07:10:11.536
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:10:11.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:10:11.54
  STEP: creating the pod @ 04/17/23 07:10:11.541
  Apr 17 07:10:11.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-9198 create -f -'
  Apr 17 07:10:11.929: INFO: stderr: ""
  Apr 17 07:10:11.929: INFO: stdout: "pod/pause created\n"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 04/17/23 07:10:13.934
  Apr 17 07:10:13.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-9198 label pods pause testing-label=testing-label-value'
  Apr 17 07:10:13.979: INFO: stderr: ""
  Apr 17 07:10:13.979: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 04/17/23 07:10:13.979
  Apr 17 07:10:13.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-9198 get pod pause -L testing-label'
  Apr 17 07:10:14.018: INFO: stderr: ""
  Apr 17 07:10:14.018: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 04/17/23 07:10:14.018
  Apr 17 07:10:14.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-9198 label pods pause testing-label-'
  Apr 17 07:10:14.061: INFO: stderr: ""
  Apr 17 07:10:14.061: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 04/17/23 07:10:14.061
  Apr 17 07:10:14.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-9198 get pod pause -L testing-label'
  Apr 17 07:10:14.100: INFO: stderr: ""
  Apr 17 07:10:14.100: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
  STEP: using delete to clean up resources @ 04/17/23 07:10:14.1
  Apr 17 07:10:14.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-9198 delete --grace-period=0 --force -f -'
  Apr 17 07:10:14.143: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 17 07:10:14.143: INFO: stdout: "pod \"pause\" force deleted\n"
  Apr 17 07:10:14.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-9198 get rc,svc -l name=pause --no-headers'
  Apr 17 07:10:14.186: INFO: stderr: "No resources found in kubectl-9198 namespace.\n"
  Apr 17 07:10:14.186: INFO: stdout: ""
  Apr 17 07:10:14.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-9198 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 17 07:10:14.225: INFO: stderr: ""
  Apr 17 07:10:14.225: INFO: stdout: ""
  Apr 17 07:10:14.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9198" for this suite. @ 04/17/23 07:10:14.227
â€¢ [2.693 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 04/17/23 07:10:14.229
  Apr 17 07:10:14.229: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename hostport @ 04/17/23 07:10:14.229
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:10:14.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:10:14.234
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 04/17/23 07:10:14.236
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.18.0.3 on the node which pod1 resides and expect scheduled @ 04/17/23 07:10:16.242
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.18.0.3 but use UDP protocol on the node which pod2 resides @ 04/17/23 07:10:28.26
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 04/17/23 07:10:32.272
  Apr 17 07:10:32.272: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.18.0.3 http://127.0.0.1:54323/hostname] Namespace:hostport-2212 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:10:32.272: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:10:32.272: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:10:32.272: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-2212/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.18.0.3+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.18.0.3, port: 54323 @ 04/17/23 07:10:32.333
  Apr 17 07:10:32.333: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.18.0.3:54323/hostname] Namespace:hostport-2212 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:10:32.333: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:10:32.333: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:10:32.333: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-2212/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.18.0.3%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.18.0.3, port: 54323 UDP @ 04/17/23 07:10:32.378
  Apr 17 07:10:32.378: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.18.0.3 54323] Namespace:hostport-2212 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:10:32.378: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:10:32.379: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:10:32.379: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-2212/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.18.0.3+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  Apr 17 07:10:37.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-2212" for this suite. @ 04/17/23 07:10:37.407
â€¢ [23.181 seconds]
------------------------------
SS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 04/17/23 07:10:37.41
  Apr 17 07:10:37.410: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename cronjob @ 04/17/23 07:10:37.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:10:37.414
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:10:37.415
  STEP: Creating a ReplaceConcurrent cronjob @ 04/17/23 07:10:37.416
  STEP: Ensuring a job is scheduled @ 04/17/23 07:10:37.418
  STEP: Ensuring exactly one is scheduled @ 04/17/23 07:11:01.42
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/17/23 07:11:01.421
  STEP: Ensuring the job is replaced with a new one @ 04/17/23 07:11:01.422
  STEP: Removing cronjob @ 04/17/23 07:12:01.425
  Apr 17 07:12:01.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9891" for this suite. @ 04/17/23 07:12:01.427
â€¢ [84.019 seconds]
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 04/17/23 07:12:01.429
  Apr 17 07:12:01.429: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 07:12:01.429
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:12:01.433
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:12:01.434
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-3232 @ 04/17/23 07:12:01.435
  STEP: changing the ExternalName service to type=ClusterIP @ 04/17/23 07:12:01.437
  STEP: creating replication controller externalname-service in namespace services-3232 @ 04/17/23 07:12:01.443
  I0417 07:12:01.445142      30 runners.go:194] Created replication controller with name: externalname-service, namespace: services-3232, replica count: 2
  I0417 07:12:04.497317      30 runners.go:194] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 17 07:12:04.497: INFO: Creating new exec pod
  Apr 17 07:12:07.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-3232 exec execpodd8tgw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 17 07:12:07.600: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 17 07:12:07.600: INFO: stdout: "externalname-service-zmljp"
  Apr 17 07:12:07.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-3232 exec execpodd8tgw -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.213.146 80'
  Apr 17 07:12:07.725: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.213.146 80\nConnection to 10.96.213.146 80 port [tcp/http] succeeded!\n"
  Apr 17 07:12:07.725: INFO: stdout: "externalname-service-zmljp"
  Apr 17 07:12:07.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 17 07:12:07.726: INFO: Cleaning up the ExternalName to ClusterIP test service
  STEP: Destroying namespace "services-3232" for this suite. @ 04/17/23 07:12:07.731
â€¢ [6.304 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 04/17/23 07:12:07.733
  Apr 17 07:12:07.733: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename cronjob @ 04/17/23 07:12:07.733
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:12:07.737
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:12:07.738
  STEP: Creating a suspended cronjob @ 04/17/23 07:12:07.739
  STEP: Ensuring no jobs are scheduled @ 04/17/23 07:12:07.741
  STEP: Ensuring no job exists by listing jobs explicitly @ 04/17/23 07:17:07.745
  STEP: Removing cronjob @ 04/17/23 07:17:07.746
  Apr 17 07:17:07.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1940" for this suite. @ 04/17/23 07:17:07.749
â€¢ [300.017 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:354
  STEP: Creating a kubernetes client @ 04/17/23 07:17:07.751
  Apr 17 07:17:07.751: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 07:17:07.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:17:07.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:17:07.756
  STEP: creating a replication controller @ 04/17/23 07:17:07.758
  Apr 17 07:17:07.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 create -f -'
  Apr 17 07:17:07.899: INFO: stderr: ""
  Apr 17 07:17:07.899: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/17/23 07:17:07.899
  Apr 17 07:17:07.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 17 07:17:07.939: INFO: stderr: ""
  Apr 17 07:17:07.939: INFO: stdout: "update-demo-nautilus-74lz5 update-demo-nautilus-kfjj9 "
  Apr 17 07:17:07.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods update-demo-nautilus-74lz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 17 07:17:07.978: INFO: stderr: ""
  Apr 17 07:17:07.978: INFO: stdout: ""
  Apr 17 07:17:07.978: INFO: update-demo-nautilus-74lz5 is created but not running
  Apr 17 07:17:12.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 17 07:17:13.021: INFO: stderr: ""
  Apr 17 07:17:13.021: INFO: stdout: "update-demo-nautilus-74lz5 update-demo-nautilus-kfjj9 "
  Apr 17 07:17:13.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods update-demo-nautilus-74lz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 17 07:17:13.062: INFO: stderr: ""
  Apr 17 07:17:13.062: INFO: stdout: "true"
  Apr 17 07:17:13.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods update-demo-nautilus-74lz5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 17 07:17:13.102: INFO: stderr: ""
  Apr 17 07:17:13.102: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 17 07:17:13.102: INFO: validating pod update-demo-nautilus-74lz5
  Apr 17 07:17:13.104: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 17 07:17:13.104: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 17 07:17:13.104: INFO: update-demo-nautilus-74lz5 is verified up and running
  Apr 17 07:17:13.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods update-demo-nautilus-kfjj9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 17 07:17:13.143: INFO: stderr: ""
  Apr 17 07:17:13.143: INFO: stdout: "true"
  Apr 17 07:17:13.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods update-demo-nautilus-kfjj9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 17 07:17:13.182: INFO: stderr: ""
  Apr 17 07:17:13.182: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 17 07:17:13.182: INFO: validating pod update-demo-nautilus-kfjj9
  Apr 17 07:17:13.184: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 17 07:17:13.184: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 17 07:17:13.184: INFO: update-demo-nautilus-kfjj9 is verified up and running
  STEP: scaling down the replication controller @ 04/17/23 07:17:13.184
  Apr 17 07:17:13.184: INFO: scanned /root for discovery docs: <nil>
  Apr 17 07:17:13.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  Apr 17 07:17:14.231: INFO: stderr: ""
  Apr 17 07:17:14.231: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/17/23 07:17:14.231
  Apr 17 07:17:14.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 17 07:17:14.272: INFO: stderr: ""
  Apr 17 07:17:14.272: INFO: stdout: "update-demo-nautilus-74lz5 "
  Apr 17 07:17:14.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods update-demo-nautilus-74lz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 17 07:17:14.311: INFO: stderr: ""
  Apr 17 07:17:14.311: INFO: stdout: "true"
  Apr 17 07:17:14.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods update-demo-nautilus-74lz5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 17 07:17:14.351: INFO: stderr: ""
  Apr 17 07:17:14.351: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 17 07:17:14.351: INFO: validating pod update-demo-nautilus-74lz5
  Apr 17 07:17:14.352: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 17 07:17:14.352: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 17 07:17:14.352: INFO: update-demo-nautilus-74lz5 is verified up and running
  STEP: scaling up the replication controller @ 04/17/23 07:17:14.352
  Apr 17 07:17:14.353: INFO: scanned /root for discovery docs: <nil>
  Apr 17 07:17:14.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  Apr 17 07:17:15.400: INFO: stderr: ""
  Apr 17 07:17:15.400: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/17/23 07:17:15.4
  Apr 17 07:17:15.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 17 07:17:15.443: INFO: stderr: ""
  Apr 17 07:17:15.443: INFO: stdout: "update-demo-nautilus-74lz5 update-demo-nautilus-bbn5x "
  Apr 17 07:17:15.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods update-demo-nautilus-74lz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 17 07:17:15.483: INFO: stderr: ""
  Apr 17 07:17:15.483: INFO: stdout: "true"
  Apr 17 07:17:15.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods update-demo-nautilus-74lz5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 17 07:17:15.523: INFO: stderr: ""
  Apr 17 07:17:15.523: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 17 07:17:15.523: INFO: validating pod update-demo-nautilus-74lz5
  Apr 17 07:17:15.524: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 17 07:17:15.524: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 17 07:17:15.524: INFO: update-demo-nautilus-74lz5 is verified up and running
  Apr 17 07:17:15.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods update-demo-nautilus-bbn5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 17 07:17:15.563: INFO: stderr: ""
  Apr 17 07:17:15.563: INFO: stdout: "true"
  Apr 17 07:17:15.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods update-demo-nautilus-bbn5x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 17 07:17:15.603: INFO: stderr: ""
  Apr 17 07:17:15.603: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 17 07:17:15.603: INFO: validating pod update-demo-nautilus-bbn5x
  Apr 17 07:17:15.605: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 17 07:17:15.605: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 17 07:17:15.605: INFO: update-demo-nautilus-bbn5x is verified up and running
  STEP: using delete to clean up resources @ 04/17/23 07:17:15.605
  Apr 17 07:17:15.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 delete --grace-period=0 --force -f -'
  Apr 17 07:17:15.646: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 17 07:17:15.646: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 17 07:17:15.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get rc,svc -l name=update-demo --no-headers'
  Apr 17 07:17:15.688: INFO: stderr: "No resources found in kubectl-2024 namespace.\n"
  Apr 17 07:17:15.688: INFO: stdout: ""
  Apr 17 07:17:15.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-2024 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 17 07:17:15.729: INFO: stderr: ""
  Apr 17 07:17:15.729: INFO: stdout: ""
  Apr 17 07:17:15.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2024" for this suite. @ 04/17/23 07:17:15.731
â€¢ [7.981 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:262
  STEP: Creating a kubernetes client @ 04/17/23 07:17:15.733
  Apr 17 07:17:15.733: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:17:15.733
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:17:15.737
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:17:15.738
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 07:17:15.739
  STEP: Saw pod success @ 04/17/23 07:17:19.748
  Apr 17 07:17:19.750: INFO: Trying to get logs from node c3-worker2 pod downwardapi-volume-5acd4e57-5b10-4eec-9b89-50ca30c9c9a4 container client-container: <nil>
  STEP: delete the pod @ 04/17/23 07:17:19.759
  Apr 17 07:17:19.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-47" for this suite. @ 04/17/23 07:17:19.764
â€¢ [4.033 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:321
  STEP: Creating a kubernetes client @ 04/17/23 07:17:19.766
  Apr 17 07:17:19.766: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename gc @ 04/17/23 07:17:19.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:17:19.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:17:19.772
  STEP: create the rc @ 04/17/23 07:17:19.773
  W0417 07:17:19.775251      30 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 04/17/23 07:17:24.779
  STEP: wait for all pods to be garbage collected @ 04/17/23 07:17:24.781
  STEP: Gathering metrics @ 04/17/23 07:17:29.787
  Apr 17 07:17:29.842: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 17 07:17:29.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8995" for this suite. @ 04/17/23 07:17:29.843
â€¢ [10.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]
test/e2e/apps/replica_set.go:143
  STEP: Creating a kubernetes client @ 04/17/23 07:17:29.847
  Apr 17 07:17:29.847: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename replicaset @ 04/17/23 07:17:29.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:17:29.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:17:29.853
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 04/17/23 07:17:29.854
  Apr 17 07:17:29.857: INFO: Pod name sample-pod: Found 0 pods out of 1
  Apr 17 07:17:34.859: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/17/23 07:17:34.859
  STEP: getting scale subresource @ 04/17/23 07:17:34.859
  STEP: updating a scale subresource @ 04/17/23 07:17:34.86
  STEP: verifying the replicaset Spec.Replicas was modified @ 04/17/23 07:17:34.863
  STEP: Patch a scale subresource @ 04/17/23 07:17:34.864
  Apr 17 07:17:34.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7075" for this suite. @ 04/17/23 07:17:34.868
â€¢ [5.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:218
  STEP: Creating a kubernetes client @ 04/17/23 07:17:34.871
  Apr 17 07:17:34.871: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 07:17:34.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:17:34.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:17:34.876
  STEP: Creating a pod to test downward api env vars @ 04/17/23 07:17:34.877
  STEP: Saw pod success @ 04/17/23 07:17:38.884
  Apr 17 07:17:38.886: INFO: Trying to get logs from node c3-worker2 pod downward-api-63cb1fb0-1266-4f07-9ace-d29b84237de5 container dapi-container: <nil>
  STEP: delete the pod @ 04/17/23 07:17:38.888
  Apr 17 07:17:38.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-409" for this suite. @ 04/17/23 07:17:38.894
â€¢ [4.025 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:236
  STEP: Creating a kubernetes client @ 04/17/23 07:17:38.896
  Apr 17 07:17:38.896: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 07:17:38.896
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:17:38.9
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:17:38.901
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 07:17:38.902
  STEP: Saw pod success @ 04/17/23 07:17:42.911
  Apr 17 07:17:42.912: INFO: Trying to get logs from node c3-worker2 pod downwardapi-volume-7555b368-f5e0-4618-a6e4-c41427cd1870 container client-container: <nil>
  STEP: delete the pod @ 04/17/23 07:17:42.914
  Apr 17 07:17:42.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9181" for this suite. @ 04/17/23 07:17:42.919
â€¢ [4.025 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:250
  STEP: Creating a kubernetes client @ 04/17/23 07:17:42.921
  Apr 17 07:17:42.921: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 07:17:42.921
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:17:42.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:17:42.926
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 07:17:42.928
  STEP: Saw pod success @ 04/17/23 07:17:46.936
  Apr 17 07:17:46.937: INFO: Trying to get logs from node c3-worker pod downwardapi-volume-0688516b-bb6d-4f89-b547-61fd0e245e1c container client-container: <nil>
  STEP: delete the pod @ 04/17/23 07:17:46.946
  Apr 17 07:17:46.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-220" for this suite. @ 04/17/23 07:17:46.951
â€¢ [4.031 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:107
  STEP: Creating a kubernetes client @ 04/17/23 07:17:46.953
  Apr 17 07:17:46.953: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 07:17:46.953
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:17:46.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:17:46.958
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/17/23 07:17:46.959
  STEP: Saw pod success @ 04/17/23 07:17:50.967
  Apr 17 07:17:50.968: INFO: Trying to get logs from node c3-worker pod pod-0160f019-61d6-4bc7-aea6-c501519ea3c5 container test-container: <nil>
  STEP: delete the pod @ 04/17/23 07:17:50.97
  Apr 17 07:17:50.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6597" for this suite. @ 04/17/23 07:17:50.975
â€¢ [4.024 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 04/17/23 07:17:50.977
  Apr 17 07:17:50.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename watch @ 04/17/23 07:17:50.978
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:17:50.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:17:50.983
  STEP: creating a watch on configmaps with a certain label @ 04/17/23 07:17:50.984
  STEP: creating a new configmap @ 04/17/23 07:17:50.984
  STEP: modifying the configmap once @ 04/17/23 07:17:50.985
  STEP: changing the label value of the configmap @ 04/17/23 07:17:50.988
  STEP: Expecting to observe a delete notification for the watched object @ 04/17/23 07:17:50.99
  Apr 17 07:17:50.990: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2635  e8a4a6d7-7508-4b05-8e18-9103d9d78a1a 54853 0 2023-04-17 07:17:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-17 07:17:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 07:17:50.990: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2635  e8a4a6d7-7508-4b05-8e18-9103d9d78a1a 54854 0 2023-04-17 07:17:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-17 07:17:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 07:17:50.990: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2635  e8a4a6d7-7508-4b05-8e18-9103d9d78a1a 54855 0 2023-04-17 07:17:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-17 07:17:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 04/17/23 07:17:50.99
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 04/17/23 07:17:50.992
  STEP: changing the label value of the configmap back @ 04/17/23 07:18:00.993
  STEP: modifying the configmap a third time @ 04/17/23 07:18:00.997
  STEP: deleting the configmap @ 04/17/23 07:18:00.999
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 04/17/23 07:18:01.001
  Apr 17 07:18:01.001: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2635  e8a4a6d7-7508-4b05-8e18-9103d9d78a1a 54888 0 2023-04-17 07:17:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-17 07:18:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 07:18:01.001: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2635  e8a4a6d7-7508-4b05-8e18-9103d9d78a1a 54889 0 2023-04-17 07:17:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-17 07:18:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 07:18:01.001: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2635  e8a4a6d7-7508-4b05-8e18-9103d9d78a1a 54890 0 2023-04-17 07:17:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-17 07:18:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 07:18:01.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-2635" for this suite. @ 04/17/23 07:18:01.002
â€¢ [10.027 seconds]
------------------------------
SS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 04/17/23 07:18:01.004
  Apr 17 07:18:01.004: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 07:18:01.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:18:01.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:18:01.009
  STEP: Creating secret with name secret-test-585c7ea4-a997-4719-8b0b-be5a4af3f7c6 @ 04/17/23 07:18:01.01
  STEP: Creating a pod to test consume secrets @ 04/17/23 07:18:01.012
  STEP: Saw pod success @ 04/17/23 07:18:05.019
  Apr 17 07:18:05.020: INFO: Trying to get logs from node c3-worker pod pod-secrets-b24f0d3c-4051-4e65-835e-42a7f100dbbe container secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 07:18:05.022
  Apr 17 07:18:05.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9566" for this suite. @ 04/17/23 07:18:05.028
â€¢ [4.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:252
  STEP: Creating a kubernetes client @ 04/17/23 07:18:05.03
  Apr 17 07:18:05.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename namespaces @ 04/17/23 07:18:05.031
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:18:05.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:18:05.036
  STEP: Creating a test namespace @ 04/17/23 07:18:05.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:18:05.041
  STEP: Creating a service in the namespace @ 04/17/23 07:18:05.042
  STEP: Deleting the namespace @ 04/17/23 07:18:05.045
  STEP: Waiting for the namespace to be removed. @ 04/17/23 07:18:05.046
  STEP: Recreating the namespace @ 04/17/23 07:18:11.049
  STEP: Verifying there is no service in the namespace @ 04/17/23 07:18:11.053
  Apr 17 07:18:11.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2012" for this suite. @ 04/17/23 07:18:11.055
  STEP: Destroying namespace "nsdeletetest-9322" for this suite. @ 04/17/23 07:18:11.056
  Apr 17 07:18:11.057: INFO: Namespace nsdeletetest-9322 was already deleted
  STEP: Destroying namespace "nsdeletetest-284" for this suite. @ 04/17/23 07:18:11.057
â€¢ [6.028 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 04/17/23 07:18:11.058
  Apr 17 07:18:11.058: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pods @ 04/17/23 07:18:11.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:18:11.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:18:11.063
  STEP: Saw pod success @ 04/17/23 07:18:17.081
  Apr 17 07:18:17.082: INFO: Trying to get logs from node c3-worker2 pod client-envvars-4c3bf82d-8baf-4b8b-9adc-a3cfafcd122e container env3cont: <nil>
  STEP: delete the pod @ 04/17/23 07:18:17.084
  Apr 17 07:18:17.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9328" for this suite. @ 04/17/23 07:18:17.089
â€¢ [6.032 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 04/17/23 07:18:17.091
  Apr 17 07:18:17.091: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename deployment @ 04/17/23 07:18:17.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:18:17.094
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:18:17.096
  STEP: creating a Deployment @ 04/17/23 07:18:17.098
  STEP: waiting for Deployment to be created @ 04/17/23 07:18:17.099
  STEP: waiting for all Replicas to be Ready @ 04/17/23 07:18:17.1
  Apr 17 07:18:17.100: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 17 07:18:17.100: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 17 07:18:17.103: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 17 07:18:17.103: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 17 07:18:17.106: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 17 07:18:17.106: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 17 07:18:17.112: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 17 07:18:17.112: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 17 07:18:18.227: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 17 07:18:18.227: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 17 07:18:18.240: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 04/17/23 07:18:18.24
  W0417 07:18:18.245760      30 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Apr 17 07:18:18.246: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 04/17/23 07:18:18.246
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 0
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:18.247: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:18.249: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:18.249: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:18.253: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:18.253: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:18.255: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  Apr 17 07:18:18.255: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  Apr 17 07:18:18.259: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  Apr 17 07:18:18.259: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  Apr 17 07:18:19.245: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:19.245: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:19.250: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  STEP: listing Deployments @ 04/17/23 07:18:19.25
  Apr 17 07:18:19.251: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 04/17/23 07:18:19.251
  Apr 17 07:18:19.255: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 04/17/23 07:18:19.256
  Apr 17 07:18:19.258: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 17 07:18:19.258: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 17 07:18:19.262: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 17 07:18:19.266: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 17 07:18:19.268: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 17 07:18:20.242: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 17 07:18:20.253: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 17 07:18:20.255: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 17 07:18:20.258: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 17 07:18:21.250: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 04/17/23 07:18:21.255
  STEP: fetching the DeploymentStatus @ 04/17/23 07:18:21.258
  Apr 17 07:18:21.260: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  Apr 17 07:18:21.260: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  Apr 17 07:18:21.260: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  Apr 17 07:18:21.260: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  Apr 17 07:18:21.260: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 1
  Apr 17 07:18:21.260: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:21.260: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 3
  Apr 17 07:18:21.260: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:21.260: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 2
  Apr 17 07:18:21.260: INFO: observed Deployment test-deployment in namespace deployment-414 with ReadyReplicas 3
  STEP: deleting the Deployment @ 04/17/23 07:18:21.26
  Apr 17 07:18:21.263: INFO: observed event type MODIFIED
  Apr 17 07:18:21.263: INFO: observed event type MODIFIED
  Apr 17 07:18:21.263: INFO: observed event type MODIFIED
  Apr 17 07:18:21.263: INFO: observed event type MODIFIED
  Apr 17 07:18:21.263: INFO: observed event type MODIFIED
  Apr 17 07:18:21.263: INFO: observed event type MODIFIED
  Apr 17 07:18:21.263: INFO: observed event type MODIFIED
  Apr 17 07:18:21.263: INFO: observed event type MODIFIED
  Apr 17 07:18:21.263: INFO: observed event type MODIFIED
  Apr 17 07:18:21.263: INFO: observed event type MODIFIED
  Apr 17 07:18:21.263: INFO: observed event type MODIFIED
  Apr 17 07:18:21.264: INFO: Log out all the ReplicaSets if there is no deployment created
  Apr 17 07:18:21.265: INFO: ReplicaSet "test-deployment-58db457f5f":
  &ReplicaSet{ObjectMeta:{test-deployment-58db457f5f  deployment-414  c2976390-6e9a-4980-a442-a9b5d6a140b5 55073 3 2023-04-17 07:18:17 +0000 UTC <nil> <nil> map[pod-template-hash:58db457f5f test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 6e5fb816-4af3-4874-b6b5-73614248a0da 0xc0029dbc47 0xc0029dbc48}] [] [{kube-controller-manager Update apps/v1 2023-04-17 07:18:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6e5fb816-4af3-4874-b6b5-73614248a0da\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 07:18:19 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 58db457f5f,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:58db457f5f test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0029dbcd0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

  Apr 17 07:18:21.266: INFO: ReplicaSet "test-deployment-5b5dcbcd95":
  &ReplicaSet{ObjectMeta:{test-deployment-5b5dcbcd95  deployment-414  b0b9528f-c97d-41f3-a48a-b3c8d4bbbd8b 55152 4 2023-04-17 07:18:18 +0000 UTC <nil> <nil> map[pod-template-hash:5b5dcbcd95 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 6e5fb816-4af3-4874-b6b5-73614248a0da 0xc0029dbd37 0xc0029dbd38}] [] [{kube-controller-manager Update apps/v1 2023-04-17 07:18:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6e5fb816-4af3-4874-b6b5-73614248a0da\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 07:18:21 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 5b5dcbcd95,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:5b5dcbcd95 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.9 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0029dbdc0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

  Apr 17 07:18:21.267: INFO: pod: "test-deployment-5b5dcbcd95-tb78c":
  &Pod{ObjectMeta:{test-deployment-5b5dcbcd95-tb78c test-deployment-5b5dcbcd95- deployment-414  8736bf68-3f24-42a0-8a7a-b4a75ad65c18 55147 0 2023-04-17 07:18:18 +0000 UTC 2023-04-17 07:18:22 +0000 UTC 0xc0007fe158 map[pod-template-hash:5b5dcbcd95 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-5b5dcbcd95 b0b9528f-c97d-41f3-a48a-b3c8d4bbbd8b 0xc0007fe187 0xc0007fe188}] [] [{kube-controller-manager Update v1 2023-04-17 07:18:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b0b9528f-c97d-41f3-a48a-b3c8d4bbbd8b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:18:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.240\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bwntp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.9,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bwntp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.240,StartTime:2023-04-17 07:18:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:18:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.9,ImageID:registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097,ContainerID:containerd://5812f4cc8ca645746806ca847e36883be2a246de02484ec952b12c6245f4fdeb,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.240,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}

  Apr 17 07:18:21.267: INFO: pod: "test-deployment-5b5dcbcd95-z8z2l":
  &Pod{ObjectMeta:{test-deployment-5b5dcbcd95-z8z2l test-deployment-5b5dcbcd95- deployment-414  162ca9cc-1759-4597-bd29-e0fea2068c19 55121 0 2023-04-17 07:18:19 +0000 UTC 2023-04-17 07:18:21 +0000 UTC 0xc0007fe350 map[pod-template-hash:5b5dcbcd95 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-5b5dcbcd95 b0b9528f-c97d-41f3-a48a-b3c8d4bbbd8b 0xc0007fe387 0xc0007fe388}] [] [{kube-controller-manager Update v1 2023-04-17 07:18:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b0b9528f-c97d-41f3-a48a-b3c8d4bbbd8b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:18:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.183\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k6szn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.9,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k6szn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.183,StartTime:2023-04-17 07:18:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:18:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.9,ImageID:registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097,ContainerID:containerd://0ab7b9c3f340f648fb817a4b5c54cf48479f953fdced18e3e79b3754304c1728,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.183,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}

  Apr 17 07:18:21.267: INFO: ReplicaSet "test-deployment-6fc78d85c6":
  &ReplicaSet{ObjectMeta:{test-deployment-6fc78d85c6  deployment-414  ccec55b7-78d9-49ed-8ca2-8c8859931a22 55144 2 2023-04-17 07:18:19 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 6e5fb816-4af3-4874-b6b5-73614248a0da 0xc0029dbe27 0xc0029dbe28}] [] [{kube-controller-manager Update apps/v1 2023-04-17 07:18:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6e5fb816-4af3-4874-b6b5-73614248a0da\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 07:18:21 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 6fc78d85c6,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0029dbeb0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

  Apr 17 07:18:21.268: INFO: pod: "test-deployment-6fc78d85c6-jdvzs":
  &Pod{ObjectMeta:{test-deployment-6fc78d85c6-jdvzs test-deployment-6fc78d85c6- deployment-414  2e0dabbd-6b3f-4820-97d6-89698a8d8583 55143 0 2023-04-17 07:18:20 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-6fc78d85c6 ccec55b7-78d9-49ed-8ca2-8c8859931a22 0xc00163fc67 0xc00163fc68}] [] [{kube-controller-manager Update v1 2023-04-17 07:18:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ccec55b7-78d9-49ed-8ca2-8c8859931a22\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:18:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.241\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wptr8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wptr8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.241,StartTime:2023-04-17 07:18:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:18:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://3dff7559b8b50924ac8b58f7863974c05217d4c6e059bb169fd7fcb9e3e99081,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.241,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}

  Apr 17 07:18:21.268: INFO: pod: "test-deployment-6fc78d85c6-xwbhr":
  &Pod{ObjectMeta:{test-deployment-6fc78d85c6-xwbhr test-deployment-6fc78d85c6- deployment-414  c92d8c11-dd9a-4a7c-83b2-aad0eec44591 55114 0 2023-04-17 07:18:19 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-6fc78d85c6 ccec55b7-78d9-49ed-8ca2-8c8859931a22 0xc00163fe57 0xc00163fe58}] [] [{kube-controller-manager Update v1 2023-04-17 07:18:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ccec55b7-78d9-49ed-8ca2-8c8859931a22\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:18:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.184\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bdbjf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bdbjf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:18:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.184,StartTime:2023-04-17 07:18:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:18:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://f9b14c6be85efad112391e132bde65043b5399ddc464a72d5f1834b6c8e110d2,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.184,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}

  Apr 17 07:18:21.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-414" for this suite. @ 04/17/23 07:18:21.27
â€¢ [4.181 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 04/17/23 07:18:21.271
  Apr 17 07:18:21.271: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/17/23 07:18:21.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:18:21.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:18:21.277
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 04/17/23 07:18:21.278
  Apr 17 07:18:21.278: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 04/17/23 07:18:26.297
  Apr 17 07:18:26.297: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:18:27.488: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:18:32.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2695" for this suite. @ 04/17/23 07:18:32.373
â€¢ [11.103 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:402
  STEP: Creating a kubernetes client @ 04/17/23 07:18:32.375
  Apr 17 07:18:32.375: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 07:18:32.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:18:32.38
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:18:32.381
  STEP: Setting up server cert @ 04/17/23 07:18:32.387
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 07:18:32.523
  STEP: Deploying the webhook pod @ 04/17/23 07:18:32.525
  STEP: Wait for the deployment to be ready @ 04/17/23 07:18:32.529
  Apr 17 07:18:32.531: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 07:18:34.535
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 07:18:34.538
  Apr 17 07:18:35.538: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 04/17/23 07:18:35.54
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/17/23 07:18:35.548
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 04/17/23 07:18:35.552
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/17/23 07:18:35.555
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 04/17/23 07:18:35.559
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/17/23 07:18:35.561
  Apr 17 07:18:35.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7355" for this suite. @ 04/17/23 07:18:35.581
  STEP: Destroying namespace "webhook-markers-9577" for this suite. @ 04/17/23 07:18:35.583
â€¢ [3.210 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]
test/e2e/apps/replica_set.go:176
  STEP: Creating a kubernetes client @ 04/17/23 07:18:35.585
  Apr 17 07:18:35.585: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename replicaset @ 04/17/23 07:18:35.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:18:35.589
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:18:35.59
  STEP: Create a Replicaset @ 04/17/23 07:18:35.592
  STEP: Verify that the required pods have come up. @ 04/17/23 07:18:35.594
  Apr 17 07:18:35.595: INFO: Pod name sample-pod: Found 0 pods out of 1
  Apr 17 07:18:40.596: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/17/23 07:18:40.596
  STEP: Getting /status @ 04/17/23 07:18:40.596
  Apr 17 07:18:40.598: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 04/17/23 07:18:40.598
  Apr 17 07:18:40.601: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 04/17/23 07:18:40.601
  Apr 17 07:18:40.602: INFO: Observed &ReplicaSet event: ADDED
  Apr 17 07:18:40.602: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 17 07:18:40.602: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 17 07:18:40.602: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 17 07:18:40.602: INFO: Found replicaset test-rs in namespace replicaset-3259 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 17 07:18:40.602: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 04/17/23 07:18:40.602
  Apr 17 07:18:40.602: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 17 07:18:40.604: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 04/17/23 07:18:40.604
  Apr 17 07:18:40.604: INFO: Observed &ReplicaSet event: ADDED
  Apr 17 07:18:40.605: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 17 07:18:40.605: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 17 07:18:40.605: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 17 07:18:40.605: INFO: Observed replicaset test-rs in namespace replicaset-3259 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 17 07:18:40.605: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 17 07:18:40.605: INFO: Found replicaset test-rs in namespace replicaset-3259 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Apr 17 07:18:40.605: INFO: Replicaset test-rs has a patched status
  Apr 17 07:18:40.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3259" for this suite. @ 04/17/23 07:18:40.606
â€¢ [5.022 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:85
  STEP: Creating a kubernetes client @ 04/17/23 07:18:40.608
  Apr 17 07:18:40.608: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/17/23 07:18:40.608
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:18:40.612
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:18:40.613
  Apr 17 07:18:40.614: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:18:46.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5647" for this suite. @ 04/17/23 07:18:46.687
â€¢ [6.081 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 04/17/23 07:18:46.689
  Apr 17 07:18:46.689: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/17/23 07:18:46.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:18:46.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:18:46.695
  STEP: set up a multi version CRD @ 04/17/23 07:18:46.697
  Apr 17 07:18:46.697: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: mark a version not serverd @ 04/17/23 07:18:49.857
  STEP: check the unserved version gets removed @ 04/17/23 07:18:49.866
  STEP: check the other version is not changed @ 04/17/23 07:18:50.551
  Apr 17 07:18:53.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5163" for this suite. @ 04/17/23 07:18:53.051
â€¢ [6.364 seconds]
------------------------------
SSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 04/17/23 07:18:53.053
  Apr 17 07:18:53.053: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename disruption @ 04/17/23 07:18:53.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:18:53.057
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:18:53.058
  STEP: Creating a pdb that targets all three pods in a test replica set @ 04/17/23 07:18:53.059
  STEP: Waiting for the pdb to be processed @ 04/17/23 07:18:53.061
  STEP: First trying to evict a pod which shouldn't be evictable @ 04/17/23 07:18:55.066
  STEP: Waiting for all pods to be running @ 04/17/23 07:18:55.066
  Apr 17 07:18:55.067: INFO: pods: 0 < 3
  STEP: locating a running pod @ 04/17/23 07:18:57.07
  STEP: Updating the pdb to allow a pod to be evicted @ 04/17/23 07:18:57.074
  STEP: Waiting for the pdb to be processed @ 04/17/23 07:18:57.076
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/17/23 07:18:59.079
  STEP: Waiting for all pods to be running @ 04/17/23 07:18:59.079
  STEP: Waiting for the pdb to observed all healthy pods @ 04/17/23 07:18:59.08
  STEP: Patching the pdb to disallow a pod to be evicted @ 04/17/23 07:18:59.086
  STEP: Waiting for the pdb to be processed @ 04/17/23 07:18:59.092
  STEP: Waiting for all pods to be running @ 04/17/23 07:19:01.095
  STEP: locating a running pod @ 04/17/23 07:19:01.096
  STEP: Deleting the pdb to allow a pod to be evicted @ 04/17/23 07:19:01.099
  STEP: Waiting for the pdb to be deleted @ 04/17/23 07:19:01.101
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/17/23 07:19:01.102
  STEP: Waiting for all pods to be running @ 04/17/23 07:19:01.102
  Apr 17 07:19:01.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9195" for this suite. @ 04/17/23 07:19:01.109
â€¢ [8.058 seconds]
------------------------------
SSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 04/17/23 07:19:01.111
  Apr 17 07:19:01.111: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename containers @ 04/17/23 07:19:01.111
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:19:01.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:19:01.116
  STEP: Creating a pod to test override arguments @ 04/17/23 07:19:01.117
  STEP: Saw pod success @ 04/17/23 07:19:05.125
  Apr 17 07:19:05.125: INFO: Trying to get logs from node c3-worker pod client-containers-539c70b4-4b81-48bc-9356-ecd61f61466e container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 07:19:05.128
  Apr 17 07:19:05.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-1999" for this suite. @ 04/17/23 07:19:05.133
â€¢ [4.024 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:131
  STEP: Creating a kubernetes client @ 04/17/23 07:19:05.135
  Apr 17 07:19:05.135: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 07:19:05.135
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:19:05.139
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:19:05.141
  STEP: Creating the pod @ 04/17/23 07:19:05.142
  Apr 17 07:19:07.655: INFO: Successfully updated pod "labelsupdate2c0e6827-00f1-4e51-b831-7d7ff7b28deb"
  Apr 17 07:19:11.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3563" for this suite. @ 04/17/23 07:19:11.665
â€¢ [6.532 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]
test/e2e/network/endpointslice.go:355
  STEP: Creating a kubernetes client @ 04/17/23 07:19:11.668
  Apr 17 07:19:11.668: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename endpointslice @ 04/17/23 07:19:11.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:19:11.672
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:19:11.673
  STEP: getting /apis @ 04/17/23 07:19:11.674
  STEP: getting /apis/discovery.k8s.io @ 04/17/23 07:19:11.676
  STEP: getting /apis/discovery.k8s.iov1 @ 04/17/23 07:19:11.676
  STEP: creating @ 04/17/23 07:19:11.676
  STEP: getting @ 04/17/23 07:19:11.68
  STEP: listing @ 04/17/23 07:19:11.681
  STEP: watching @ 04/17/23 07:19:11.682
  Apr 17 07:19:11.682: INFO: starting watch
  STEP: cluster-wide listing @ 04/17/23 07:19:11.682
  STEP: cluster-wide watching @ 04/17/23 07:19:11.683
  Apr 17 07:19:11.683: INFO: starting watch
  STEP: patching @ 04/17/23 07:19:11.683
  STEP: updating @ 04/17/23 07:19:11.685
  Apr 17 07:19:11.687: INFO: waiting for watch events with expected annotations
  Apr 17 07:19:11.687: INFO: saw patched and updated annotations
  STEP: deleting @ 04/17/23 07:19:11.687
  STEP: deleting a collection @ 04/17/23 07:19:11.69
  Apr 17 07:19:11.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-3091" for this suite. @ 04/17/23 07:19:11.695
â€¢ [0.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]
test/e2e/apimachinery/resource_quota.go:806
  STEP: Creating a kubernetes client @ 04/17/23 07:19:11.698
  Apr 17 07:19:11.698: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename resourcequota @ 04/17/23 07:19:11.698
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:19:11.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:19:11.702
  STEP: Creating a ResourceQuota with best effort scope @ 04/17/23 07:19:11.704
  STEP: Ensuring ResourceQuota status is calculated @ 04/17/23 07:19:11.705
  STEP: Creating a ResourceQuota with not best effort scope @ 04/17/23 07:19:13.707
  STEP: Ensuring ResourceQuota status is calculated @ 04/17/23 07:19:13.709
  STEP: Creating a best-effort pod @ 04/17/23 07:19:15.712
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 04/17/23 07:19:15.717
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 04/17/23 07:19:17.719
  STEP: Deleting the pod @ 04/17/23 07:19:19.721
  STEP: Ensuring resource quota status released the pod usage @ 04/17/23 07:19:19.724
  STEP: Creating a not best-effort pod @ 04/17/23 07:19:21.727
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 04/17/23 07:19:21.73
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 04/17/23 07:19:23.733
  STEP: Deleting the pod @ 04/17/23 07:19:25.736
  STEP: Ensuring resource quota status released the pod usage @ 04/17/23 07:19:25.738
  Apr 17 07:19:27.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1032" for this suite. @ 04/17/23 07:19:27.742
â€¢ [16.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:107
  STEP: Creating a kubernetes client @ 04/17/23 07:19:27.745
  Apr 17 07:19:27.745: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pod-network-test @ 04/17/23 07:19:27.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:19:27.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:19:27.751
  STEP: Performing setup for networking test in namespace pod-network-test-6782 @ 04/17/23 07:19:27.752
  STEP: creating a selector @ 04/17/23 07:19:27.752
  STEP: Creating the service pods in kubernetes @ 04/17/23 07:19:27.752
  Apr 17 07:19:27.752: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 04/17/23 07:19:39.778
  Apr 17 07:19:41.788: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Apr 17 07:19:41.788: INFO: Going to poll 10.244.1.247 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  Apr 17 07:19:41.789: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.247:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6782 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:19:41.789: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:19:41.790: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:19:41.790: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-6782/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.1.247%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 17 07:19:41.864: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 17 07:19:41.864: INFO: Going to poll 10.244.2.188 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  Apr 17 07:19:41.865: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.188:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6782 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:19:41.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:19:41.866: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:19:41.866: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-6782/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.2.188%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 17 07:19:41.915: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 17 07:19:41.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6782" for this suite. @ 04/17/23 07:19:41.917
â€¢ [14.174 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs  [Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 04/17/23 07:19:41.919
  Apr 17 07:19:41.919: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl-logs @ 04/17/23 07:19:41.919
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:19:41.923
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:19:41.924
  STEP: creating an pod @ 04/17/23 07:19:41.926
  Apr 17 07:19:41.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-logs-5343 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.43 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  Apr 17 07:19:41.968: INFO: stderr: ""
  Apr 17 07:19:41.968: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 04/17/23 07:19:41.968
  Apr 17 07:19:41.968: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  Apr 17 07:19:43.972: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 04/17/23 07:19:43.972
  Apr 17 07:19:43.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-logs-5343 logs logs-generator logs-generator'
  Apr 17 07:19:44.015: INFO: stderr: ""
  Apr 17 07:19:44.015: INFO: stdout: "I0417 07:19:42.565882       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/ldx6 492\nI0417 07:19:42.766206       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/fcvh 588\nI0417 07:19:42.966529       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/jb4 542\nI0417 07:19:43.166818       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/fc5r 336\nI0417 07:19:43.366054       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/b9t 407\nI0417 07:19:43.566342       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/484m 539\nI0417 07:19:43.766623       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/822 298\nI0417 07:19:43.966905       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/4799 474\n"
  STEP: limiting log lines @ 04/17/23 07:19:44.015
  Apr 17 07:19:44.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-logs-5343 logs logs-generator logs-generator --tail=1'
  Apr 17 07:19:44.056: INFO: stderr: ""
  Apr 17 07:19:44.056: INFO: stdout: "I0417 07:19:43.966905       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/4799 474\n"
  Apr 17 07:19:44.056: INFO: got output "I0417 07:19:43.966905       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/4799 474\n"
  STEP: limiting log bytes @ 04/17/23 07:19:44.056
  Apr 17 07:19:44.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-logs-5343 logs logs-generator logs-generator --limit-bytes=1'
  Apr 17 07:19:44.098: INFO: stderr: ""
  Apr 17 07:19:44.098: INFO: stdout: "I"
  Apr 17 07:19:44.098: INFO: got output "I"
  STEP: exposing timestamps @ 04/17/23 07:19:44.098
  Apr 17 07:19:44.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-logs-5343 logs logs-generator logs-generator --tail=1 --timestamps'
  Apr 17 07:19:44.142: INFO: stderr: ""
  Apr 17 07:19:44.142: INFO: stdout: "2023-04-17T07:19:43.966944690Z I0417 07:19:43.966905       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/4799 474\n"
  Apr 17 07:19:44.142: INFO: got output "2023-04-17T07:19:43.966944690Z I0417 07:19:43.966905       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/4799 474\n"
  STEP: restricting to a time range @ 04/17/23 07:19:44.142
  Apr 17 07:19:46.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-logs-5343 logs logs-generator logs-generator --since=1s'
  Apr 17 07:19:46.688: INFO: stderr: ""
  Apr 17 07:19:46.688: INFO: stdout: "I0417 07:19:45.766509       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/55xs 482\nI0417 07:19:45.966819       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/czcj 563\nI0417 07:19:46.166064       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/6qf 267\nI0417 07:19:46.366390       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/ftk 406\nI0417 07:19:46.566672       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/bx9 258\n"
  Apr 17 07:19:46.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-logs-5343 logs logs-generator logs-generator --since=24h'
  Apr 17 07:19:46.733: INFO: stderr: ""
  Apr 17 07:19:46.733: INFO: stdout: "I0417 07:19:42.565882       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/ldx6 492\nI0417 07:19:42.766206       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/fcvh 588\nI0417 07:19:42.966529       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/jb4 542\nI0417 07:19:43.166818       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/fc5r 336\nI0417 07:19:43.366054       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/b9t 407\nI0417 07:19:43.566342       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/484m 539\nI0417 07:19:43.766623       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/822 298\nI0417 07:19:43.966905       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/4799 474\nI0417 07:19:44.166201       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/52k5 452\nI0417 07:19:44.366512       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/vft 539\nI0417 07:19:44.566807       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/p4m 312\nI0417 07:19:44.766036       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/8qff 296\nI0417 07:19:44.966336       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/qfnz 504\nI0417 07:19:45.166627       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/m9w 280\nI0417 07:19:45.366927       1 logs_generator.go:76] 14 POST /api/v1/namespaces/default/pods/tmh 377\nI0417 07:19:45.566215       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/tzb9 444\nI0417 07:19:45.766509       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/55xs 482\nI0417 07:19:45.966819       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/czcj 563\nI0417 07:19:46.166064       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/6qf 267\nI0417 07:19:46.366390       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/ftk 406\nI0417 07:19:46.566672       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/bx9 258\n"
  Apr 17 07:19:46.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-logs-5343 delete pod logs-generator'
  Apr 17 07:19:47.379: INFO: stderr: ""
  Apr 17 07:19:47.379: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Apr 17 07:19:47.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-5343" for this suite. @ 04/17/23 07:19:47.381
â€¢ [5.464 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]
test/e2e/kubectl/kubectl.go:1701
  STEP: Creating a kubernetes client @ 04/17/23 07:19:47.383
  Apr 17 07:19:47.383: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 07:19:47.383
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:19:47.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:19:47.388
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/17/23 07:19:47.389
  Apr 17 07:19:47.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4650 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Apr 17 07:19:47.431: INFO: stderr: ""
  Apr 17 07:19:47.431: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/17/23 07:19:47.431
  Apr 17 07:19:47.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4650 delete pods e2e-test-httpd-pod'
  Apr 17 07:19:49.383: INFO: stderr: ""
  Apr 17 07:19:49.383: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 17 07:19:49.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4650" for this suite. @ 04/17/23 07:19:49.384
â€¢ [2.003 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:46
  STEP: Creating a kubernetes client @ 04/17/23 07:19:49.386
  Apr 17 07:19:49.386: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 04/17/23 07:19:49.387
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:19:49.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:19:49.391
  STEP: creating a target pod @ 04/17/23 07:19:49.392
  STEP: adding an ephemeral container @ 04/17/23 07:19:51.398
  STEP: checking pod container endpoints @ 04/17/23 07:19:53.407
  Apr 17 07:19:53.407: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-1076 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:19:53.407: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:19:53.408: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:19:53.408: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-1076/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Apr 17 07:19:53.483: INFO: Exec stderr: ""
  Apr 17 07:19:53.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-1076" for this suite. @ 04/17/23 07:19:53.486
â€¢ [4.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]
test/e2e/storage/csistoragecapacity.go:49
  STEP: Creating a kubernetes client @ 04/17/23 07:19:53.489
  Apr 17 07:19:53.489: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename csistoragecapacity @ 04/17/23 07:19:53.489
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:19:53.493
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:19:53.494
  STEP: getting /apis @ 04/17/23 07:19:53.496
  STEP: getting /apis/storage.k8s.io @ 04/17/23 07:19:53.497
  STEP: getting /apis/storage.k8s.io/v1 @ 04/17/23 07:19:53.498
  STEP: creating @ 04/17/23 07:19:53.498
  STEP: watching @ 04/17/23 07:19:53.503
  Apr 17 07:19:53.503: INFO: starting watch
  STEP: getting @ 04/17/23 07:19:53.505
  STEP: listing in namespace @ 04/17/23 07:19:53.506
  STEP: listing across namespaces @ 04/17/23 07:19:53.507
  STEP: patching @ 04/17/23 07:19:53.508
  STEP: updating @ 04/17/23 07:19:53.509
  Apr 17 07:19:53.511: INFO: waiting for watch events with expected annotations in namespace
  Apr 17 07:19:53.511: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 04/17/23 07:19:53.511
  STEP: deleting a collection @ 04/17/23 07:19:53.514
  Apr 17 07:19:53.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-4962" for this suite. @ 04/17/23 07:19:53.519
â€¢ [0.032 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:69
  STEP: Creating a kubernetes client @ 04/17/23 07:19:53.521
  Apr 17 07:19:53.521: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:19:53.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:19:53.525
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:19:53.526
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 07:19:53.527
  STEP: Saw pod success @ 04/17/23 07:19:57.536
  Apr 17 07:19:57.537: INFO: Trying to get logs from node c3-worker2 pod downwardapi-volume-8cb5cfbb-6ebc-4396-92ff-245867af61c3 container client-container: <nil>
  STEP: delete the pod @ 04/17/23 07:19:57.54
  Apr 17 07:19:57.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5199" for this suite. @ 04/17/23 07:19:57.545
â€¢ [4.026 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:97
  STEP: Creating a kubernetes client @ 04/17/23 07:19:57.547
  Apr 17 07:19:57.547: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 07:19:57.547
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:19:57.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:19:57.552
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/17/23 07:19:57.554
  STEP: Saw pod success @ 04/17/23 07:20:01.562
  Apr 17 07:20:01.563: INFO: Trying to get logs from node c3-worker2 pod pod-9ce71246-f57c-4990-95a0-5f45b7db8e76 container test-container: <nil>
  STEP: delete the pod @ 04/17/23 07:20:01.566
  Apr 17 07:20:01.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3526" for this suite. @ 04/17/23 07:20:01.57
â€¢ [4.025 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:58
  STEP: Creating a kubernetes client @ 04/17/23 07:20:01.572
  Apr 17 07:20:01.572: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/17/23 07:20:01.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:20:01.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:20:01.578
  Apr 17 07:20:01.579: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:20:02.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6173" for this suite. @ 04/17/23 07:20:02.587
â€¢ [1.017 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]
test/e2e/kubectl/kubectl.go:1480
  STEP: Creating a kubernetes client @ 04/17/23 07:20:02.59
  Apr 17 07:20:02.590: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 07:20:02.59
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:20:02.594
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:20:02.595
  STEP: creating Agnhost RC @ 04/17/23 07:20:02.596
  Apr 17 07:20:02.596: INFO: namespace kubectl-8335
  Apr 17 07:20:02.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8335 create -f -'
  Apr 17 07:20:02.738: INFO: stderr: ""
  Apr 17 07:20:02.738: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/17/23 07:20:02.738
  Apr 17 07:20:03.739: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 17 07:20:03.739: INFO: Found 1 / 1
  Apr 17 07:20:03.739: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 17 07:20:03.740: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 17 07:20:03.740: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 17 07:20:03.740: INFO: wait on agnhost-primary startup in kubectl-8335 
  Apr 17 07:20:03.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8335 logs agnhost-primary-kdn5z agnhost-primary'
  Apr 17 07:20:03.783: INFO: stderr: ""
  Apr 17 07:20:03.783: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 04/17/23 07:20:03.783
  Apr 17 07:20:03.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8335 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Apr 17 07:20:03.827: INFO: stderr: ""
  Apr 17 07:20:03.827: INFO: stdout: "service/rm2 exposed\n"
  Apr 17 07:20:03.828: INFO: Service rm2 in namespace kubectl-8335 found.
  STEP: exposing service @ 04/17/23 07:20:05.83
  Apr 17 07:20:05.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-8335 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Apr 17 07:20:05.874: INFO: stderr: ""
  Apr 17 07:20:05.874: INFO: stdout: "service/rm3 exposed\n"
  Apr 17 07:20:05.875: INFO: Service rm3 in namespace kubectl-8335 found.
  Apr 17 07:20:07.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8335" for this suite. @ 04/17/23 07:20:07.88
â€¢ [5.292 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 04/17/23 07:20:07.882
  Apr 17 07:20:07.882: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename disruption @ 04/17/23 07:20:07.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:20:07.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:20:07.887
  STEP: creating the pdb @ 04/17/23 07:20:07.888
  STEP: Waiting for the pdb to be processed @ 04/17/23 07:20:07.889
  STEP: updating the pdb @ 04/17/23 07:20:09.892
  STEP: Waiting for the pdb to be processed @ 04/17/23 07:20:09.894
  STEP: patching the pdb @ 04/17/23 07:20:11.897
  STEP: Waiting for the pdb to be processed @ 04/17/23 07:20:11.9
  STEP: Waiting for the pdb to be deleted @ 04/17/23 07:20:13.904
  Apr 17 07:20:13.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9929" for this suite. @ 04/17/23 07:20:13.906
â€¢ [6.026 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 04/17/23 07:20:13.908
  Apr 17 07:20:13.908: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename sched-preemption @ 04/17/23 07:20:13.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:20:13.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:20:13.913
  Apr 17 07:20:13.919: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 17 07:21:13.928: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/17/23 07:21:13.929
  Apr 17 07:21:13.929: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/17/23 07:21:13.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:21:13.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:21:13.939
  Apr 17 07:21:13.945: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Apr 17 07:21:13.947: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Apr 17 07:21:13.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 17 07:21:13.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-4054" for this suite. @ 04/17/23 07:21:13.967
  STEP: Destroying namespace "sched-preemption-9741" for this suite. @ 04/17/23 07:21:13.969
â€¢ [60.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 04/17/23 07:21:13.97
  Apr 17 07:21:13.970: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubelet-test @ 04/17/23 07:21:13.971
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:21:13.975
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:21:13.978
  STEP: Waiting for pod completion @ 04/17/23 07:21:13.982
  Apr 17 07:21:17.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3502" for this suite. @ 04/17/23 07:21:17.992
â€¢ [4.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:89
  STEP: Creating a kubernetes client @ 04/17/23 07:21:17.993
  Apr 17 07:21:17.993: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:21:17.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:21:17.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:21:17.999
  STEP: Creating configMap with name projected-configmap-test-volume-map-d63314d4-4283-4121-a2ff-1b8b7e645cdc @ 04/17/23 07:21:18
  STEP: Creating a pod to test consume configMaps @ 04/17/23 07:21:18.002
  STEP: Saw pod success @ 04/17/23 07:21:22.009
  Apr 17 07:21:22.010: INFO: Trying to get logs from node c3-worker pod pod-projected-configmaps-93f2e3b5-c8eb-4543-b3b6-a66dbfbd3f6c container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 07:21:22.012
  Apr 17 07:21:22.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7954" for this suite. @ 04/17/23 07:21:22.017
â€¢ [4.026 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:375
  STEP: Creating a kubernetes client @ 04/17/23 07:21:22.019
  Apr 17 07:21:22.019: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:21:22.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:21:22.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:21:22.025
  STEP: Creating configMap with name projected-configmap-test-volume-2d0d7721-7bd4-4de2-994b-aaa1f4d5c946 @ 04/17/23 07:21:22.026
  STEP: Creating a pod to test consume configMaps @ 04/17/23 07:21:22.027
  STEP: Saw pod success @ 04/17/23 07:21:26.035
  Apr 17 07:21:26.036: INFO: Trying to get logs from node c3-worker pod pod-projected-configmaps-199521fe-5f88-47bc-930a-ab64368dbc0a container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 07:21:26.038
  Apr 17 07:21:26.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2711" for this suite. @ 04/17/23 07:21:26.043
â€¢ [4.026 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]
test/e2e/apps/statefulset.go:743
  STEP: Creating a kubernetes client @ 04/17/23 07:21:26.045
  Apr 17 07:21:26.045: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename statefulset @ 04/17/23 07:21:26.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:21:26.049
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:21:26.05
  STEP: Creating service test in namespace statefulset-3345 @ 04/17/23 07:21:26.051
  STEP: Looking for a node to schedule stateful set and pod @ 04/17/23 07:21:26.052
  STEP: Creating pod with conflicting port in namespace statefulset-3345 @ 04/17/23 07:21:26.053
  STEP: Waiting until pod test-pod will start running in namespace statefulset-3345 @ 04/17/23 07:21:26.056
  STEP: Creating statefulset with conflicting port in namespace statefulset-3345 @ 04/17/23 07:21:28.06
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3345 @ 04/17/23 07:21:28.061
  Apr 17 07:21:28.065: INFO: Observed stateful pod in namespace: statefulset-3345, name: ss-0, uid: a266b6f8-1488-4c37-b8aa-5698291a591d, status phase: Pending. Waiting for statefulset controller to delete.
  Apr 17 07:21:28.069: INFO: Observed stateful pod in namespace: statefulset-3345, name: ss-0, uid: a266b6f8-1488-4c37-b8aa-5698291a591d, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 17 07:21:28.071: INFO: Observed stateful pod in namespace: statefulset-3345, name: ss-0, uid: a266b6f8-1488-4c37-b8aa-5698291a591d, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 17 07:21:28.071: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3345
  STEP: Removing pod with conflicting port in namespace statefulset-3345 @ 04/17/23 07:21:28.071
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3345 and will be in running state @ 04/17/23 07:21:28.074
  Apr 17 07:21:30.078: INFO: Deleting all statefulset in ns statefulset-3345
  Apr 17 07:21:30.082: INFO: Scaling statefulset ss to 0
  Apr 17 07:21:40.098: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 17 07:21:40.099: INFO: Deleting statefulset ss
  Apr 17 07:21:40.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3345" for this suite. @ 04/17/23 07:21:40.104
â€¢ [14.062 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:137
  STEP: Creating a kubernetes client @ 04/17/23 07:21:40.107
  Apr 17 07:21:40.107: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 07:21:40.107
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:21:40.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:21:40.113
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/17/23 07:21:40.114
  STEP: Saw pod success @ 04/17/23 07:21:44.122
  Apr 17 07:21:44.123: INFO: Trying to get logs from node c3-worker pod pod-dc17625b-3687-4e4f-a4e1-16759b2022e0 container test-container: <nil>
  STEP: delete the pod @ 04/17/23 07:21:44.125
  Apr 17 07:21:44.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8273" for this suite. @ 04/17/23 07:21:44.13
â€¢ [4.024 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 04/17/23 07:21:44.132
  Apr 17 07:21:44.132: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename var-expansion @ 04/17/23 07:21:44.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:21:44.135
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:21:44.136
  STEP: Creating a pod to test env composition @ 04/17/23 07:21:44.137
  STEP: Saw pod success @ 04/17/23 07:21:48.145
  Apr 17 07:21:48.146: INFO: Trying to get logs from node c3-worker pod var-expansion-ce1628e0-35e9-4aec-b48e-d5b8a76cc778 container dapi-container: <nil>
  STEP: delete the pod @ 04/17/23 07:21:48.148
  Apr 17 07:21:48.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3049" for this suite. @ 04/17/23 07:21:48.154
â€¢ [4.024 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]
test/e2e/apps/statefulset.go:852
  STEP: Creating a kubernetes client @ 04/17/23 07:21:48.156
  Apr 17 07:21:48.156: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename statefulset @ 04/17/23 07:21:48.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:21:48.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:21:48.161
  STEP: Creating service test in namespace statefulset-74 @ 04/17/23 07:21:48.162
  STEP: Creating statefulset ss in namespace statefulset-74 @ 04/17/23 07:21:48.163
  Apr 17 07:21:48.166: INFO: Found 0 stateful pods, waiting for 1
  Apr 17 07:21:58.170: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 04/17/23 07:21:58.172
  STEP: updating a scale subresource @ 04/17/23 07:21:58.173
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/17/23 07:21:58.174
  STEP: Patch a scale subresource @ 04/17/23 07:21:58.175
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/17/23 07:21:58.177
  Apr 17 07:21:58.178: INFO: Deleting all statefulset in ns statefulset-74
  Apr 17 07:21:58.179: INFO: Scaling statefulset ss to 0
  Apr 17 07:22:08.187: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 17 07:22:08.188: INFO: Deleting statefulset ss
  Apr 17 07:22:08.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-74" for this suite. @ 04/17/23 07:22:08.192
â€¢ [20.038 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:250
  STEP: Creating a kubernetes client @ 04/17/23 07:22:08.194
  Apr 17 07:22:08.194: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:22:08.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:22:08.199
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:22:08.2
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 07:22:08.201
  STEP: Saw pod success @ 04/17/23 07:22:12.21
  Apr 17 07:22:12.210: INFO: Trying to get logs from node c3-worker pod downwardapi-volume-46db1581-8d92-4189-a82a-27c2f7548a3b container client-container: <nil>
  STEP: delete the pod @ 04/17/23 07:22:12.213
  Apr 17 07:22:12.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2803" for this suite. @ 04/17/23 07:22:12.217
â€¢ [4.025 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 04/17/23 07:22:12.219
  Apr 17 07:22:12.219: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubelet-test @ 04/17/23 07:22:12.219
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:22:12.223
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:22:12.224
  Apr 17 07:22:14.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5328" for this suite. @ 04/17/23 07:22:14.235
â€¢ [2.018 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:99
  STEP: Creating a kubernetes client @ 04/17/23 07:22:14.237
  Apr 17 07:22:14.237: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 07:22:14.237
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:22:14.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:22:14.242
  STEP: Creating configMap with name configmap-test-volume-map-50b2360a-e64c-45bb-a638-0fc711caed2c @ 04/17/23 07:22:14.243
  STEP: Creating a pod to test consume configMaps @ 04/17/23 07:22:14.244
  STEP: Saw pod success @ 04/17/23 07:22:18.252
  Apr 17 07:22:18.253: INFO: Trying to get logs from node c3-worker2 pod pod-configmaps-bfdf3aa3-faf7-4b96-86fb-eeba8c9485f2 container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 07:22:18.261
  Apr 17 07:22:18.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6075" for this suite. @ 04/17/23 07:22:18.267
â€¢ [4.032 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]
test/e2e/apimachinery/webhook.go:209
  STEP: Creating a kubernetes client @ 04/17/23 07:22:18.269
  Apr 17 07:22:18.269: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 07:22:18.269
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:22:18.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:22:18.275
  STEP: Setting up server cert @ 04/17/23 07:22:18.281
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 07:22:18.434
  STEP: Deploying the webhook pod @ 04/17/23 07:22:18.436
  STEP: Wait for the deployment to be ready @ 04/17/23 07:22:18.439
  Apr 17 07:22:18.441: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 07:22:20.445
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 07:22:20.447
  Apr 17 07:22:21.448: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/17/23 07:22:21.449
  STEP: create a pod @ 04/17/23 07:22:21.456
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 04/17/23 07:22:23.461
  Apr 17 07:22:23.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=webhook-8512 attach --namespace=webhook-8512 to-be-attached-pod -i -c=container1'
  Apr 17 07:22:23.510: INFO: rc: 1
  Apr 17 07:22:23.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8512" for this suite. @ 04/17/23 07:22:23.522
  STEP: Destroying namespace "webhook-markers-67" for this suite. @ 04/17/23 07:22:23.523
â€¢ [5.256 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]
test/e2e/apimachinery/resource_quota.go:328
  STEP: Creating a kubernetes client @ 04/17/23 07:22:23.525
  Apr 17 07:22:23.525: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename resourcequota @ 04/17/23 07:22:23.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:22:23.529
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:22:23.53
  STEP: Counting existing ResourceQuota @ 04/17/23 07:22:40.533
  STEP: Creating a ResourceQuota @ 04/17/23 07:22:45.535
  STEP: Ensuring resource quota status is calculated @ 04/17/23 07:22:45.536
  STEP: Creating a ConfigMap @ 04/17/23 07:22:47.539
  STEP: Ensuring resource quota status captures configMap creation @ 04/17/23 07:22:47.542
  STEP: Deleting a ConfigMap @ 04/17/23 07:22:49.545
  STEP: Ensuring resource quota status released usage @ 04/17/23 07:22:49.546
  Apr 17 07:22:51.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-894" for this suite. @ 04/17/23 07:22:51.549
â€¢ [28.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 04/17/23 07:22:51.551
  Apr 17 07:22:51.551: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename dns @ 04/17/23 07:22:51.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:22:51.555
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:22:51.556
  STEP: Creating a test headless service @ 04/17/23 07:22:51.557
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3410.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3410.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 04/17/23 07:22:51.559
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3410.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3410.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 04/17/23 07:22:51.559
  STEP: creating a pod to probe DNS @ 04/17/23 07:22:51.559
  STEP: submitting the pod to kubernetes @ 04/17/23 07:22:51.559
  STEP: retrieving the pod @ 04/17/23 07:22:53.564
  STEP: looking for the results for each expected name from probers @ 04/17/23 07:22:53.565
  Apr 17 07:22:53.569: INFO: Unable to read jessie_hosts@dns-querier-2.dns-test-service-2.dns-3410.svc.cluster.local from pod dns-3410/dns-test-aa1669cc-46b8-464f-b11f-e6dfa897024e: the server could not find the requested resource (get pods dns-test-aa1669cc-46b8-464f-b11f-e6dfa897024e)
  Apr 17 07:22:53.570: INFO: Unable to read jessie_hosts@dns-querier-2 from pod dns-3410/dns-test-aa1669cc-46b8-464f-b11f-e6dfa897024e: the server could not find the requested resource (get pods dns-test-aa1669cc-46b8-464f-b11f-e6dfa897024e)
  Apr 17 07:22:53.570: INFO: Lookups using dns-3410/dns-test-aa1669cc-46b8-464f-b11f-e6dfa897024e failed for: [jessie_hosts@dns-querier-2.dns-test-service-2.dns-3410.svc.cluster.local jessie_hosts@dns-querier-2]

  Apr 17 07:22:58.576: INFO: DNS probes using dns-3410/dns-test-aa1669cc-46b8-464f-b11f-e6dfa897024e succeeded

  Apr 17 07:22:58.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 07:22:58.577
  STEP: deleting the test headless service @ 04/17/23 07:22:58.58
  STEP: Destroying namespace "dns-3410" for this suite. @ 04/17/23 07:22:58.583
â€¢ [7.034 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 04/17/23 07:22:58.585
  Apr 17 07:22:58.585: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:22:58.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:22:58.589
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:22:58.59
  STEP: Creating projection with secret that has name projected-secret-test-map-c815af17-5abc-4a33-b67f-f73d571806d2 @ 04/17/23 07:22:58.591
  STEP: Creating a pod to test consume secrets @ 04/17/23 07:22:58.592
  STEP: Saw pod success @ 04/17/23 07:23:02.598
  Apr 17 07:23:02.599: INFO: Trying to get logs from node c3-worker pod pod-projected-secrets-d57eb026-2c4d-48a7-94c9-c11555af3da1 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 07:23:02.603
  Apr 17 07:23:02.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9223" for this suite. @ 04/17/23 07:23:02.607
â€¢ [4.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:124
  STEP: Creating a kubernetes client @ 04/17/23 07:23:02.609
  Apr 17 07:23:02.609: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:23:02.609
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:23:02.613
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:23:02.614
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-26c41209-2d56-4808-9b71-9dacd19743ed @ 04/17/23 07:23:02.616
  STEP: Creating the pod @ 04/17/23 07:23:02.618
  STEP: Updating configmap projected-configmap-test-upd-26c41209-2d56-4808-9b71-9dacd19743ed @ 04/17/23 07:23:04.627
  STEP: waiting to observe update in volume @ 04/17/23 07:23:04.628
  Apr 17 07:24:24.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3297" for this suite. @ 04/17/23 07:24:24.792
â€¢ [82.185 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 04/17/23 07:24:24.794
  Apr 17 07:24:24.794: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename deployment @ 04/17/23 07:24:24.795
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:24:24.799
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:24:24.8
  Apr 17 07:24:24.802: INFO: Creating deployment "webserver-deployment"
  Apr 17 07:24:24.804: INFO: Waiting for observed generation 1
  Apr 17 07:24:26.807: INFO: Waiting for all required pods to come up
  Apr 17 07:24:26.808: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 04/17/23 07:24:26.808
  Apr 17 07:24:26.808: INFO: Waiting for deployment "webserver-deployment" to complete
  Apr 17 07:24:26.810: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Apr 17 07:24:26.813: INFO: Updating deployment webserver-deployment
  Apr 17 07:24:26.813: INFO: Waiting for observed generation 2
  Apr 17 07:24:28.817: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Apr 17 07:24:28.818: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Apr 17 07:24:28.818: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 17 07:24:28.821: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Apr 17 07:24:28.821: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Apr 17 07:24:28.822: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 17 07:24:28.823: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Apr 17 07:24:28.823: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Apr 17 07:24:28.827: INFO: Updating deployment webserver-deployment
  Apr 17 07:24:28.827: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Apr 17 07:24:28.828: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Apr 17 07:24:28.829: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Apr 17 07:24:30.832: INFO: Deployment "webserver-deployment":
  &Deployment{ObjectMeta:{webserver-deployment  deployment-4581  0477e424-2d6a-4932-88de-e19440684b0c 57517 3 2023-04-17 07:24:24 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00610c8a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:20,UnavailableReplicas:13,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-17 07:24:28 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-7b75d79cf5" is progressing.,LastUpdateTime:2023-04-17 07:24:29 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,},},ReadyReplicas:20,CollisionCount:nil,},}

  Apr 17 07:24:30.834: INFO: New ReplicaSet "webserver-deployment-7b75d79cf5" of Deployment "webserver-deployment":
  &ReplicaSet{ObjectMeta:{webserver-deployment-7b75d79cf5  deployment-4581  a480feb7-b52f-439d-8d02-85921d594f3f 57383 3 2023-04-17 07:24:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 0477e424-2d6a-4932-88de-e19440684b0c 0xc002da8eb7 0xc002da8eb8}] [] [{kube-controller-manager Update apps/v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0477e424-2d6a-4932-88de-e19440684b0c\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 7b75d79cf5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002da8f58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 17 07:24:30.834: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Apr 17 07:24:30.834: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-67bd4bf6dc  deployment-4581  8772a614-5a5c-4efa-a595-19ede418d766 57516 3 2023-04-17 07:24:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 0477e424-2d6a-4932-88de-e19440684b0c 0xc002da8dc7 0xc002da8dc8}] [] [{kube-controller-manager Update apps/v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0477e424-2d6a-4932-88de-e19440684b0c\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 67bd4bf6dc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002da8e58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:20,AvailableReplicas:20,Conditions:[]ReplicaSetCondition{},},}
  Apr 17 07:24:30.836: INFO: Pod "webserver-deployment-67bd4bf6dc-2cjcb" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-2cjcb webserver-deployment-67bd4bf6dc- deployment-4581  a9c885d4-4e15-4a7d-a8fc-b6f3330932df 57233 0 2023-04-17 07:24:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc00610cc77 0xc00610cc78}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.201\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2bmhg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2bmhg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.201,StartTime:2023-04-17 07:24:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://25b92ba715b520cb6efeb787308ea3c2adc35de47c9a2e08475cf51f7a1c729f,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.201,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.836: INFO: Pod "webserver-deployment-67bd4bf6dc-2zs7k" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-2zs7k webserver-deployment-67bd4bf6dc- deployment-4581  db99956f-221f-4ff9-9c51-d15f11c58291 57485 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc00610ce60 0xc00610ce61}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.212\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nqntn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nqntn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.212,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://84d7c5f392b0a1c51b662bc46dfe418153343d002f76eb4a5f02f1a104113913,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.212,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-4g987" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-4g987 webserver-deployment-67bd4bf6dc- deployment-4581  57d34882-5f81-46f0-bd75-e77dac845e3b 57255 0 2023-04-17 07:24:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc00610d060 0xc00610d061}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mlsm2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mlsm2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.15,StartTime:2023-04-17 07:24:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://896a6c8ad3f84a66e90b5654db65f2e574cef125191a2f5432f4837a875e17d1,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.15,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-4zvsz" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-4zvsz webserver-deployment-67bd4bf6dc- deployment-4581  431c0f53-3e48-4314-ac33-017deedd522b 57507 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc00610d240 0xc00610d241}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.27\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gcwtj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gcwtj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.27,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://6ae585b24373158f289b4b24feb29a54ad1c9966d5acc200afa696ca58b1a095,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.27,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-7vm94" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-7vm94 webserver-deployment-67bd4bf6dc- deployment-4581  4f09fc87-defe-4398-9b3e-d1da2fe5aa5b 57234 0 2023-04-17 07:24:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc00610d420 0xc00610d421}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.16\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r2fv8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r2fv8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.16,StartTime:2023-04-17 07:24:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://a4df0142bd3f89e4d334d25b2ab86dd2a7bde81d39d83022921e894687999f38,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.16,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-89rw7" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-89rw7 webserver-deployment-67bd4bf6dc- deployment-4581  89e75b4c-7285-44d6-862b-ffe25c951ca6 57495 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc00610d600 0xc00610d601}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.28\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dgczd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dgczd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.28,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://7c1e5de3b6aaec14c6d9187d95e1aa4670d4229d8ccfc5cb0252ab85626b0775,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.28,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-9z9tc" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-9z9tc webserver-deployment-67bd4bf6dc- deployment-4581  eed6205c-2ffb-4824-8788-79dd8ca79249 57501 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc00610d7e0 0xc00610d7e1}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-27khc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-27khc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.21,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://bfc2f0a99a552d4eb00114ad8160afa240006a4bd90fba52a3263fda92c86d48,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.21,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-cnjfj" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-cnjfj webserver-deployment-67bd4bf6dc- deployment-4581  c5faee41-c9e9-48d2-8489-8587f8d04c91 57254 0 2023-04-17 07:24:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc00610d9c0 0xc00610d9c1}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.199\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-48ntt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-48ntt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.199,StartTime:2023-04-17 07:24:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://4fc1799417a5550f4a24c24ad9ac67b0eba58a6c99c375847f20c2e95d70af69,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.199,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-cprrm" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-cprrm webserver-deployment-67bd4bf6dc- deployment-4581  84bb3ff2-9e34-4540-8fa9-1c95a2c33c2e 57249 0 2023-04-17 07:24:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc00610dba0 0xc00610dba1}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kf46r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kf46r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.12,StartTime:2023-04-17 07:24:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://e7734df2ccf79a87d2076bcba318670497ae4a91ed64b94cc94766c6e8c77fd5,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.12,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-f4wfw" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-f4wfw webserver-deployment-67bd4bf6dc- deployment-4581  62579fd0-a877-4296-baf6-a337003678a2 57505 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc00610dd80 0xc00610dd81}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.29\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8jxbk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8jxbk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.29,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://d2b0923f271c24329d450bffd9c4f520f5752d9fd5107326d2c68903bdb41c6f,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.29,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-fgmdw" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-fgmdw webserver-deployment-67bd4bf6dc- deployment-4581  6727296c-0b62-409c-883a-ff4a6d7a72f2 57498 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc00610df60 0xc00610df61}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.20\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9v4gd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9v4gd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.20,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://ceacaa14f5eb7bc22364d2aaebd28e2729bfc9b47408bb94d02b8b20d4738d18,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.20,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-gkjmp" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-gkjmp webserver-deployment-67bd4bf6dc- deployment-4581  0f9f20c3-aaf3-4a2b-9c0d-324a0c4878b4 57502 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc005ec2140 0xc005ec2141}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.204\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ghnqk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ghnqk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.204,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://9ddf87393b1b9ddfef1835e2ed5486c8f182339de2f81aedd1e766375db3d5f5,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.204,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-jskvj" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-jskvj webserver-deployment-67bd4bf6dc- deployment-4581  61119ab1-76b4-4f4a-b0a9-0d1daa16689e 57503 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc005ec2320 0xc005ec2321}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.22\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gmgbc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gmgbc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.22,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://14e6ecfc1e3574c5368385e148a7ec358eb960f455041144dbb6b2497f860a93,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.22,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-k2gk2" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-k2gk2 webserver-deployment-67bd4bf6dc- deployment-4581  090c3513-c366-48e8-a31f-230992118d8f 57242 0 2023-04-17 07:24:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc005ec2500 0xc005ec2501}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.200\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-46kv4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-46kv4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.200,StartTime:2023-04-17 07:24:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://76b8a637c2ca1859443af58dcb04946c07622d12aeea00dde1001b84e2f281e5,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.200,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.837: INFO: Pod "webserver-deployment-67bd4bf6dc-nrbbb" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-nrbbb webserver-deployment-67bd4bf6dc- deployment-4581  17fd3aaa-8b38-482a-b25e-f73fd916dee2 57486 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc005ec2700 0xc005ec2701}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.24\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-flc6c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-flc6c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.24,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://73b61646d9bed6fa76aae5cc7e018833a0201b11f14ed27ba4605fa65afd1f47,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.24,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-67bd4bf6dc-p8k44" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-p8k44 webserver-deployment-67bd4bf6dc- deployment-4581  1fc5e6a8-4950-43d4-8bac-1b9b90e917ad 57494 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc005ec28e0 0xc005ec28e1}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.208\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-brhzl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-brhzl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.208,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://57679f988cdf03919cc11be3b5a57f857fd0777389e1c8b7ce4ab576defde447,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.208,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-67bd4bf6dc-qs52j" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-qs52j webserver-deployment-67bd4bf6dc- deployment-4581  db63fdbe-a20b-4d5b-a6e7-17a35925a3dd 57236 0 2023-04-17 07:24:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc005ec2ac0 0xc005ec2ac1}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.197\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z2dhn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z2dhn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.197,StartTime:2023-04-17 07:24:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://ae3866504a09635a95cd07e251ac65801453fe06385a5e9993c2569e374e2cf9,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.197,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-67bd4bf6dc-tntp2" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-tntp2 webserver-deployment-67bd4bf6dc- deployment-4581  ccc7409e-5c04-429e-87a0-d250f0791590 57482 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc005ec2ca0 0xc005ec2ca1}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.211\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dwjh7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dwjh7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.211,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://d14957de91ccdcea0e7a1bfabfe9d5ad4708d829e4b4d7b78a08fdb21dc98e9f,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.211,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-67bd4bf6dc-wlvzc" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-wlvzc webserver-deployment-67bd4bf6dc- deployment-4581  47131c52-db3e-4478-b40e-6b0ef422f8ed 57500 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc005ec2e80 0xc005ec2e81}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.207\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d7xqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d7xqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.207,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://650b522a55248e875c35f4402ae56d6be43e69713f9ec70e9e58e80a7f6afe8b,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.207,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-67bd4bf6dc-zm7mk" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-zm7mk webserver-deployment-67bd4bf6dc- deployment-4581  bdf4a54a-b4f1-45d2-b6f6-6d44c969661e 57248 0 2023-04-17 07:24:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 8772a614-5a5c-4efa-a595-19ede418d766 0xc005ec3060 0xc005ec3061}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8772a614-5a5c-4efa-a595-19ede418d766\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.198\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tb7rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tb7rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.198,StartTime:2023-04-17 07:24:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 07:24:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://ba805cb7bd4fd0d7d72babbe9d8dd50f0647f8e47bc72338ab740d329a589d59,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.198,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-7b75d79cf5-4cpqb" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-4cpqb webserver-deployment-7b75d79cf5- deployment-4581  4897a7cf-be38-4e99-97e6-507f0893755c 57403 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc005ec3240 0xc005ec3241}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-b9vhc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-b9vhc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-7b75d79cf5-5xn5v" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-5xn5v webserver-deployment-7b75d79cf5- deployment-4581  ace90550-5b87-43be-862e-cbacad4e8d12 57397 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc005ec3420 0xc005ec3421}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v2vxt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v2vxt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-7b75d79cf5-8llnz" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-8llnz webserver-deployment-7b75d79cf5- deployment-4581  e492384d-b359-4218-9f6d-8e31eb0405ee 57506 0 2023-04-17 07:24:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc005ec3600 0xc005ec3601}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.19\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hhzjp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hhzjp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.19,StartTime:2023-04-17 07:24:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.19,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-7b75d79cf5-9hzv7" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-9hzv7 webserver-deployment-7b75d79cf5- deployment-4581  603bc8b0-7962-4318-bd34-94f3241fd71a 57418 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc005ec3810 0xc005ec3811}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2f2wq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2f2wq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-7b75d79cf5-brcdn" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-brcdn webserver-deployment-7b75d79cf5- deployment-4581  27a0bb3b-b049-4a91-9c9c-f2d9124720ba 57504 0 2023-04-17 07:24:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc005ec39f0 0xc005ec39f1}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.203\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dl2ns,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dl2ns,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.203,StartTime:2023-04-17 07:24:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.203,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-7b75d79cf5-gffrq" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-gffrq webserver-deployment-7b75d79cf5- deployment-4581  96d4dbe3-bfae-4fb1-86b1-eef58b606889 57286 0 2023-04-17 07:24:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc005ec3c00 0xc005ec3c01}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xsbwp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xsbwp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:,StartTime:2023-04-17 07:24:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-7b75d79cf5-gvljd" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-gvljd webserver-deployment-7b75d79cf5- deployment-4581  f0b40dab-df86-413f-8629-900cc38f47b0 57535 0 2023-04-17 07:24:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc005ec3de0 0xc005ec3de1}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t2sxl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t2sxl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:10.244.1.18,StartTime:2023-04-17 07:24:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.18,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-7b75d79cf5-hb6xm" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-hb6xm webserver-deployment-7b75d79cf5- deployment-4581  169cbaf3-2c97-4156-9ef7-e5c749a261f2 57415 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc005ec3ff0 0xc005ec3ff1}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hvqqv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hvqqv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.838: INFO: Pod "webserver-deployment-7b75d79cf5-hsdkw" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-hsdkw webserver-deployment-7b75d79cf5- deployment-4581  63700e28-ad68-4e92-86ce-8dd6c3a940b9 57388 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc0009fe1d0 0xc0009fe1d1}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-85kns,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-85kns,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.839: INFO: Pod "webserver-deployment-7b75d79cf5-trrdk" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-trrdk webserver-deployment-7b75d79cf5- deployment-4581  75ac96d3-1096-46fa-b95a-6269be7df230 57411 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc0009fe3b0 0xc0009fe3b1}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6brlm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6brlm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.839: INFO: Pod "webserver-deployment-7b75d79cf5-tw4wk" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-tw4wk webserver-deployment-7b75d79cf5- deployment-4581  48c97cba-8e38-4a7d-bd40-c975e26ea6a1 57402 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc0009fe5a0 0xc0009fe5a1}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ckj5p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ckj5p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.839: INFO: Pod "webserver-deployment-7b75d79cf5-tzj7t" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-tzj7t webserver-deployment-7b75d79cf5- deployment-4581  5490158d-7781-479b-9217-9790d1ca4c45 57532 0 2023-04-17 07:24:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc0009fe780 0xc0009fe781}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.202\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kmcmz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kmcmz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.202,StartTime:2023-04-17 07:24:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.202,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.839: INFO: Pod "webserver-deployment-7b75d79cf5-zx8b4" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-zx8b4 webserver-deployment-7b75d79cf5- deployment-4581  3c8b3568-7b42-4162-8e76-bc59eee26c35 57387 0 2023-04-17 07:24:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 a480feb7-b52f-439d-8d02-85921d594f3f 0xc0009fe990 0xc0009fe991}] [] [{kube-controller-manager Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a480feb7-b52f-439d-8d02-85921d594f3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 07:24:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rk4kp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rk4kp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 07:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.3,PodIP:,StartTime:2023-04-17 07:24:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 07:24:30.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4581" for this suite. @ 04/17/23 07:24:30.84
â€¢ [6.048 seconds]
------------------------------
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 04/17/23 07:24:30.842
  Apr 17 07:24:30.842: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubelet-test @ 04/17/23 07:24:30.843
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:24:30.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:24:30.848
  Apr 17 07:24:30.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1435" for this suite. @ 04/17/23 07:24:30.857
â€¢ [0.017 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]
test/e2e/apps/statefulset.go:327
  STEP: Creating a kubernetes client @ 04/17/23 07:24:30.859
  Apr 17 07:24:30.859: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename statefulset @ 04/17/23 07:24:30.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:24:30.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:24:30.864
  STEP: Creating service test in namespace statefulset-154 @ 04/17/23 07:24:30.865
  STEP: Creating a new StatefulSet @ 04/17/23 07:24:30.866
  Apr 17 07:24:30.869: INFO: Found 0 stateful pods, waiting for 3
  Apr 17 07:24:40.871: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 17 07:24:40.871: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 17 07:24:40.871: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/17/23 07:24:40.875
  Apr 17 07:24:40.888: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/17/23 07:24:40.888
  STEP: Not applying an update when the partition is greater than the number of replicas @ 04/17/23 07:24:50.893
  STEP: Performing a canary update @ 04/17/23 07:24:50.893
  Apr 17 07:24:50.906: INFO: Updating stateful set ss2
  Apr 17 07:24:50.908: INFO: Waiting for Pod statefulset-154/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  STEP: Restoring Pods to the correct revision when they are deleted @ 04/17/23 07:25:00.912
  Apr 17 07:25:00.920: INFO: Found 1 stateful pods, waiting for 3
  Apr 17 07:25:10.922: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 17 07:25:10.922: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 17 07:25:10.922: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 04/17/23 07:25:10.924
  Apr 17 07:25:10.940: INFO: Updating stateful set ss2
  Apr 17 07:25:10.942: INFO: Waiting for Pod statefulset-154/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Apr 17 07:25:20.960: INFO: Updating stateful set ss2
  Apr 17 07:25:20.962: INFO: Waiting for StatefulSet statefulset-154/ss2 to complete update
  Apr 17 07:25:20.962: INFO: Waiting for Pod statefulset-154/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Apr 17 07:25:30.965: INFO: Deleting all statefulset in ns statefulset-154
  Apr 17 07:25:30.966: INFO: Scaling statefulset ss2 to 0
  Apr 17 07:25:40.973: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 17 07:25:40.974: INFO: Deleting statefulset ss2
  Apr 17 07:25:40.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-154" for this suite. @ 04/17/23 07:25:40.979
â€¢ [70.122 seconds]
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2187
  STEP: Creating a kubernetes client @ 04/17/23 07:25:40.981
  Apr 17 07:25:40.981: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 07:25:40.981
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:25:40.985
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:25:40.986
  STEP: creating service in namespace services-4273 @ 04/17/23 07:25:40.987
  STEP: creating service affinity-clusterip-transition in namespace services-4273 @ 04/17/23 07:25:40.987
  STEP: creating replication controller affinity-clusterip-transition in namespace services-4273 @ 04/17/23 07:25:40.99
  I0417 07:25:40.991891      30 runners.go:194] Created replication controller with name: affinity-clusterip-transition, namespace: services-4273, replica count: 3
  I0417 07:25:44.042725      30 runners.go:194] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 17 07:25:44.045: INFO: Creating new exec pod
  Apr 17 07:25:47.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4273 exec execpod-affinitynvx2x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Apr 17 07:25:47.152: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Apr 17 07:25:47.152: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:25:47.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4273 exec execpod-affinitynvx2x -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.19.33 80'
  Apr 17 07:25:47.267: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.19.33 80\nConnection to 10.96.19.33 80 port [tcp/http] succeeded!\n"
  Apr 17 07:25:47.267: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:25:47.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4273 exec execpod-affinitynvx2x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.19.33:80/ ; done'
  Apr 17 07:25:47.393: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n"
  Apr 17 07:25:47.393: INFO: stdout: "\naffinity-clusterip-transition-xbq4t\naffinity-clusterip-transition-xbq4t\naffinity-clusterip-transition-xbq4t\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-xbq4t\naffinity-clusterip-transition-xbq4t\naffinity-clusterip-transition-xbq4t\naffinity-clusterip-transition-xbq4t\naffinity-clusterip-transition-t2mmc\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-t2mmc\naffinity-clusterip-transition-t2mmc\naffinity-clusterip-transition-t2mmc\naffinity-clusterip-transition-t2mmc"
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-xbq4t
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-xbq4t
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-xbq4t
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-xbq4t
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-xbq4t
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-xbq4t
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-xbq4t
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-t2mmc
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-t2mmc
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-t2mmc
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-t2mmc
  Apr 17 07:25:47.393: INFO: Received response from host: affinity-clusterip-transition-t2mmc
  Apr 17 07:25:47.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4273 exec execpod-affinitynvx2x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.19.33:80/ ; done'
  Apr 17 07:25:47.537: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n"
  Apr 17 07:25:47.537: INFO: stdout: "\naffinity-clusterip-transition-t2mmc\naffinity-clusterip-transition-xbq4t\naffinity-clusterip-transition-xbq4t\naffinity-clusterip-transition-t2mmc\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-t2mmc\naffinity-clusterip-transition-xbq4t\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r"
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-t2mmc
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-xbq4t
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-xbq4t
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-t2mmc
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-t2mmc
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-xbq4t
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:25:47.537: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4273 exec execpod-affinitynvx2x -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.19.33:80/ ; done'
  Apr 17 07:26:17.692: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.19.33:80/\n"
  Apr 17 07:26:17.693: INFO: stdout: "\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r\naffinity-clusterip-transition-4z88r"
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Received response from host: affinity-clusterip-transition-4z88r
  Apr 17 07:26:17.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 17 07:26:17.694: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-4273, will wait for the garbage collector to delete the pods @ 04/17/23 07:26:17.698
  Apr 17 07:26:17.751: INFO: Deleting ReplicationController affinity-clusterip-transition took: 1.731284ms
  Apr 17 07:26:17.851: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.245508ms
  STEP: Destroying namespace "services-4273" for this suite. @ 04/17/23 07:26:20.956
â€¢ [39.977 seconds]
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
test/e2e/apimachinery/aggregator.go:92
  STEP: Creating a kubernetes client @ 04/17/23 07:26:20.958
  Apr 17 07:26:20.958: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename aggregator @ 04/17/23 07:26:20.958
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:26:20.961
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:26:20.962
  Apr 17 07:26:20.964: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Registering the sample API server. @ 04/17/23 07:26:20.964
  Apr 17 07:26:21.085: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Apr 17 07:26:21.092: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
  Apr 17 07:26:23.105: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:26:25.108: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:26:27.108: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:26:29.108: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:26:31.108: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:26:33.109: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:26:35.108: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:26:37.107: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:26:39.109: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:26:41.107: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:26:43.164: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:26:45.107: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 17 07:26:47.215: INFO: Waited 105.113091ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 04/17/23 07:26:47.23
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 04/17/23 07:26:47.231
  STEP: List APIServices @ 04/17/23 07:26:47.233
  Apr 17 07:26:47.235: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 04/17/23 07:26:47.235
  Apr 17 07:26:47.243: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 04/17/23 07:26:47.243
  Apr 17 07:26:47.248: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2023, time.April, 17, 7, 26, 47, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 04/17/23 07:26:47.248
  Apr 17 07:26:47.249: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2023-04-17 07:26:47 +0000 UTC Passed all checks passed}
  Apr 17 07:26:47.249: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 17 07:26:47.249: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 04/17/23 07:26:47.249
  Apr 17 07:26:47.254: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete APIService "dynamic-flunder-693939089" @ 04/17/23 07:26:47.254
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 04/17/23 07:26:47.263
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 04/17/23 07:26:47.265
  STEP: Patch APIService Status @ 04/17/23 07:26:47.266
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 04/17/23 07:26:47.268
  Apr 17 07:26:47.269: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2023-04-17 07:26:47 +0000 UTC Passed all checks passed}
  Apr 17 07:26:47.269: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 17 07:26:47.269: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Apr 17 07:26:47.269: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "e2e-apiservice=patched" @ 04/17/23 07:26:47.269
  STEP: Confirm that the generated APIService has been deleted @ 04/17/23 07:26:47.271
  Apr 17 07:26:47.271: INFO: Requesting list of APIServices to confirm quantity
  Apr 17 07:26:47.272: INFO: Found 0 APIService with label "e2e-apiservice=patched"
  Apr 17 07:26:47.272: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Apr 17 07:26:47.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-5366" for this suite. @ 04/17/23 07:26:47.316
â€¢ [26.360 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:347
  STEP: Creating a kubernetes client @ 04/17/23 07:26:47.318
  Apr 17 07:26:47.318: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename security-context-test @ 04/17/23 07:26:47.318
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:26:47.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:26:47.324
  Apr 17 07:26:51.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-7797" for this suite. @ 04/17/23 07:26:51.334
â€¢ [4.017 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance]
test/e2e/network/ingress.go:556
  STEP: Creating a kubernetes client @ 04/17/23 07:26:51.335
  Apr 17 07:26:51.335: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename ingress @ 04/17/23 07:26:51.336
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:26:51.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:26:51.341
  STEP: getting /apis @ 04/17/23 07:26:51.342
  STEP: getting /apis/networking.k8s.io @ 04/17/23 07:26:51.343
  STEP: getting /apis/networking.k8s.iov1 @ 04/17/23 07:26:51.344
  STEP: creating @ 04/17/23 07:26:51.344
  STEP: getting @ 04/17/23 07:26:51.349
  STEP: listing @ 04/17/23 07:26:51.35
  STEP: watching @ 04/17/23 07:26:51.351
  Apr 17 07:26:51.351: INFO: starting watch
  STEP: cluster-wide listing @ 04/17/23 07:26:51.351
  STEP: cluster-wide watching @ 04/17/23 07:26:51.352
  Apr 17 07:26:51.352: INFO: starting watch
  STEP: patching @ 04/17/23 07:26:51.352
  STEP: updating @ 04/17/23 07:26:51.354
  Apr 17 07:26:51.356: INFO: waiting for watch events with expected annotations
  Apr 17 07:26:51.356: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/17/23 07:26:51.356
  STEP: updating /status @ 04/17/23 07:26:51.358
  STEP: get /status @ 04/17/23 07:26:51.36
  STEP: deleting @ 04/17/23 07:26:51.361
  STEP: deleting a collection @ 04/17/23 07:26:51.363
  Apr 17 07:26:51.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-7885" for this suite. @ 04/17/23 07:26:51.368
â€¢ [0.034 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]
test/e2e/apps/daemon_set.go:825
  STEP: Creating a kubernetes client @ 04/17/23 07:26:51.37
  Apr 17 07:26:51.370: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename daemonsets @ 04/17/23 07:26:51.37
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:26:51.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:26:51.374
  STEP: Creating simple DaemonSet "daemon-set" @ 04/17/23 07:26:51.38
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/17/23 07:26:51.382
  Apr 17 07:26:51.383: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 07:26:51.383: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 07:26:51.383: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 07:26:52.385: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 07:26:52.386: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 17 07:26:52.386: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: listing all DaemonSets @ 04/17/23 07:26:52.387
  STEP: DeleteCollection of the DaemonSets @ 04/17/23 07:26:52.388
  STEP: Verify that ReplicaSets have been deleted @ 04/17/23 07:26:52.389
  Apr 17 07:26:52.392: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"58612"},"items":null}

  Apr 17 07:26:52.394: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"58612"},"items":[{"metadata":{"name":"daemon-set-4pmd9","generateName":"daemon-set-","namespace":"daemonsets-3048","uid":"f91373f2-07c2-4b87-9738-58212857fb43","resourceVersion":"58612","creationTimestamp":"2023-04-17T07:26:51Z","deletionTimestamp":"2023-04-17T07:27:22Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6974d7cff5","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"1e729a0e-321f-49cb-aab9-381d0afe8e6c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-17T07:26:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e729a0e-321f-49cb-aab9-381d0afe8e6c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-17T07:26:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.219\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-b5wjg","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-b5wjg","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"c3-worker2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["c3-worker2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-17T07:26:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-17T07:26:51Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-17T07:26:51Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-17T07:26:51Z"}],"hostIP":"172.18.0.4","podIP":"10.244.2.219","podIPs":[{"ip":"10.244.2.219"}],"startTime":"2023-04-17T07:26:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-17T07:26:51Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://dabba37110c61e199cb8931788fdf29ad8e0629dee584cc5cadcd06b787c1ed1","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-75tnx","generateName":"daemon-set-","namespace":"daemonsets-3048","uid":"7a6dcf4d-8e05-41a9-b9d1-e8fdae73b8f5","resourceVersion":"58611","creationTimestamp":"2023-04-17T07:26:51Z","deletionTimestamp":"2023-04-17T07:27:22Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6974d7cff5","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"1e729a0e-321f-49cb-aab9-381d0afe8e6c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-17T07:26:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1e729a0e-321f-49cb-aab9-381d0afe8e6c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-17T07:26:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.39\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-s6t5f","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-s6t5f","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"c3-worker","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["c3-worker"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-17T07:26:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-17T07:26:51Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-17T07:26:51Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-17T07:26:51Z"}],"hostIP":"172.18.0.3","podIP":"10.244.1.39","podIPs":[{"ip":"10.244.1.39"}],"startTime":"2023-04-17T07:26:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-17T07:26:51Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://ed79e789439a82372bf04b11e71c98fe472e4c308fb9d6a2461d4bdeb647e866","started":true}],"qosClass":"BestEffort"}}]}

  Apr 17 07:26:52.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3048" for this suite. @ 04/17/23 07:26:52.398
â€¢ [1.029 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance]
test/e2e/apps/replica_set.go:154
  STEP: Creating a kubernetes client @ 04/17/23 07:26:52.4
  Apr 17 07:26:52.400: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename replicaset @ 04/17/23 07:26:52.401
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:26:52.404
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:26:52.405
  Apr 17 07:26:52.409: INFO: Pod name sample-pod: Found 0 pods out of 1
  Apr 17 07:26:57.411: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/17/23 07:26:57.411
  STEP: Scaling up "test-rs" replicaset  @ 04/17/23 07:26:57.411
  Apr 17 07:26:57.414: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 04/17/23 07:26:57.414
  W0417 07:26:57.416348      30 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Apr 17 07:26:57.416: INFO: observed ReplicaSet test-rs in namespace replicaset-8635 with ReadyReplicas 1, AvailableReplicas 1
  Apr 17 07:26:57.420: INFO: observed ReplicaSet test-rs in namespace replicaset-8635 with ReadyReplicas 1, AvailableReplicas 1
  Apr 17 07:26:57.423: INFO: observed ReplicaSet test-rs in namespace replicaset-8635 with ReadyReplicas 1, AvailableReplicas 1
  Apr 17 07:26:57.425: INFO: observed ReplicaSet test-rs in namespace replicaset-8635 with ReadyReplicas 1, AvailableReplicas 1
  Apr 17 07:26:57.991: INFO: observed ReplicaSet test-rs in namespace replicaset-8635 with ReadyReplicas 2, AvailableReplicas 2
  Apr 17 07:26:58.988: INFO: observed Replicaset test-rs in namespace replicaset-8635 with ReadyReplicas 3 found true
  Apr 17 07:26:58.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8635" for this suite. @ 04/17/23 07:26:58.989
â€¢ [6.591 seconds]
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 04/17/23 07:26:58.991
  Apr 17 07:26:58.991: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename taint-multiple-pods @ 04/17/23 07:26:58.992
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:26:58.996
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:26:58.997
  Apr 17 07:26:58.998: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 17 07:27:59.007: INFO: Waiting for terminating namespaces to be deleted...
  Apr 17 07:27:59.007: INFO: Starting informer...
  STEP: Starting pods... @ 04/17/23 07:27:59.007
  Apr 17 07:27:59.213: INFO: Pod1 is running on c3-worker. Tainting Node
  Apr 17 07:28:01.422: INFO: Pod2 is running on c3-worker. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/17/23 07:28:01.422
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/17/23 07:28:01.426
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 04/17/23 07:28:01.427
  Apr 17 07:28:07.077: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  Apr 17 07:28:27.101: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  Apr 17 07:28:27.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/17/23 07:28:27.107
  STEP: Destroying namespace "taint-multiple-pods-3247" for this suite. @ 04/17/23 07:28:27.108
â€¢ [88.119 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
test/e2e/apps/statefulset.go:591
  STEP: Creating a kubernetes client @ 04/17/23 07:28:27.11
  Apr 17 07:28:27.110: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename statefulset @ 04/17/23 07:28:27.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:28:27.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:28:27.116
  STEP: Creating service test in namespace statefulset-5792 @ 04/17/23 07:28:27.117
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 04/17/23 07:28:27.119
  STEP: Creating stateful set ss in namespace statefulset-5792 @ 04/17/23 07:28:27.12
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5792 @ 04/17/23 07:28:27.122
  Apr 17 07:28:27.123: INFO: Found 0 stateful pods, waiting for 1
  Apr 17 07:28:37.125: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 04/17/23 07:28:37.125
  Apr 17 07:28:37.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-5792 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 17 07:28:37.233: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 17 07:28:37.233: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 17 07:28:37.233: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 17 07:28:37.234: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  Apr 17 07:28:47.237: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 17 07:28:47.237: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 17 07:28:47.242: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999809s
  Apr 17 07:28:48.244: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.998791741s
  Apr 17 07:28:49.246: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.996854496s
  Apr 17 07:28:50.247: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.995166461s
  Apr 17 07:28:51.249: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.993713901s
  Apr 17 07:28:52.251: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.992095252s
  Apr 17 07:28:53.253: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.990272009s
  Apr 17 07:28:54.254: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.988403516s
  Apr 17 07:28:55.256: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.986649936s
  Apr 17 07:28:56.258: INFO: Verifying statefulset ss doesn't scale past 1 for another 984.305058ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5792 @ 04/17/23 07:28:57.258
  Apr 17 07:28:57.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-5792 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 17 07:28:57.376: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 17 07:28:57.376: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 17 07:28:57.376: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 17 07:28:57.378: INFO: Found 1 stateful pods, waiting for 3
  Apr 17 07:29:07.382: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 17 07:29:07.382: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 17 07:29:07.382: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 04/17/23 07:29:07.382
  STEP: Scale down will halt with unhealthy stateful pod @ 04/17/23 07:29:07.382
  Apr 17 07:29:07.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-5792 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 17 07:29:07.496: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 17 07:29:07.496: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 17 07:29:07.496: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 17 07:29:07.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-5792 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 17 07:29:07.612: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 17 07:29:07.612: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 17 07:29:07.612: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 17 07:29:07.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-5792 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 17 07:29:07.740: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 17 07:29:07.740: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 17 07:29:07.740: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 17 07:29:07.740: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 17 07:29:07.741: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
  Apr 17 07:29:17.746: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 17 07:29:17.746: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 17 07:29:17.746: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Apr 17 07:29:17.750: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999985s
  Apr 17 07:29:18.752: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.998877617s
  Apr 17 07:29:19.753: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.997004989s
  Apr 17 07:29:20.755: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.995585743s
  Apr 17 07:29:21.756: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.993909162s
  Apr 17 07:29:22.758: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.992203044s
  Apr 17 07:29:23.761: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.990031158s
  Apr 17 07:29:24.762: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.987878858s
  Apr 17 07:29:25.764: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.986268967s
  Apr 17 07:29:26.766: INFO: Verifying statefulset ss doesn't scale past 3 for another 983.967613ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5792 @ 04/17/23 07:29:27.767
  Apr 17 07:29:27.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-5792 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 17 07:29:27.877: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 17 07:29:27.877: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 17 07:29:27.877: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 17 07:29:27.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-5792 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 17 07:29:27.999: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 17 07:29:28.000: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 17 07:29:28.000: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 17 07:29:28.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=statefulset-5792 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 17 07:29:28.104: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 17 07:29:28.104: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 17 07:29:28.104: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 17 07:29:28.104: INFO: Scaling statefulset ss to 0
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 04/17/23 07:29:38.112
  Apr 17 07:29:38.112: INFO: Deleting all statefulset in ns statefulset-5792
  Apr 17 07:29:38.113: INFO: Scaling statefulset ss to 0
  Apr 17 07:29:38.117: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 17 07:29:38.117: INFO: Deleting statefulset ss
  Apr 17 07:29:38.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5792" for this suite. @ 04/17/23 07:29:38.121
â€¢ [71.013 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 04/17/23 07:29:38.123
  Apr 17 07:29:38.123: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:29:38.124
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:29:38.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:29:38.128
  STEP: Creating projection with secret that has name projected-secret-test-47aa79e3-fe7d-40a2-82dd-d2a773f296aa @ 04/17/23 07:29:38.129
  STEP: Creating a pod to test consume secrets @ 04/17/23 07:29:38.131
  STEP: Saw pod success @ 04/17/23 07:29:42.138
  Apr 17 07:29:42.139: INFO: Trying to get logs from node c3-worker pod pod-projected-secrets-5effb940-e561-4dc2-8e6c-bd49d86696fd container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 07:29:42.148
  Apr 17 07:29:42.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1696" for this suite. @ 04/17/23 07:29:42.152
â€¢ [4.031 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:255
  STEP: Creating a kubernetes client @ 04/17/23 07:29:42.154
  Apr 17 07:29:42.154: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename init-container @ 04/17/23 07:29:42.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:29:42.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:29:42.159
  STEP: creating the pod @ 04/17/23 07:29:42.16
  Apr 17 07:29:42.160: INFO: PodSpec: initContainers in spec.initContainers
  Apr 17 07:29:45.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-3480" for this suite. @ 04/17/23 07:29:45.208
â€¢ [3.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:177
  STEP: Creating a kubernetes client @ 04/17/23 07:29:45.21
  Apr 17 07:29:45.210: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 07:29:45.211
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:29:45.215
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:29:45.216
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/17/23 07:29:45.217
  STEP: Saw pod success @ 04/17/23 07:29:49.225
  Apr 17 07:29:49.226: INFO: Trying to get logs from node c3-worker pod pod-41d2c374-5c10-4a23-968f-53addabb5c22 container test-container: <nil>
  STEP: delete the pod @ 04/17/23 07:29:49.228
  Apr 17 07:29:49.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2782" for this suite. @ 04/17/23 07:29:49.233
â€¢ [4.024 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:89
  STEP: Creating a kubernetes client @ 04/17/23 07:29:49.235
  Apr 17 07:29:49.235: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 07:29:49.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:29:49.239
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:29:49.24
  STEP: Creating configMap with name configmap-test-volume-map-239036b9-42da-48ca-869e-a3fec0012ba6 @ 04/17/23 07:29:49.241
  STEP: Creating a pod to test consume configMaps @ 04/17/23 07:29:49.242
  STEP: Saw pod success @ 04/17/23 07:29:53.25
  Apr 17 07:29:53.251: INFO: Trying to get logs from node c3-worker pod pod-configmaps-016613cb-4be9-47e1-ad3b-162110253f73 container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 07:29:53.254
  Apr 17 07:29:53.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2954" for this suite. @ 04/17/23 07:29:53.26
â€¢ [4.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]
test/e2e/apimachinery/resource_quota.go:693
  STEP: Creating a kubernetes client @ 04/17/23 07:29:53.262
  Apr 17 07:29:53.262: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename resourcequota @ 04/17/23 07:29:53.262
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:29:53.266
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:29:53.267
  STEP: Creating a ResourceQuota with terminating scope @ 04/17/23 07:29:53.268
  STEP: Ensuring ResourceQuota status is calculated @ 04/17/23 07:29:53.269
  STEP: Creating a ResourceQuota with not terminating scope @ 04/17/23 07:29:55.271
  STEP: Ensuring ResourceQuota status is calculated @ 04/17/23 07:29:55.272
  STEP: Creating a long running pod @ 04/17/23 07:29:57.274
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 04/17/23 07:29:57.278
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 04/17/23 07:29:59.28
  STEP: Deleting the pod @ 04/17/23 07:30:01.282
  STEP: Ensuring resource quota status released the pod usage @ 04/17/23 07:30:01.285
  STEP: Creating a terminating pod @ 04/17/23 07:30:03.286
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 04/17/23 07:30:03.29
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 04/17/23 07:30:05.292
  STEP: Deleting the pod @ 04/17/23 07:30:07.294
  STEP: Ensuring resource quota status released the pod usage @ 04/17/23 07:30:07.297
  Apr 17 07:30:09.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5422" for this suite. @ 04/17/23 07:30:09.301
â€¢ [16.041 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 04/17/23 07:30:09.303
  Apr 17 07:30:09.303: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename field-validation @ 04/17/23 07:30:09.304
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:30:09.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:30:09.308
  STEP: apply creating a deployment @ 04/17/23 07:30:09.31
  Apr 17 07:30:09.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7815" for this suite. @ 04/17/23 07:30:09.314
â€¢ [0.012 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance]
test/e2e/network/service.go:3113
  STEP: Creating a kubernetes client @ 04/17/23 07:30:09.316
  Apr 17 07:30:09.316: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 07:30:09.316
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:30:09.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:30:09.32
  STEP: fetching services @ 04/17/23 07:30:09.321
  Apr 17 07:30:09.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-801" for this suite. @ 04/17/23 07:30:09.323
â€¢ [0.009 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]
test/e2e/apps/rc.go:85
  STEP: Creating a kubernetes client @ 04/17/23 07:30:09.325
  Apr 17 07:30:09.325: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename replication-controller @ 04/17/23 07:30:09.325
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:30:09.329
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:30:09.33
  Apr 17 07:30:09.330: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 04/17/23 07:30:10.334
  STEP: Checking rc "condition-test" has the desired failure condition set @ 04/17/23 07:30:10.336
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 04/17/23 07:30:11.338
  Apr 17 07:30:11.341: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 04/17/23 07:30:11.341
  Apr 17 07:30:12.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-914" for this suite. @ 04/17/23 07:30:12.345
â€¢ [3.022 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]
test/e2e/apimachinery/resource_quota.go:395
  STEP: Creating a kubernetes client @ 04/17/23 07:30:12.347
  Apr 17 07:30:12.347: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename resourcequota @ 04/17/23 07:30:12.347
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:30:12.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:30:12.352
  STEP: Counting existing ResourceQuota @ 04/17/23 07:30:12.353
  STEP: Creating a ResourceQuota @ 04/17/23 07:30:17.355
  STEP: Ensuring resource quota status is calculated @ 04/17/23 07:30:17.357
  STEP: Creating a ReplicationController @ 04/17/23 07:30:19.36
  STEP: Ensuring resource quota status captures replication controller creation @ 04/17/23 07:30:19.364
  STEP: Deleting a ReplicationController @ 04/17/23 07:30:21.366
  STEP: Ensuring resource quota status released usage @ 04/17/23 07:30:21.367
  Apr 17 07:30:23.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7351" for this suite. @ 04/17/23 07:30:23.37
â€¢ [11.025 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]
test/e2e/apimachinery/resource_quota.go:1013
  STEP: Creating a kubernetes client @ 04/17/23 07:30:23.372
  Apr 17 07:30:23.372: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename resourcequota @ 04/17/23 07:30:23.373
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:30:23.377
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:30:23.378
  STEP: Creating resourceQuota "e2e-rq-status-pq4lg" @ 04/17/23 07:30:23.38
  Apr 17 07:30:23.382: INFO: Resource quota "e2e-rq-status-pq4lg" reports spec: hard cpu limit of 500m
  Apr 17 07:30:23.382: INFO: Resource quota "e2e-rq-status-pq4lg" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-pq4lg" /status @ 04/17/23 07:30:23.382
  STEP: Confirm /status for "e2e-rq-status-pq4lg" resourceQuota via watch @ 04/17/23 07:30:23.384
  Apr 17 07:30:23.385: INFO: observed resourceQuota "e2e-rq-status-pq4lg" in namespace "resourcequota-6322" with hard status: v1.ResourceList(nil)
  Apr 17 07:30:23.385: INFO: Found resourceQuota "e2e-rq-status-pq4lg" in namespace "resourcequota-6322" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 17 07:30:23.385: INFO: ResourceQuota "e2e-rq-status-pq4lg" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 04/17/23 07:30:23.385
  Apr 17 07:30:23.387: INFO: Resource quota "e2e-rq-status-pq4lg" reports spec: hard cpu limit of 1
  Apr 17 07:30:23.387: INFO: Resource quota "e2e-rq-status-pq4lg" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-pq4lg" /status @ 04/17/23 07:30:23.387
  STEP: Confirm /status for "e2e-rq-status-pq4lg" resourceQuota via watch @ 04/17/23 07:30:23.389
  Apr 17 07:30:23.389: INFO: observed resourceQuota "e2e-rq-status-pq4lg" in namespace "resourcequota-6322" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 17 07:30:23.389: INFO: Found resourceQuota "e2e-rq-status-pq4lg" in namespace "resourcequota-6322" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Apr 17 07:30:23.389: INFO: ResourceQuota "e2e-rq-status-pq4lg" /status was patched
  STEP: Get "e2e-rq-status-pq4lg" /status @ 04/17/23 07:30:23.389
  Apr 17 07:30:23.390: INFO: Resourcequota "e2e-rq-status-pq4lg" reports status: hard cpu of 1
  Apr 17 07:30:23.390: INFO: Resourcequota "e2e-rq-status-pq4lg" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-pq4lg" /status before checking Spec is unchanged @ 04/17/23 07:30:23.391
  Apr 17 07:30:23.392: INFO: Resourcequota "e2e-rq-status-pq4lg" reports status: hard cpu of 2
  Apr 17 07:30:23.392: INFO: Resourcequota "e2e-rq-status-pq4lg" reports status: hard memory of 2Gi
  Apr 17 07:30:23.393: INFO: Found resourceQuota "e2e-rq-status-pq4lg" in namespace "resourcequota-6322" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  Apr 17 07:33:28.398: INFO: ResourceQuota "e2e-rq-status-pq4lg" Spec was unchanged and /status reset
  Apr 17 07:33:28.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6322" for this suite. @ 04/17/23 07:33:28.399
â€¢ [185.028 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster  [Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 04/17/23 07:33:28.403
  Apr 17 07:33:28.403: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename dns @ 04/17/23 07:33:28.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:33:28.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:33:28.408
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/17/23 07:33:28.409
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/17/23 07:33:28.409
  STEP: creating a pod to probe DNS @ 04/17/23 07:33:28.409
  STEP: submitting the pod to kubernetes @ 04/17/23 07:33:28.409
  STEP: retrieving the pod @ 04/17/23 07:33:30.416
  STEP: looking for the results for each expected name from probers @ 04/17/23 07:33:30.417
  Apr 17 07:33:30.421: INFO: DNS probes using dns-590/dns-test-8bfdcdb0-28e0-464e-9487-6fb587030735 succeeded

  Apr 17 07:33:30.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 07:33:30.422
  STEP: Destroying namespace "dns-590" for this suite. @ 04/17/23 07:33:30.426
â€¢ [2.024 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:213
  STEP: Creating a kubernetes client @ 04/17/23 07:33:30.428
  Apr 17 07:33:30.428: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/17/23 07:33:30.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:33:30.432
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:33:30.433
  STEP: create the container to handle the HTTPGet hook request. @ 04/17/23 07:33:30.435
  STEP: create the pod with lifecycle hook @ 04/17/23 07:33:32.442
  STEP: delete the pod with lifecycle hook @ 04/17/23 07:33:34.447
  STEP: check prestop hook @ 04/17/23 07:33:36.452
  Apr 17 07:33:36.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4462" for this suite. @ 04/17/23 07:33:36.463
â€¢ [6.037 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:109
  STEP: Creating a kubernetes client @ 04/17/23 07:33:36.465
  Apr 17 07:33:36.465: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 07:33:36.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:33:36.469
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:33:36.47
  STEP: Creating configMap with name configmap-test-volume-map-7ff1196a-97ca-4b08-9acf-86651df461eb @ 04/17/23 07:33:36.471
  STEP: Creating a pod to test consume configMaps @ 04/17/23 07:33:36.472
  STEP: Saw pod success @ 04/17/23 07:33:40.48
  Apr 17 07:33:40.481: INFO: Trying to get logs from node c3-worker pod pod-configmaps-ff1af067-6d6b-4f8a-866c-5236ecbc7cde container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 07:33:40.489
  Apr 17 07:33:40.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5569" for this suite. @ 04/17/23 07:33:40.493
â€¢ [4.031 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]
test/e2e/auth/service_accounts.go:740
  STEP: Creating a kubernetes client @ 04/17/23 07:33:40.495
  Apr 17 07:33:40.495: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename svcaccounts @ 04/17/23 07:33:40.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:33:40.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:33:40.501
  Apr 17 07:33:40.503: INFO: Got root ca configmap in namespace "svcaccounts-11"
  Apr 17 07:33:40.504: INFO: Deleted root ca configmap in namespace "svcaccounts-11"
  STEP: waiting for a new root ca configmap created @ 04/17/23 07:33:41.005
  Apr 17 07:33:41.006: INFO: Recreated root ca configmap in namespace "svcaccounts-11"
  Apr 17 07:33:41.008: INFO: Updated root ca configmap in namespace "svcaccounts-11"
  STEP: waiting for the root ca configmap reconciled @ 04/17/23 07:33:41.508
  Apr 17 07:33:41.509: INFO: Reconciled root ca configmap in namespace "svcaccounts-11"
  Apr 17 07:33:41.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-11" for this suite. @ 04/17/23 07:33:41.511
â€¢ [1.016 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 04/17/23 07:33:41.512
  Apr 17 07:33:41.512: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename cronjob @ 04/17/23 07:33:41.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:33:41.516
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:33:41.517
  STEP: Creating a cronjob @ 04/17/23 07:33:41.518
  STEP: Ensuring more than one job is running at a time @ 04/17/23 07:33:41.52
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 04/17/23 07:35:01.522
  STEP: Removing cronjob @ 04/17/23 07:35:01.523
  Apr 17 07:35:01.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3376" for this suite. @ 04/17/23 07:35:01.526
â€¢ [80.015 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 04/17/23 07:35:01.528
  Apr 17 07:35:01.528: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 07:35:01.528
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:35:01.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:35:01.533
  STEP: Creating secret with name secret-test-a45fb37f-9dd7-41bb-87eb-42731c9efd1f @ 04/17/23 07:35:01.534
  STEP: Creating a pod to test consume secrets @ 04/17/23 07:35:01.535
  STEP: Saw pod success @ 04/17/23 07:35:05.543
  Apr 17 07:35:05.544: INFO: Trying to get logs from node c3-worker pod pod-secrets-01a46c22-6fc4-4f8b-ae87-7b4b927338af container secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 07:35:05.547
  Apr 17 07:35:05.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2652" for this suite. @ 04/17/23 07:35:05.552
â€¢ [4.026 seconds]
------------------------------
S
------------------------------
[sig-network] Services should serve multiport endpoints from pods  [Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 04/17/23 07:35:05.554
  Apr 17 07:35:05.554: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 07:35:05.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:35:05.558
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:35:05.559
  STEP: creating service multi-endpoint-test in namespace services-9493 @ 04/17/23 07:35:05.56
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9493 to expose endpoints map[] @ 04/17/23 07:35:05.562
  Apr 17 07:35:05.563: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  Apr 17 07:35:06.565: INFO: successfully validated that service multi-endpoint-test in namespace services-9493 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-9493 @ 04/17/23 07:35:06.565
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9493 to expose endpoints map[pod1:[100]] @ 04/17/23 07:35:08.572
  Apr 17 07:35:08.574: INFO: successfully validated that service multi-endpoint-test in namespace services-9493 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-9493 @ 04/17/23 07:35:08.574
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9493 to expose endpoints map[pod1:[100] pod2:[101]] @ 04/17/23 07:35:10.579
  Apr 17 07:35:10.583: INFO: successfully validated that service multi-endpoint-test in namespace services-9493 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 04/17/23 07:35:10.583
  Apr 17 07:35:10.583: INFO: Creating new exec pod
  Apr 17 07:35:13.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-9493 exec execpodhttd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Apr 17 07:35:13.700: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Apr 17 07:35:13.700: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:35:13.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-9493 exec execpodhttd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.246.251 80'
  Apr 17 07:35:13.783: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.246.251 80\nConnection to 10.96.246.251 80 port [tcp/http] succeeded!\n"
  Apr 17 07:35:13.783: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:35:13.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-9493 exec execpodhttd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Apr 17 07:35:13.901: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Apr 17 07:35:13.901: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:35:13.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-9493 exec execpodhttd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.246.251 81'
  Apr 17 07:35:14.024: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.246.251 81\nConnection to 10.96.246.251 81 port [tcp/*] succeeded!\n"
  Apr 17 07:35:14.024: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-9493 @ 04/17/23 07:35:14.024
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9493 to expose endpoints map[pod2:[101]] @ 04/17/23 07:35:14.028
  Apr 17 07:35:14.032: INFO: successfully validated that service multi-endpoint-test in namespace services-9493 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-9493 @ 04/17/23 07:35:14.032
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9493 to expose endpoints map[] @ 04/17/23 07:35:14.034
  Apr 17 07:35:15.040: INFO: successfully validated that service multi-endpoint-test in namespace services-9493 exposes endpoints map[]
  Apr 17 07:35:15.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9493" for this suite. @ 04/17/23 07:35:15.046
â€¢ [9.495 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]
test/e2e/network/endpointslice.go:68
  STEP: Creating a kubernetes client @ 04/17/23 07:35:15.049
  Apr 17 07:35:15.049: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename endpointslice @ 04/17/23 07:35:15.049
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:35:15.054
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:35:15.055
  Apr 17 07:35:15.058: INFO: Endpoints addresses: [172.18.0.2] , ports: [6443]
  Apr 17 07:35:15.058: INFO: EndpointSlices addresses: [172.18.0.2] , ports: [6443]
  Apr 17 07:35:15.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-8710" for this suite. @ 04/17/23 07:35:15.06
â€¢ [0.012 seconds]
------------------------------
S
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 04/17/23 07:35:15.061
  Apr 17 07:35:15.061: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-probe @ 04/17/23 07:35:15.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:35:15.065
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:35:15.066
  STEP: Creating pod test-webserver-f71be0ac-be67-4637-b746-acba44c461bb in namespace container-probe-5426 @ 04/17/23 07:35:15.067
  Apr 17 07:35:17.073: INFO: Started pod test-webserver-f71be0ac-be67-4637-b746-acba44c461bb in namespace container-probe-5426
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/17/23 07:35:17.073
  Apr 17 07:35:17.074: INFO: Initial restart count of pod test-webserver-f71be0ac-be67-4637-b746-acba44c461bb is 0
  Apr 17 07:39:17.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 07:39:17.361
  STEP: Destroying namespace "container-probe-5426" for this suite. @ 04/17/23 07:39:17.364
â€¢ [242.305 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:157
  STEP: Creating a kubernetes client @ 04/17/23 07:39:17.366
  Apr 17 07:39:17.366: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 07:39:17.366
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:39:17.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:39:17.371
  STEP: Creating a pod to test emptydir volume type on node default medium @ 04/17/23 07:39:17.372
  STEP: Saw pod success @ 04/17/23 07:39:19.377
  Apr 17 07:39:19.378: INFO: Trying to get logs from node c3-worker pod pod-0498a5ea-c6c1-4325-a395-f881d97885df container test-container: <nil>
  STEP: delete the pod @ 04/17/23 07:39:19.386
  Apr 17 07:39:19.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2083" for this suite. @ 04/17/23 07:39:19.391
â€¢ [2.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]
test/e2e/apps/controller_revision.go:124
  STEP: Creating a kubernetes client @ 04/17/23 07:39:19.393
  Apr 17 07:39:19.393: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename controllerrevisions @ 04/17/23 07:39:19.393
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:39:19.397
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:39:19.397
  STEP: Creating DaemonSet "e2e-zb2c8-daemon-set" @ 04/17/23 07:39:19.403
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/17/23 07:39:19.404
  Apr 17 07:39:19.405: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 07:39:19.406: INFO: Number of nodes with available pods controlled by daemonset e2e-zb2c8-daemon-set: 0
  Apr 17 07:39:19.406: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 07:39:20.408: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 07:39:20.409: INFO: Number of nodes with available pods controlled by daemonset e2e-zb2c8-daemon-set: 0
  Apr 17 07:39:20.409: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 07:39:21.408: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 07:39:21.409: INFO: Number of nodes with available pods controlled by daemonset e2e-zb2c8-daemon-set: 2
  Apr 17 07:39:21.409: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-zb2c8-daemon-set
  STEP: Confirm DaemonSet "e2e-zb2c8-daemon-set" successfully created with "daemonset-name=e2e-zb2c8-daemon-set" label @ 04/17/23 07:39:21.411
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-zb2c8-daemon-set" @ 04/17/23 07:39:21.413
  Apr 17 07:39:21.414: INFO: Located ControllerRevision: "e2e-zb2c8-daemon-set-59cc7bbb8d"
  STEP: Patching ControllerRevision "e2e-zb2c8-daemon-set-59cc7bbb8d" @ 04/17/23 07:39:21.414
  Apr 17 07:39:21.417: INFO: e2e-zb2c8-daemon-set-59cc7bbb8d has been patched
  STEP: Create a new ControllerRevision @ 04/17/23 07:39:21.417
  Apr 17 07:39:21.419: INFO: Created ControllerRevision: e2e-zb2c8-daemon-set-75c548ccf4
  STEP: Confirm that there are two ControllerRevisions @ 04/17/23 07:39:21.419
  Apr 17 07:39:21.419: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 17 07:39:21.420: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-zb2c8-daemon-set-59cc7bbb8d" @ 04/17/23 07:39:21.42
  STEP: Confirm that there is only one ControllerRevision @ 04/17/23 07:39:21.421
  Apr 17 07:39:21.421: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 17 07:39:21.422: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-zb2c8-daemon-set-75c548ccf4" @ 04/17/23 07:39:21.422
  Apr 17 07:39:21.425: INFO: e2e-zb2c8-daemon-set-75c548ccf4 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 04/17/23 07:39:21.425
  W0417 07:39:21.427226      30 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 04/17/23 07:39:21.427
  Apr 17 07:39:21.427: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 17 07:39:22.428: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 17 07:39:22.429: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-zb2c8-daemon-set-75c548ccf4=updated" @ 04/17/23 07:39:22.429
  STEP: Confirm that there is only one ControllerRevision @ 04/17/23 07:39:22.431
  Apr 17 07:39:22.431: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 17 07:39:22.431: INFO: Found 1 ControllerRevisions
  Apr 17 07:39:22.432: INFO: ControllerRevision "e2e-zb2c8-daemon-set-5f65d68d8c" has revision 3
  STEP: Deleting DaemonSet "e2e-zb2c8-daemon-set" @ 04/17/23 07:39:22.433
  STEP: deleting DaemonSet.extensions e2e-zb2c8-daemon-set in namespace controllerrevisions-4908, will wait for the garbage collector to delete the pods @ 04/17/23 07:39:22.433
  Apr 17 07:39:22.486: INFO: Deleting DaemonSet.extensions e2e-zb2c8-daemon-set took: 1.964353ms
  Apr 17 07:39:22.587: INFO: Terminating DaemonSet.extensions e2e-zb2c8-daemon-set pods took: 100.683208ms
  Apr 17 07:39:24.989: INFO: Number of nodes with available pods controlled by daemonset e2e-zb2c8-daemon-set: 0
  Apr 17 07:39:24.989: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-zb2c8-daemon-set
  Apr 17 07:39:24.990: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"60800"},"items":null}

  Apr 17 07:39:24.991: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"60800"},"items":null}

  Apr 17 07:39:24.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-4908" for this suite. @ 04/17/23 07:39:24.995
â€¢ [5.604 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance]
test/e2e/common/node/secrets.go:154
  STEP: Creating a kubernetes client @ 04/17/23 07:39:24.997
  Apr 17 07:39:24.997: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 07:39:24.997
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:39:25.001
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:39:25.002
  STEP: creating a secret @ 04/17/23 07:39:25.003
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 04/17/23 07:39:25.004
  STEP: patching the secret @ 04/17/23 07:39:25.005
  STEP: deleting the secret using a LabelSelector @ 04/17/23 07:39:25.008
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 04/17/23 07:39:25.01
  Apr 17 07:39:25.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5382" for this suite. @ 04/17/23 07:39:25.012
â€¢ [0.017 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 04/17/23 07:39:25.014
  Apr 17 07:39:25.014: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pods @ 04/17/23 07:39:25.015
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:39:25.018
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:39:25.019
  STEP: creating pod @ 04/17/23 07:39:25.02
  Apr 17 07:39:27.028: INFO: Pod pod-hostip-9588a020-f656-41ab-949d-e54012f39628 has hostIP: 172.18.0.3
  Apr 17 07:39:27.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6949" for this suite. @ 04/17/23 07:39:27.029
â€¢ [2.017 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 04/17/23 07:39:27.031
  Apr 17 07:39:27.031: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 07:39:27.032
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:39:27.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:39:27.037
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-5319 @ 04/17/23 07:39:27.038
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/17/23 07:39:27.041
  STEP: creating service externalsvc in namespace services-5319 @ 04/17/23 07:39:27.041
  STEP: creating replication controller externalsvc in namespace services-5319 @ 04/17/23 07:39:27.044
  I0417 07:39:27.045934      30 runners.go:194] Created replication controller with name: externalsvc, namespace: services-5319, replica count: 2
  I0417 07:39:30.097910      30 runners.go:194] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 04/17/23 07:39:30.099
  Apr 17 07:39:30.103: INFO: Creating new exec pod
  Apr 17 07:39:32.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-5319 exec execpodskcqn -- /bin/sh -x -c nslookup nodeport-service.services-5319.svc.cluster.local'
  Apr 17 07:39:32.772: INFO: stderr: "+ nslookup nodeport-service.services-5319.svc.cluster.local\n"
  Apr 17 07:39:32.772: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nNon-authoritative answer:\nName:\tnodeport-service.services-5319.svc.cluster.local.DOMAINS\nAddress: 3.64.163.50\n\n"
  Apr 17 07:39:32.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-5319, will wait for the garbage collector to delete the pods @ 04/17/23 07:39:32.774
  Apr 17 07:39:32.827: INFO: Deleting ReplicationController externalsvc took: 1.684134ms
  Apr 17 07:39:32.928: INFO: Terminating ReplicationController externalsvc pods took: 100.845029ms
  Apr 17 07:39:36.039: INFO: Cleaning up the NodePort to ExternalName test service
  STEP: Destroying namespace "services-5319" for this suite. @ 04/17/23 07:39:36.043
â€¢ [9.015 seconds]
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 04/17/23 07:39:36.047
  Apr 17 07:39:36.047: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-probe @ 04/17/23 07:39:36.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:39:36.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:39:36.052
  STEP: Creating pod liveness-72d8f2aa-5418-4f66-ae73-0971d0f5822e in namespace container-probe-2495 @ 04/17/23 07:39:36.053
  Apr 17 07:39:38.060: INFO: Started pod liveness-72d8f2aa-5418-4f66-ae73-0971d0f5822e in namespace container-probe-2495
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/17/23 07:39:38.06
  Apr 17 07:39:38.061: INFO: Initial restart count of pod liveness-72d8f2aa-5418-4f66-ae73-0971d0f5822e is 0
  Apr 17 07:43:38.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 07:43:38.368
  STEP: Destroying namespace "container-probe-2495" for this suite. @ 04/17/23 07:43:38.372
â€¢ [242.327 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]
test/e2e/apimachinery/webhook.go:370
  STEP: Creating a kubernetes client @ 04/17/23 07:43:38.374
  Apr 17 07:43:38.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 07:43:38.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:43:38.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:43:38.379
  STEP: Setting up server cert @ 04/17/23 07:43:38.385
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 07:43:38.506
  STEP: Deploying the webhook pod @ 04/17/23 07:43:38.509
  STEP: Wait for the deployment to be ready @ 04/17/23 07:43:38.513
  Apr 17 07:43:38.514: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 07:43:40.518
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 07:43:40.522
  Apr 17 07:43:41.522: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 04/17/23 07:43:41.523
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/17/23 07:43:41.523
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 04/17/23 07:43:41.53
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 04/17/23 07:43:42.534
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/17/23 07:43:42.534
  STEP: Having no error when timeout is longer than webhook latency @ 04/17/23 07:43:43.542
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/17/23 07:43:43.542
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 04/17/23 07:43:48.555
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/17/23 07:43:48.555
  Apr 17 07:43:53.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1271" for this suite. @ 04/17/23 07:43:53.578
  STEP: Destroying namespace "webhook-markers-982" for this suite. @ 04/17/23 07:43:53.58
â€¢ [15.207 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 04/17/23 07:43:53.582
  Apr 17 07:43:53.582: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename containers @ 04/17/23 07:43:53.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:43:53.586
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:43:53.587
  STEP: Creating a pod to test override all @ 04/17/23 07:43:53.588
  STEP: Saw pod success @ 04/17/23 07:43:55.594
  Apr 17 07:43:55.595: INFO: Trying to get logs from node c3-worker pod client-containers-107e0d90-5d0c-463c-baf0-15654ed79665 container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 07:43:55.604
  Apr 17 07:43:55.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-635" for this suite. @ 04/17/23 07:43:55.61
â€¢ [2.029 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]
test/e2e/apimachinery/webhook.go:118
  STEP: Creating a kubernetes client @ 04/17/23 07:43:55.611
  Apr 17 07:43:55.611: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 07:43:55.612
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:43:55.616
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:43:55.617
  STEP: Setting up server cert @ 04/17/23 07:43:55.623
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 07:43:55.992
  STEP: Deploying the webhook pod @ 04/17/23 07:43:55.994
  STEP: Wait for the deployment to be ready @ 04/17/23 07:43:55.997
  Apr 17 07:43:55.999: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 07:43:58.003
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 07:43:58.006
  Apr 17 07:43:59.006: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 04/17/23 07:43:59.008
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 04/17/23 07:43:59.008
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 04/17/23 07:43:59.008
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 04/17/23 07:43:59.008
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 04/17/23 07:43:59.009
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/17/23 07:43:59.009
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/17/23 07:43:59.009
  Apr 17 07:43:59.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7803" for this suite. @ 04/17/23 07:43:59.019
  STEP: Destroying namespace "webhook-markers-1338" for this suite. @ 04/17/23 07:43:59.02
â€¢ [3.410 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
test/e2e/auth/service_accounts.go:529
  STEP: Creating a kubernetes client @ 04/17/23 07:43:59.022
  Apr 17 07:43:59.022: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename svcaccounts @ 04/17/23 07:43:59.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:43:59.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:43:59.027
  Apr 17 07:43:59.031: INFO: created pod
  Apr 17 07:49:29.034: INFO: polling logs
  Apr 17 07:49:29.045: INFO: Pod logs: 
  I0417 07:43:59.605179       1 log.go:198] OK: Got token
  I0417 07:43:59.605199       1 log.go:198] validating with in-cluster discovery
  I0417 07:43:59.605380       1 log.go:198] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0417 07:43:59.605395       1 log.go:198] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7426:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1681718039, NotBefore:1681717439, IssuedAt:1681717439, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7426", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c92392a0-ca0b-43a1-a4a0-fed41b45630d"}}}
  I0417 07:44:00.482390       1 log.go:198] failed to validate with in-cluster discovery: Get "https://kubernetes.default.svc.cluster.local/.well-known/openid-configuration": x509: certificate is valid for undeveloped.com, undeveloped.es, undeveloped.cn, undeveloped.uk, undeveloped.eu, undeveloped.us, undeveloped.nl, undeveloped.be, undeveloped.co.uk, undeveloped.domains, dan.com, www.dan.com, undeveloped.fr, undeveloped.nu, not kubernetes.default.svc.cluster.local
  I0417 07:44:00.482403       1 log.go:198] falling back to validating with external discovery
  I0417 07:44:00.482478       1 log.go:198] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0417 07:44:00.482491       1 log.go:198] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7426:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1681718039, NotBefore:1681717439, IssuedAt:1681717439, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7426", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c92392a0-ca0b-43a1-a4a0-fed41b45630d"}}}
  I0417 07:44:01.372353       1 log.go:198] Get "https://kubernetes.default.svc.cluster.local/.well-known/openid-configuration": x509: certificate is valid for undeveloped.com, undeveloped.es, undeveloped.cn, undeveloped.uk, undeveloped.eu, undeveloped.us, undeveloped.nl, undeveloped.be, undeveloped.co.uk, undeveloped.domains, dan.com, www.dan.com, undeveloped.fr, undeveloped.nu, not kubernetes.default.svc.cluster.local

  Apr 17 07:49:29.045: INFO: Failed inside E2E framework:
      k8s.io/kubernetes/test/e2e/framework/pod.WaitForPodCondition({0x7f74bc2cc398, 0xc006476cf0}, {0x72b3890?, 0xc005ca0000?}, {0xc001eeac50, 0x10}, {0xc005532c78, 0x18}, {0xc005532d98, 0x13}, ...)
      	test/e2e/framework/pod/wait.go:228 +0x25f
      k8s.io/kubernetes/test/e2e/framework/pod.WaitForPodSuccessInNamespaceTimeout({0x7f74bc2cc398, 0xc006476cf0}, {0x72b3890, 0xc005ca0000}, {0xc005532c78, 0x18}, {0xc001eeac50, 0x10}, 0x0?)
      	test/e2e/framework/pod/wait.go:403 +0x177
      k8s.io/kubernetes/test/e2e/framework/pod.WaitForPodSuccessInNamespace(...)
      	test/e2e/framework/pod/wait.go:519
      k8s.io/kubernetes/test/e2e/auth.glob..func5.7({0x7f74bc2cc398?, 0xc006476cf0})
      	test/e2e/auth/service_accounts.go:617 +0xb1c
  [FAILED] in [It] - test/e2e/auth/service_accounts.go:635 @ 04/17/23 07:49:29.047
  Apr 17 07:49:29.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: dump namespace information after failure @ 04/17/23 07:49:29.048
  STEP: Collecting events from namespace "svcaccounts-7426". @ 04/17/23 07:49:29.048
  STEP: Found 4 events. @ 04/17/23 07:49:29.049
  Apr 17 07:49:29.049: INFO: At 2023-04-17 07:43:59 +0000 UTC - event for oidc-discovery-validator: {default-scheduler } Scheduled: Successfully assigned svcaccounts-7426/oidc-discovery-validator to c3-worker
  Apr 17 07:49:29.049: INFO: At 2023-04-17 07:43:59 +0000 UTC - event for oidc-discovery-validator: {kubelet c3-worker} Pulled: Container image "registry.k8s.io/e2e-test-images/agnhost:2.43" already present on machine
  Apr 17 07:49:29.049: INFO: At 2023-04-17 07:43:59 +0000 UTC - event for oidc-discovery-validator: {kubelet c3-worker} Created: Created container oidc-discovery-validator
  Apr 17 07:49:29.049: INFO: At 2023-04-17 07:43:59 +0000 UTC - event for oidc-discovery-validator: {kubelet c3-worker} Started: Started container oidc-discovery-validator
  Apr 17 07:49:29.051: INFO: POD                       NODE       PHASE   GRACE  CONDITIONS
  Apr 17 07:49:29.051: INFO: oidc-discovery-validator  c3-worker  Failed         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 07:43:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-17 07:44:02 +0000 UTC PodFailed } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-17 07:44:02 +0000 UTC PodFailed } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-17 07:43:59 +0000 UTC  }]
  Apr 17 07:49:29.051: INFO: 
  Apr 17 07:49:29.054: INFO: 
  Logging node info for node c3-control-plane
  Apr 17 07:49:29.055: INFO: Node Info: &Node{ObjectMeta:{c3-control-plane    629f5c81-a482-4eed-bde6-31d867b17658 61688 0 2023-04-16 23:18:07 +0000 UTC <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux kubernetes.io/arch:amd64 kubernetes.io/hostname:c3-control-plane kubernetes.io/os:linux node-role.kubernetes.io/control-plane: node.kubernetes.io/exclude-from-external-load-balancers:] map[kubeadm.alpha.kubernetes.io/cri-socket:unix:///run/containerd/containerd.sock node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true] [] [] [{kubelet Update v1 2023-04-16 23:18:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}},"f:spec":{"f:providerID":{}}} } {kubeadm Update v1 2023-04-16 23:18:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}},"f:labels":{"f:node-role.kubernetes.io/control-plane":{},"f:node.kubernetes.io/exclude-from-external-load-balancers":{}}}} } {kube-controller-manager Update v1 2023-04-16 23:18:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.0.0/24\"":{}},"f:taints":{}}} } {kubelet Update v1 2023-04-17 07:45:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:images":{}}} status}]},Spec:NodeSpec{PodCIDR:10.244.0.0/24,DoNotUseExternalID:,ProviderID:kind://docker/c3/c3-control-plane,Unschedulable:false,Taints:[]Taint{Taint{Key:node-role.kubernetes.io/control-plane,Value:,Effect:NoSchedule,TimeAdded:<nil>,},},ConfigSource:nil,PodCIDRs:[10.244.0.0/24],},Status:NodeStatus{Capacity:ResourceList{cpu: {{64 0} {<nil>} 64 DecimalSI},ephemeral-storage: {{233551093760 0} {<nil>}  BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{269851996160 0} {<nil>} 263527340Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{64 0} {<nil>} 64 DecimalSI},ephemeral-storage: {{233551093760 0} {<nil>}  BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{269851996160 0} {<nil>} 263527340Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2023-04-17 07:45:23 +0000 UTC,LastTransitionTime:2023-04-16 23:18:05 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2023-04-17 07:45:23 +0000 UTC,LastTransitionTime:2023-04-16 23:18:05 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2023-04-17 07:45:23 +0000 UTC,LastTransitionTime:2023-04-16 23:18:05 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2023-04-17 07:45:23 +0000 UTC,LastTransitionTime:2023-04-16 23:18:29 +0000 UTC,Reason:KubeletReady,Message:kubelet is posting ready status,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:172.18.0.2,},NodeAddress{Type:Hostname,Address:c3-control-plane,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:767839283df247938c9426a6b5ad4d25,SystemUUID:51c9e800-a9ee-4c59-a6d9-4c838bece296,BootID:6c31530c-b1ee-4d7b-9f9a-cd7e74053a70,KernelVersion:5.15.0-58-generic,OSImage:Ubuntu 22.04.2 LTS,ContainerRuntimeVersion:containerd://1.6.19-46-g941215f49,KubeletVersion:v1.27.0,KubeProxyVersion:v1.27.0,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[docker.io/sonobuoy/systemd-logs@sha256:0b8b2b7b43b03f7db26e7e4b99be402495b77b496f5a5b0425b3c226bc1e9cbd docker.io/sonobuoy/systemd-logs:v0.4],SizeBytes:127795048,},ContainerImage{Names:[registry.k8s.io/etcd:3.5.7-0],SizeBytes:101639218,},ContainerImage{Names:[docker.io/library/import-2023-04-11@sha256:1e9953bc5edfc7a95ee557bbbe582da753e6385833bf6c49bdc7e363bda2e7af registry.k8s.io/kube-apiserver:v1.27.0],SizeBytes:83427839,},ContainerImage{Names:[docker.io/library/import-2023-04-11@sha256:0b14caafa64dd35b5d5a10502811f0ba6d4b790215e38f86bdb641407cf8c069 registry.k8s.io/kube-controller-manager:v1.27.0],SizeBytes:74408077,},ContainerImage{Names:[docker.io/library/import-2023-04-11@sha256:bc131b7c57288fdbc7053d16b5488a509897c97429056decba9242675ed41d8c registry.k8s.io/kube-proxy:v1.27.0],SizeBytes:72702973,},ContainerImage{Names:[docker.io/library/import-2023-04-11@sha256:7443dcbb453e39f79e4863b0fb6f169e538aa6bb3ff7f9226f7d4c83571285b7 registry.k8s.io/kube-scheduler:v1.27.0],SizeBytes:59781773,},ContainerImage{Names:[docker.io/kindest/kindnetd:v20230330-48f316cd@sha256:c19d6362a6a928139820761475a38c24c0cf84d507b9ddf414a078cf627497af docker.io/kindest/kindnetd@sha256:c19d6362a6a928139820761475a38c24c0cf84d507b9ddf414a078cf627497af],SizeBytes:27726335,},ContainerImage{Names:[docker.io/sonobuoy/sonobuoy@sha256:8f9f3cd082287f5c5c2cce37251771ae6631b38fd71c7a5820be5d2d545a3a0c docker.io/sonobuoy/sonobuoy:v0.56.16],SizeBytes:20486754,},ContainerImage{Names:[docker.io/kindest/local-path-provisioner:v0.0.23-kind.0@sha256:f2d0a02831ff3a03cf51343226670d5060623b43a4cfc4808bd0875b2c4b9501 docker.io/kindest/local-path-provisioner@sha256:f2d0a02831ff3a03cf51343226670d5060623b43a4cfc4808bd0875b2c4b9501],SizeBytes:18664669,},ContainerImage{Names:[registry.k8s.io/coredns/coredns:v1.10.1],SizeBytes:16190758,},ContainerImage{Names:[docker.io/kindest/local-path-helper:v20230330-48f316cd@sha256:135203f2441f916fb13dad1561d27f60a6f11f50ec288b01a7d2ee9947c36270],SizeBytes:3052037,},ContainerImage{Names:[registry.k8s.io/pause:3.7],SizeBytes:311278,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}
  Apr 17 07:49:29.055: INFO: 
  Logging kubelet events for node c3-control-plane
  Apr 17 07:49:29.056: INFO: 
  Logging pods the kubelet thinks is on node c3-control-plane
  Apr 17 07:49:29.067: INFO: local-path-provisioner-5d7949c7d4-c5mv7 started at 2023-04-16 23:18:29 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.067: INFO: 	Container local-path-provisioner ready: true, restart count 0
  Apr 17 07:49:29.067: INFO: sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-b56js started at 2023-04-17 06:33:10 +0000 UTC (0+2 container statuses recorded)
  Apr 17 07:49:29.067: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 07:49:29.067: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 17 07:49:29.067: INFO: etcd-c3-control-plane started at 2023-04-16 23:18:10 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.067: INFO: 	Container etcd ready: true, restart count 0
  Apr 17 07:49:29.067: INFO: kube-controller-manager-c3-control-plane started at 2023-04-16 23:18:10 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.067: INFO: 	Container kube-controller-manager ready: true, restart count 0
  Apr 17 07:49:29.067: INFO: kube-proxy-dqrpp started at 2023-04-16 23:18:26 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.067: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 17 07:49:29.067: INFO: coredns-5d78c9869d-q9pjc started at 2023-04-16 23:18:29 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.067: INFO: 	Container coredns ready: true, restart count 0
  Apr 17 07:49:29.067: INFO: coredns-5d78c9869d-gdmwj started at 2023-04-16 23:18:29 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.067: INFO: 	Container coredns ready: true, restart count 0
  Apr 17 07:49:29.067: INFO: kube-apiserver-c3-control-plane started at 2023-04-16 23:18:10 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.067: INFO: 	Container kube-apiserver ready: true, restart count 0
  Apr 17 07:49:29.067: INFO: kube-scheduler-c3-control-plane started at 2023-04-16 23:18:10 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.067: INFO: 	Container kube-scheduler ready: true, restart count 0
  Apr 17 07:49:29.067: INFO: kindnet-qcvcz started at 2023-04-16 23:18:26 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.067: INFO: 	Container kindnet-cni ready: true, restart count 0
  Apr 17 07:49:29.096: INFO: 
  Latency metrics for node c3-control-plane
  Apr 17 07:49:29.096: INFO: 
  Logging node info for node c3-worker
  Apr 17 07:49:29.097: INFO: Node Info: &Node{ObjectMeta:{c3-worker    f97506c8-e8a4-48aa-9ded-6334de00cd05 61831 0 2023-04-16 23:18:29 +0000 UTC <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux kubernetes.io/arch:amd64 kubernetes.io/hostname:c3-worker kubernetes.io/os:linux] map[kubeadm.alpha.kubernetes.io/cri-socket:unix:///run/containerd/containerd.sock node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true] [] [] [{kube-controller-manager Update v1 2023-04-16 23:18:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.1.0/24\"":{}}}} } {kubelet Update v1 2023-04-16 23:18:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}},"f:spec":{"f:providerID":{}}} } {kubeadm Update v1 2023-04-16 23:18:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}}}} } {kubelet Update v1 2023-04-17 07:47:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:images":{}}} status}]},Spec:NodeSpec{PodCIDR:10.244.1.0/24,DoNotUseExternalID:,ProviderID:kind://docker/c3/c3-worker,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[10.244.1.0/24],},Status:NodeStatus{Capacity:ResourceList{cpu: {{64 0} {<nil>} 64 DecimalSI},ephemeral-storage: {{233551093760 0} {<nil>}  BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{269851996160 0} {<nil>} 263527340Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{64 0} {<nil>} 64 DecimalSI},ephemeral-storage: {{233551093760 0} {<nil>}  BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{269851996160 0} {<nil>} 263527340Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2023-04-17 07:47:00 +0000 UTC,LastTransitionTime:2023-04-16 23:18:29 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2023-04-17 07:47:00 +0000 UTC,LastTransitionTime:2023-04-16 23:18:29 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2023-04-17 07:47:00 +0000 UTC,LastTransitionTime:2023-04-16 23:18:29 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2023-04-17 07:47:00 +0000 UTC,LastTransitionTime:2023-04-16 23:18:35 +0000 UTC,Reason:KubeletReady,Message:kubelet is posting ready status,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:172.18.0.3,},NodeAddress{Type:Hostname,Address:c3-worker,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:a124023345bc40a6a2c520704aa857a5,SystemUUID:a7192449-7130-463d-8afd-264f8a3a8947,BootID:6c31530c-b1ee-4d7b-9f9a-cd7e74053a70,KernelVersion:5.15.0-58-generic,OSImage:Ubuntu 22.04.2 LTS,ContainerRuntimeVersion:containerd://1.6.19-46-g941215f49,KubeletVersion:v1.27.0,KubeProxyVersion:v1.27.0,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[docker.io/sonobuoy/systemd-logs@sha256:0b8b2b7b43b03f7db26e7e4b99be402495b77b496f5a5b0425b3c226bc1e9cbd docker.io/sonobuoy/systemd-logs:v0.4],SizeBytes:127795048,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/jessie-dnsutils@sha256:24aaf2626d6b27864c29de2097e8bbb840b3a414271bf7c8995e431e47d8408e registry.k8s.io/e2e-test-images/jessie-dnsutils:1.7],SizeBytes:112030336,},ContainerImage{Names:[registry.k8s.io/etcd:3.5.7-0],SizeBytes:101639218,},ContainerImage{Names:[docker.io/library/import-2023-04-11@sha256:1e9953bc5edfc7a95ee557bbbe582da753e6385833bf6c49bdc7e363bda2e7af registry.k8s.io/kube-apiserver:v1.27.0],SizeBytes:83427839,},ContainerImage{Names:[registry.k8s.io/conformance@sha256:75b754c768525c5646d42d1209985223a5149acb58f7d1c76430fc41ec48f7f3 registry.k8s.io/conformance:v1.27.0],SizeBytes:78246002,},ContainerImage{Names:[docker.io/library/import-2023-04-11@sha256:0b14caafa64dd35b5d5a10502811f0ba6d4b790215e38f86bdb641407cf8c069 registry.k8s.io/kube-controller-manager:v1.27.0],SizeBytes:74408077,},ContainerImage{Names:[docker.io/library/import-2023-04-11@sha256:bc131b7c57288fdbc7053d16b5488a509897c97429056decba9242675ed41d8c registry.k8s.io/kube-proxy:v1.27.0],SizeBytes:72702973,},ContainerImage{Names:[docker.io/library/import-2023-04-11@sha256:7443dcbb453e39f79e4863b0fb6f169e538aa6bb3ff7f9226f7d4c83571285b7 registry.k8s.io/kube-scheduler:v1.27.0],SizeBytes:59781773,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e registry.k8s.io/e2e-test-images/agnhost:2.43],SizeBytes:51706353,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/nautilus@sha256:80ba6c8c44f9623f06e868a1aa66026c8ec438ad814f9ec95e9333b415fe3550 registry.k8s.io/e2e-test-images/nautilus:1.7],SizeBytes:49641698,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/httpd@sha256:3fe7acf013d1264ffded116b80a73dc129a449b0fccdb8d21af8279f2233f36e registry.k8s.io/e2e-test-images/httpd:2.4.39-4],SizeBytes:41901587,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22 registry.k8s.io/e2e-test-images/httpd:2.4.38-4],SizeBytes:40764257,},ContainerImage{Names:[docker.io/kindest/kindnetd:v20230330-48f316cd@sha256:c19d6362a6a928139820761475a38c24c0cf84d507b9ddf414a078cf627497af docker.io/kindest/kindnetd@sha256:c19d6362a6a928139820761475a38c24c0cf84d507b9ddf414a078cf627497af],SizeBytes:27726335,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/sample-apiserver@sha256:8d70890151aa5d096f331cb9da1b9cd5be0412b7363fe67b5c3befdcaa2a28d0 registry.k8s.io/e2e-test-images/sample-apiserver:1.17.7],SizeBytes:25667066,},ContainerImage{Names:[docker.io/sonobuoy/sonobuoy@sha256:8f9f3cd082287f5c5c2cce37251771ae6631b38fd71c7a5820be5d2d545a3a0c docker.io/sonobuoy/sonobuoy:v0.56.16],SizeBytes:20486754,},ContainerImage{Names:[docker.io/kindest/local-path-provisioner:v0.0.23-kind.0@sha256:f2d0a02831ff3a03cf51343226670d5060623b43a4cfc4808bd0875b2c4b9501],SizeBytes:18664669,},ContainerImage{Names:[registry.k8s.io/coredns/coredns:v1.10.1],SizeBytes:16190758,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/nginx@sha256:5c99cf6a02adda929b10321dbf4ecfa00d87be9ba4fb456006237d530ab4baa1 registry.k8s.io/e2e-test-images/nginx:1.14-4],SizeBytes:6978614,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/nonewprivs@sha256:8ac1264691820febacf3aea5d152cbde6d10685731ec14966a9401c6f47a68ac registry.k8s.io/e2e-test-images/nonewprivs:1.3],SizeBytes:3263463,},ContainerImage{Names:[docker.io/kindest/local-path-helper:v20230330-48f316cd@sha256:135203f2441f916fb13dad1561d27f60a6f11f50ec288b01a7d2ee9947c36270],SizeBytes:3052037,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937 registry.k8s.io/e2e-test-images/busybox:1.29-4],SizeBytes:731990,},ContainerImage{Names:[registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097 registry.k8s.io/pause:3.9],SizeBytes:321520,},ContainerImage{Names:[registry.k8s.io/pause:3.7],SizeBytes:311278,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}
  Apr 17 07:49:29.097: INFO: 
  Logging kubelet events for node c3-worker
  Apr 17 07:49:29.098: INFO: 
  Logging pods the kubelet thinks is on node c3-worker
  Apr 17 07:49:29.101: INFO: oidc-discovery-validator started at 2023-04-17 07:43:59 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.101: INFO: 	Container oidc-discovery-validator ready: false, restart count 0
  Apr 17 07:49:29.101: INFO: sonobuoy started at 2023-04-17 06:33:09 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.101: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 17 07:49:29.101: INFO: kube-proxy-6r2kb started at 2023-04-16 23:18:32 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.101: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 17 07:49:29.101: INFO: sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-7tzl9 started at 2023-04-17 06:33:10 +0000 UTC (0+2 container statuses recorded)
  Apr 17 07:49:29.101: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 07:49:29.101: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 17 07:49:29.101: INFO: kindnet-plq69 started at 2023-04-16 23:18:32 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.101: INFO: 	Container kindnet-cni ready: true, restart count 0
  Apr 17 07:49:29.123: INFO: 
  Latency metrics for node c3-worker
  Apr 17 07:49:29.123: INFO: 
  Logging node info for node c3-worker2
  Apr 17 07:49:29.124: INFO: Node Info: &Node{ObjectMeta:{c3-worker2    e9399153-422e-4b16-8c0b-d8cb00c9859c 62040 0 2023-04-16 23:18:30 +0000 UTC <nil> <nil> map[beta.kubernetes.io/arch:amd64 beta.kubernetes.io/os:linux kubernetes.io/arch:amd64 kubernetes.io/hostname:c3-worker2 kubernetes.io/os:linux] map[kubeadm.alpha.kubernetes.io/cri-socket:unix:///run/containerd/containerd.sock node.alpha.kubernetes.io/ttl:0 volumes.kubernetes.io/controller-managed-attach-detach:true] [] [] [{kube-controller-manager Update v1 2023-04-16 23:18:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.2.0/24\"":{}}}} } {kubelet Update v1 2023-04-16 23:18:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}},"f:spec":{"f:providerID":{}}} } {kubeadm Update v1 2023-04-16 23:18:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}}}} } {kubelet Update v1 2023-04-17 07:49:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:images":{}}} status}]},Spec:NodeSpec{PodCIDR:10.244.2.0/24,DoNotUseExternalID:,ProviderID:kind://docker/c3/c3-worker2,Unschedulable:false,Taints:[]Taint{},ConfigSource:nil,PodCIDRs:[10.244.2.0/24],},Status:NodeStatus{Capacity:ResourceList{cpu: {{64 0} {<nil>} 64 DecimalSI},ephemeral-storage: {{233551093760 0} {<nil>}  BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{269851996160 0} {<nil>} 263527340Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{cpu: {{64 0} {<nil>} 64 DecimalSI},ephemeral-storage: {{233551093760 0} {<nil>}  BinarySI},hugepages-1Gi: {{0 0} {<nil>} 0 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{269851996160 0} {<nil>} 263527340Ki BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[]NodeCondition{NodeCondition{Type:MemoryPressure,Status:False,LastHeartbeatTime:2023-04-17 07:49:18 +0000 UTC,LastTransitionTime:2023-04-16 23:18:30 +0000 UTC,Reason:KubeletHasSufficientMemory,Message:kubelet has sufficient memory available,},NodeCondition{Type:DiskPressure,Status:False,LastHeartbeatTime:2023-04-17 07:49:18 +0000 UTC,LastTransitionTime:2023-04-16 23:18:30 +0000 UTC,Reason:KubeletHasNoDiskPressure,Message:kubelet has no disk pressure,},NodeCondition{Type:PIDPressure,Status:False,LastHeartbeatTime:2023-04-17 07:49:18 +0000 UTC,LastTransitionTime:2023-04-16 23:18:30 +0000 UTC,Reason:KubeletHasSufficientPID,Message:kubelet has sufficient PID available,},NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2023-04-17 07:49:18 +0000 UTC,LastTransitionTime:2023-04-16 23:18:36 +0000 UTC,Reason:KubeletReady,Message:kubelet is posting ready status,},},Addresses:[]NodeAddress{NodeAddress{Type:InternalIP,Address:172.18.0.4,},NodeAddress{Type:Hostname,Address:c3-worker2,},},DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:560a8a9b83bf4556a5d83b2524d9fd5c,SystemUUID:455e9dca-c778-4f77-a2de-7289b9a65d44,BootID:6c31530c-b1ee-4d7b-9f9a-cd7e74053a70,KernelVersion:5.15.0-58-generic,OSImage:Ubuntu 22.04.2 LTS,ContainerRuntimeVersion:containerd://1.6.19-46-g941215f49,KubeletVersion:v1.27.0,KubeProxyVersion:v1.27.0,OperatingSystem:linux,Architecture:amd64,},Images:[]ContainerImage{ContainerImage{Names:[docker.io/sonobuoy/systemd-logs@sha256:0b8b2b7b43b03f7db26e7e4b99be402495b77b496f5a5b0425b3c226bc1e9cbd docker.io/sonobuoy/systemd-logs:v0.4],SizeBytes:127795048,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/jessie-dnsutils@sha256:24aaf2626d6b27864c29de2097e8bbb840b3a414271bf7c8995e431e47d8408e registry.k8s.io/e2e-test-images/jessie-dnsutils:1.7],SizeBytes:112030336,},ContainerImage{Names:[registry.k8s.io/etcd:3.5.7-0],SizeBytes:101639218,},ContainerImage{Names:[docker.io/library/import-2023-04-11@sha256:1e9953bc5edfc7a95ee557bbbe582da753e6385833bf6c49bdc7e363bda2e7af registry.k8s.io/kube-apiserver:v1.27.0],SizeBytes:83427839,},ContainerImage{Names:[registry.k8s.io/conformance@sha256:75b754c768525c5646d42d1209985223a5149acb58f7d1c76430fc41ec48f7f3 registry.k8s.io/conformance:v1.27.0],SizeBytes:78246002,},ContainerImage{Names:[docker.io/library/import-2023-04-11@sha256:0b14caafa64dd35b5d5a10502811f0ba6d4b790215e38f86bdb641407cf8c069 registry.k8s.io/kube-controller-manager:v1.27.0],SizeBytes:74408077,},ContainerImage{Names:[docker.io/library/import-2023-04-11@sha256:bc131b7c57288fdbc7053d16b5488a509897c97429056decba9242675ed41d8c registry.k8s.io/kube-proxy:v1.27.0],SizeBytes:72702973,},ContainerImage{Names:[docker.io/library/import-2023-04-11@sha256:7443dcbb453e39f79e4863b0fb6f169e538aa6bb3ff7f9226f7d4c83571285b7 registry.k8s.io/kube-scheduler:v1.27.0],SizeBytes:59781773,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e registry.k8s.io/e2e-test-images/agnhost:2.43],SizeBytes:51706353,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/nautilus@sha256:80ba6c8c44f9623f06e868a1aa66026c8ec438ad814f9ec95e9333b415fe3550 registry.k8s.io/e2e-test-images/nautilus:1.7],SizeBytes:49641698,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/httpd@sha256:3fe7acf013d1264ffded116b80a73dc129a449b0fccdb8d21af8279f2233f36e registry.k8s.io/e2e-test-images/httpd:2.4.39-4],SizeBytes:41901587,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22 registry.k8s.io/e2e-test-images/httpd:2.4.38-4],SizeBytes:40764257,},ContainerImage{Names:[docker.io/kindest/kindnetd:v20230330-48f316cd@sha256:c19d6362a6a928139820761475a38c24c0cf84d507b9ddf414a078cf627497af docker.io/kindest/kindnetd@sha256:c19d6362a6a928139820761475a38c24c0cf84d507b9ddf414a078cf627497af],SizeBytes:27726335,},ContainerImage{Names:[docker.io/sonobuoy/sonobuoy@sha256:8f9f3cd082287f5c5c2cce37251771ae6631b38fd71c7a5820be5d2d545a3a0c docker.io/sonobuoy/sonobuoy:v0.56.16],SizeBytes:20486754,},ContainerImage{Names:[docker.io/kindest/local-path-provisioner:v0.0.23-kind.0@sha256:f2d0a02831ff3a03cf51343226670d5060623b43a4cfc4808bd0875b2c4b9501],SizeBytes:18664669,},ContainerImage{Names:[registry.k8s.io/coredns/coredns:v1.10.1],SizeBytes:16190758,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/nginx@sha256:5c99cf6a02adda929b10321dbf4ecfa00d87be9ba4fb456006237d530ab4baa1 registry.k8s.io/e2e-test-images/nginx:1.14-4],SizeBytes:6978614,},ContainerImage{Names:[docker.io/kindest/local-path-helper:v20230330-48f316cd@sha256:135203f2441f916fb13dad1561d27f60a6f11f50ec288b01a7d2ee9947c36270],SizeBytes:3052037,},ContainerImage{Names:[registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937 registry.k8s.io/e2e-test-images/busybox:1.29-4],SizeBytes:731990,},ContainerImage{Names:[registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097 registry.k8s.io/pause:3.9],SizeBytes:321520,},ContainerImage{Names:[registry.k8s.io/pause:3.7],SizeBytes:311278,},},VolumesInUse:[],VolumesAttached:[]AttachedVolume{},Config:nil,},}
  Apr 17 07:49:29.124: INFO: 
  Logging kubelet events for node c3-worker2
  Apr 17 07:49:29.125: INFO: 
  Logging pods the kubelet thinks is on node c3-worker2
  Apr 17 07:49:29.134: INFO: sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-svr2p started at 2023-04-17 06:33:10 +0000 UTC (0+2 container statuses recorded)
  Apr 17 07:49:29.134: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 07:49:29.134: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 17 07:49:29.134: INFO: kube-proxy-stm68 started at 2023-04-16 23:18:32 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.134: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 17 07:49:29.134: INFO: kindnet-br9l4 started at 2023-04-16 23:18:32 +0000 UTC (0+1 container statuses recorded)
  Apr 17 07:49:29.134: INFO: 	Container kindnet-cni ready: true, restart count 0
  Apr 17 07:49:29.134: INFO: sonobuoy-e2e-job-e91f319b048a45eb started at 2023-04-17 06:33:10 +0000 UTC (0+2 container statuses recorded)
  Apr 17 07:49:29.134: INFO: 	Container e2e ready: true, restart count 0
  Apr 17 07:49:29.134: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 07:49:29.159: INFO: 
  Latency metrics for node c3-worker2
  STEP: Destroying namespace "svcaccounts-7426" for this suite. @ 04/17/23 07:49:29.159
â€¢ [FAILED] [330.140 seconds]
[sig-auth] ServiceAccounts [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
test/e2e/auth/service_accounts.go:529

  [FAILED] Timed out after 300.002s.
  The matcher passed to Eventually returned the following error:
      <*errors.errorString | 0xc000b7fba0>: 
      pod "oidc-discovery-validator" failed with status: {Phase:Failed Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 07:43:59 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 07:44:02 +0000 UTC Reason:PodFailed Message:} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 07:44:02 +0000 UTC Reason:PodFailed Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 07:43:59 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.3 PodIP:10.244.1.64 PodIPs:[{IP:10.244.1.64}] StartTime:2023-04-17 07:43:59 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:oidc-discovery-validator State:{Waiting:nil Running:nil Terminated:&ContainerStateTerminated{ExitCode:1,Signal:0,Reason:Error,Message:,StartedAt:2023-04-17 07:43:59 +0000 UTC,FinishedAt:2023-04-17 07:44:01 +0000 UTC,ContainerID:containerd://a3cf44e5c4018b2b6b15f7663bd35a127f6faa35fc2774566e1a5dcc9e45c129,}} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:registry.k8s.io/e2e-test-images/agnhost:2.43 ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e ContainerID:containerd://a3cf44e5c4018b2b6b15f7663bd35a127f6faa35fc2774566e1a5dcc9e45c129 Started:0xc0051860cf AllocatedResources:map[] Resources:nil}] QOSClass:BestEffort EphemeralContainerStatuses:[] Resize:}
      {
          s: "pod \"oidc-discovery-validator\" failed with status: {Phase:Failed Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 07:43:59 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 07:44:02 +0000 UTC Reason:PodFailed Message:} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 07:44:02 +0000 UTC Reason:PodFailed Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 07:43:59 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.3 PodIP:10.244.1.64 PodIPs:[{IP:10.244.1.64}] StartTime:2023-04-17 07:43:59 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:oidc-discovery-validator State:{Waiting:nil Running:nil Terminated:&ContainerStateTerminated{ExitCode:1,Signal:0,Reason:Error,Message:,StartedAt:2023-04-17 07:43:59 +0000 UTC,FinishedAt:2023-04-17 07:44:01 +0000 UTC,ContainerID:containerd://a3cf44e5c4018b2b6b15f7663bd35a127f6faa35fc2774566e1a5dcc9e45c129,}} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:registry.k8s.io/e2e-test-images/agnhost:2.43 ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e ContainerID:containerd://a3cf44e5c4018b2b6b15f7663bd35a127f6faa35fc2774566e1a5dcc9e45c129 Started:0xc0051860cf AllocatedResources:map[] Resources:nil}] QOSClass:BestEffort EphemeralContainerStatuses:[] Resize:}",
      }
  In [It] at: test/e2e/auth/service_accounts.go:635 @ 04/17/23 07:49:29.047
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:243
  STEP: Creating a kubernetes client @ 04/17/23 07:49:29.163
  Apr 17 07:49:29.163: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename namespaces @ 04/17/23 07:49:29.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:49:29.167
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:49:29.168
  STEP: Creating a test namespace @ 04/17/23 07:49:29.169
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:49:29.172
  STEP: Creating a pod in the namespace @ 04/17/23 07:49:29.173
  STEP: Waiting for the pod to have running status @ 04/17/23 07:49:29.175
  STEP: Deleting the namespace @ 04/17/23 07:49:31.178
  STEP: Waiting for the namespace to be removed. @ 04/17/23 07:49:31.18
  STEP: Recreating the namespace @ 04/17/23 07:49:42.182
  STEP: Verifying there are no pods in the namespace @ 04/17/23 07:49:42.186
  Apr 17 07:49:42.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8442" for this suite. @ 04/17/23 07:49:42.189
  STEP: Destroying namespace "nsdeletetest-1400" for this suite. @ 04/17/23 07:49:42.19
  Apr 17 07:49:42.191: INFO: Namespace nsdeletetest-1400 was already deleted
  STEP: Destroying namespace "nsdeletetest-3431" for this suite. @ 04/17/23 07:49:42.191
â€¢ [13.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:236
  STEP: Creating a kubernetes client @ 04/17/23 07:49:42.193
  Apr 17 07:49:42.193: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:49:42.194
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:49:42.197
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:49:42.198
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 07:49:42.199
  STEP: Saw pod success @ 04/17/23 07:49:46.208
  Apr 17 07:49:46.209: INFO: Trying to get logs from node c3-worker pod downwardapi-volume-29597ba2-09fd-40a9-a022-eb47d8d48ce6 container client-container: <nil>
  STEP: delete the pod @ 04/17/23 07:49:46.211
  Apr 17 07:49:46.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5379" for this suite. @ 04/17/23 07:49:46.216
â€¢ [4.024 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:45
  STEP: Creating a kubernetes client @ 04/17/23 07:49:46.218
  Apr 17 07:49:46.218: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 07:49:46.218
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:49:46.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:49:46.223
  STEP: Creating configMap configmap-3936/configmap-test-d350e304-bdff-4074-aea9-ad51d16f8607 @ 04/17/23 07:49:46.224
  STEP: Creating a pod to test consume configMaps @ 04/17/23 07:49:46.225
  STEP: Saw pod success @ 04/17/23 07:49:50.234
  Apr 17 07:49:50.235: INFO: Trying to get logs from node c3-worker pod pod-configmaps-7720d178-62ec-47d8-9cbd-4039dc96263d container env-test: <nil>
  STEP: delete the pod @ 04/17/23 07:49:50.237
  Apr 17 07:49:50.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3936" for this suite. @ 04/17/23 07:49:50.242
â€¢ [4.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:647
  STEP: Creating a kubernetes client @ 04/17/23 07:49:50.244
  Apr 17 07:49:50.244: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename svcaccounts @ 04/17/23 07:49:50.245
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:49:50.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:49:50.249
  STEP: creating a ServiceAccount @ 04/17/23 07:49:50.251
  STEP: watching for the ServiceAccount to be added @ 04/17/23 07:49:50.253
  STEP: patching the ServiceAccount @ 04/17/23 07:49:50.253
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 04/17/23 07:49:50.255
  STEP: deleting the ServiceAccount @ 04/17/23 07:49:50.256
  Apr 17 07:49:50.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5156" for this suite. @ 04/17/23 07:49:50.26
â€¢ [0.017 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 04/17/23 07:49:50.262
  Apr 17 07:49:50.262: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename events @ 04/17/23 07:49:50.262
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:49:50.266
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:49:50.267
  STEP: creating a test event @ 04/17/23 07:49:50.268
  STEP: listing events in all namespaces @ 04/17/23 07:49:50.27
  STEP: listing events in test namespace @ 04/17/23 07:49:50.271
  STEP: listing events with field selection filtering on source @ 04/17/23 07:49:50.272
  STEP: listing events with field selection filtering on reportingController @ 04/17/23 07:49:50.272
  STEP: getting the test event @ 04/17/23 07:49:50.273
  STEP: patching the test event @ 04/17/23 07:49:50.274
  STEP: getting the test event @ 04/17/23 07:49:50.278
  STEP: updating the test event @ 04/17/23 07:49:50.279
  STEP: getting the test event @ 04/17/23 07:49:50.28
  STEP: deleting the test event @ 04/17/23 07:49:50.281
  STEP: listing events in all namespaces @ 04/17/23 07:49:50.283
  STEP: listing events in test namespace @ 04/17/23 07:49:50.284
  Apr 17 07:49:50.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4752" for this suite. @ 04/17/23 07:49:50.286
â€¢ [0.025 seconds]
------------------------------
S
------------------------------
[sig-network] Service endpoints latency should not be very high  [Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 04/17/23 07:49:50.287
  Apr 17 07:49:50.287: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename svc-latency @ 04/17/23 07:49:50.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:49:50.291
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:49:50.292
  Apr 17 07:49:50.293: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-1932 @ 04/17/23 07:49:50.293
  I0417 07:49:50.295484      30 runners.go:194] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1932, replica count: 1
  I0417 07:49:51.346963      30 runners.go:194] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0417 07:49:52.347321      30 runners.go:194] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 17 07:49:52.452: INFO: Created: latency-svc-x8cjh
  Apr 17 07:49:52.454: INFO: Got endpoints: latency-svc-x8cjh [6.557347ms]
  Apr 17 07:49:52.458: INFO: Created: latency-svc-x7zk6
  Apr 17 07:49:52.459: INFO: Got endpoints: latency-svc-x7zk6 [4.348934ms]
  Apr 17 07:49:52.459: INFO: Created: latency-svc-tp4wp
  Apr 17 07:49:52.460: INFO: Created: latency-svc-47ldk
  Apr 17 07:49:52.460: INFO: Got endpoints: latency-svc-tp4wp [5.460195ms]
  Apr 17 07:49:52.461: INFO: Got endpoints: latency-svc-47ldk [6.249334ms]
  Apr 17 07:49:52.461: INFO: Created: latency-svc-7vm66
  Apr 17 07:49:52.462: INFO: Got endpoints: latency-svc-7vm66 [7.939941ms]
  Apr 17 07:49:52.463: INFO: Created: latency-svc-lrg7f
  Apr 17 07:49:52.464: INFO: Got endpoints: latency-svc-lrg7f [8.950987ms]
  Apr 17 07:49:52.464: INFO: Created: latency-svc-7lk2l
  Apr 17 07:49:52.465: INFO: Got endpoints: latency-svc-7lk2l [10.684235ms]
  Apr 17 07:49:52.465: INFO: Created: latency-svc-zlgpc
  Apr 17 07:49:52.466: INFO: Got endpoints: latency-svc-zlgpc [11.814161ms]
  Apr 17 07:49:52.467: INFO: Created: latency-svc-nsz8q
  Apr 17 07:49:52.468: INFO: Created: latency-svc-4lxvk
  Apr 17 07:49:52.468: INFO: Got endpoints: latency-svc-nsz8q [13.356661ms]
  Apr 17 07:49:52.469: INFO: Got endpoints: latency-svc-4lxvk [14.370253ms]
  Apr 17 07:49:52.470: INFO: Created: latency-svc-vh96d
  Apr 17 07:49:52.470: INFO: Got endpoints: latency-svc-vh96d [16.000402ms]
  Apr 17 07:49:52.484: INFO: Created: latency-svc-k6c8v
  Apr 17 07:49:52.484: INFO: Created: latency-svc-zqpcz
  Apr 17 07:49:52.484: INFO: Created: latency-svc-tbtrh
  Apr 17 07:49:52.484: INFO: Created: latency-svc-bc7nj
  Apr 17 07:49:52.484: INFO: Created: latency-svc-gfzxl
  Apr 17 07:49:52.484: INFO: Created: latency-svc-t48l4
  Apr 17 07:49:52.485: INFO: Created: latency-svc-95546
  Apr 17 07:49:52.485: INFO: Created: latency-svc-qqjhb
  Apr 17 07:49:52.485: INFO: Created: latency-svc-57ths
  Apr 17 07:49:52.485: INFO: Created: latency-svc-f28sk
  Apr 17 07:49:52.485: INFO: Created: latency-svc-gcqqv
  Apr 17 07:49:52.485: INFO: Created: latency-svc-77w47
  Apr 17 07:49:52.485: INFO: Created: latency-svc-kknm5
  Apr 17 07:49:52.485: INFO: Got endpoints: latency-svc-k6c8v [30.577093ms]
  Apr 17 07:49:52.485: INFO: Created: latency-svc-mqqhg
  Apr 17 07:49:52.485: INFO: Created: latency-svc-xdrmz
  Apr 17 07:49:52.486: INFO: Got endpoints: latency-svc-95546 [31.283784ms]
  Apr 17 07:49:52.486: INFO: Got endpoints: latency-svc-qqjhb [18.109685ms]
  Apr 17 07:49:52.486: INFO: Got endpoints: latency-svc-kknm5 [15.848881ms]
  Apr 17 07:49:52.486: INFO: Got endpoints: latency-svc-bc7nj [25.524373ms]
  Apr 17 07:49:52.487: INFO: Got endpoints: latency-svc-77w47 [27.093746ms]
  Apr 17 07:49:52.487: INFO: Got endpoints: latency-svc-mqqhg [24.901714ms]
  Apr 17 07:49:52.487: INFO: Got endpoints: latency-svc-gfzxl [28.619363ms]
  Apr 17 07:49:52.488: INFO: Got endpoints: latency-svc-zqpcz [33.407514ms]
  Apr 17 07:49:52.488: INFO: Got endpoints: latency-svc-t48l4 [22.972178ms]
  Apr 17 07:49:52.488: INFO: Got endpoints: latency-svc-tbtrh [33.829977ms]
  Apr 17 07:49:52.489: INFO: Created: latency-svc-p54qb
  Apr 17 07:49:52.489: INFO: Got endpoints: latency-svc-xdrmz [34.219147ms]
  Apr 17 07:49:52.489: INFO: Got endpoints: latency-svc-57ths [25.279561ms]
  Apr 17 07:49:52.490: INFO: Got endpoints: latency-svc-f28sk [23.697775ms]
  Apr 17 07:49:52.490: INFO: Got endpoints: latency-svc-gcqqv [21.144408ms]
  Apr 17 07:49:52.490: INFO: Got endpoints: latency-svc-p54qb [4.891399ms]
  Apr 17 07:49:52.490: INFO: Created: latency-svc-wkffx
  Apr 17 07:49:52.491: INFO: Created: latency-svc-msn28
  Apr 17 07:49:52.491: INFO: Got endpoints: latency-svc-wkffx [4.240496ms]
  Apr 17 07:49:52.492: INFO: Created: latency-svc-zh748
  Apr 17 07:49:52.493: INFO: Got endpoints: latency-svc-msn28 [6.545194ms]
  Apr 17 07:49:52.493: INFO: Got endpoints: latency-svc-zh748 [7.42048ms]
  Apr 17 07:49:52.494: INFO: Created: latency-svc-ptjdt
  Apr 17 07:49:52.495: INFO: Created: latency-svc-klmxl
  Apr 17 07:49:52.496: INFO: Created: latency-svc-qwjbt
  Apr 17 07:49:52.497: INFO: Created: latency-svc-crtmw
  Apr 17 07:49:52.498: INFO: Created: latency-svc-n4gsq
  Apr 17 07:49:52.499: INFO: Created: latency-svc-zlkjx
  Apr 17 07:49:52.500: INFO: Created: latency-svc-phx6x
  Apr 17 07:49:52.501: INFO: Created: latency-svc-mksrf
  Apr 17 07:49:52.502: INFO: Created: latency-svc-lmtk6
  Apr 17 07:49:52.503: INFO: Created: latency-svc-4wvx6
  Apr 17 07:49:52.504: INFO: Got endpoints: latency-svc-ptjdt [17.715616ms]
  Apr 17 07:49:52.504: INFO: Created: latency-svc-ldwnz
  Apr 17 07:49:52.506: INFO: Created: latency-svc-nlcwn
  Apr 17 07:49:52.507: INFO: Created: latency-svc-7gr7m
  Apr 17 07:49:52.508: INFO: Created: latency-svc-vrms4
  Apr 17 07:49:52.509: INFO: Created: latency-svc-qts25
  Apr 17 07:49:52.510: INFO: Created: latency-svc-kk965
  Apr 17 07:49:52.554: INFO: Got endpoints: latency-svc-klmxl [67.981202ms]
  Apr 17 07:49:52.557: INFO: Created: latency-svc-m2mwv
  Apr 17 07:49:52.604: INFO: Got endpoints: latency-svc-qwjbt [116.508522ms]
  Apr 17 07:49:52.607: INFO: Created: latency-svc-zcbr6
  Apr 17 07:49:52.654: INFO: Got endpoints: latency-svc-crtmw [166.681081ms]
  Apr 17 07:49:52.657: INFO: Created: latency-svc-8p6sb
  Apr 17 07:49:52.704: INFO: Got endpoints: latency-svc-n4gsq [216.196724ms]
  Apr 17 07:49:52.707: INFO: Created: latency-svc-z7tvv
  Apr 17 07:49:52.755: INFO: Got endpoints: latency-svc-zlkjx [266.766528ms]
  Apr 17 07:49:52.757: INFO: Created: latency-svc-s2v5c
  Apr 17 07:49:52.804: INFO: Got endpoints: latency-svc-phx6x [315.966403ms]
  Apr 17 07:49:52.807: INFO: Created: latency-svc-qpnmm
  Apr 17 07:49:52.854: INFO: Got endpoints: latency-svc-mksrf [365.116031ms]
  Apr 17 07:49:52.856: INFO: Created: latency-svc-9xgdp
  Apr 17 07:49:52.904: INFO: Got endpoints: latency-svc-lmtk6 [415.519894ms]
  Apr 17 07:49:52.907: INFO: Created: latency-svc-r824n
  Apr 17 07:49:52.954: INFO: Got endpoints: latency-svc-4wvx6 [464.146967ms]
  Apr 17 07:49:52.957: INFO: Created: latency-svc-49rm2
  Apr 17 07:49:53.004: INFO: Got endpoints: latency-svc-ldwnz [514.189945ms]
  Apr 17 07:49:53.007: INFO: Created: latency-svc-v4k6v
  Apr 17 07:49:53.054: INFO: Got endpoints: latency-svc-nlcwn [563.751267ms]
  Apr 17 07:49:53.056: INFO: Created: latency-svc-v747n
  Apr 17 07:49:53.104: INFO: Got endpoints: latency-svc-7gr7m [612.437834ms]
  Apr 17 07:49:53.106: INFO: Created: latency-svc-8h7cl
  Apr 17 07:49:53.154: INFO: Got endpoints: latency-svc-vrms4 [661.73642ms]
  Apr 17 07:49:53.157: INFO: Created: latency-svc-q8qbn
  Apr 17 07:49:53.204: INFO: Got endpoints: latency-svc-qts25 [710.20155ms]
  Apr 17 07:49:53.206: INFO: Created: latency-svc-5n7mz
  Apr 17 07:49:53.254: INFO: Got endpoints: latency-svc-kk965 [750.123337ms]
  Apr 17 07:49:53.257: INFO: Created: latency-svc-9ncsr
  Apr 17 07:49:53.304: INFO: Got endpoints: latency-svc-m2mwv [750.075556ms]
  Apr 17 07:49:53.307: INFO: Created: latency-svc-rkzbv
  Apr 17 07:49:53.355: INFO: Got endpoints: latency-svc-zcbr6 [750.831472ms]
  Apr 17 07:49:53.357: INFO: Created: latency-svc-2t78x
  Apr 17 07:49:53.404: INFO: Got endpoints: latency-svc-8p6sb [749.825474ms]
  Apr 17 07:49:53.407: INFO: Created: latency-svc-x2kwc
  Apr 17 07:49:53.455: INFO: Got endpoints: latency-svc-z7tvv [750.286673ms]
  Apr 17 07:49:53.457: INFO: Created: latency-svc-m96z8
  Apr 17 07:49:53.504: INFO: Got endpoints: latency-svc-s2v5c [749.114054ms]
  Apr 17 07:49:53.510: INFO: Created: latency-svc-xb55h
  Apr 17 07:49:53.555: INFO: Got endpoints: latency-svc-qpnmm [750.359714ms]
  Apr 17 07:49:53.558: INFO: Created: latency-svc-6qb6h
  Apr 17 07:49:53.604: INFO: Got endpoints: latency-svc-9xgdp [750.321018ms]
  Apr 17 07:49:53.607: INFO: Created: latency-svc-scwmp
  Apr 17 07:49:53.654: INFO: Got endpoints: latency-svc-r824n [749.161777ms]
  Apr 17 07:49:53.656: INFO: Created: latency-svc-hpwdl
  Apr 17 07:49:53.704: INFO: Got endpoints: latency-svc-49rm2 [749.94775ms]
  Apr 17 07:49:53.707: INFO: Created: latency-svc-9ltgr
  Apr 17 07:49:53.755: INFO: Got endpoints: latency-svc-v4k6v [750.177172ms]
  Apr 17 07:49:53.757: INFO: Created: latency-svc-x86tz
  Apr 17 07:49:53.804: INFO: Got endpoints: latency-svc-v747n [750.089332ms]
  Apr 17 07:49:53.807: INFO: Created: latency-svc-zt547
  Apr 17 07:49:53.854: INFO: Got endpoints: latency-svc-8h7cl [750.723173ms]
  Apr 17 07:49:53.857: INFO: Created: latency-svc-wmp9b
  Apr 17 07:49:53.904: INFO: Got endpoints: latency-svc-q8qbn [749.943541ms]
  Apr 17 07:49:53.907: INFO: Created: latency-svc-q794b
  Apr 17 07:49:53.955: INFO: Got endpoints: latency-svc-5n7mz [750.980489ms]
  Apr 17 07:49:53.957: INFO: Created: latency-svc-79gn4
  Apr 17 07:49:54.004: INFO: Got endpoints: latency-svc-9ncsr [749.464309ms]
  Apr 17 07:49:54.006: INFO: Created: latency-svc-hbchc
  Apr 17 07:49:54.054: INFO: Got endpoints: latency-svc-rkzbv [750.017183ms]
  Apr 17 07:49:54.057: INFO: Created: latency-svc-kqbk5
  Apr 17 07:49:54.105: INFO: Got endpoints: latency-svc-2t78x [750.147895ms]
  Apr 17 07:49:54.108: INFO: Created: latency-svc-8jrqh
  Apr 17 07:49:54.154: INFO: Got endpoints: latency-svc-x2kwc [750.196599ms]
  Apr 17 07:49:54.157: INFO: Created: latency-svc-sggsb
  Apr 17 07:49:54.203: INFO: Got endpoints: latency-svc-m96z8 [748.814498ms]
  Apr 17 07:49:54.206: INFO: Created: latency-svc-vt598
  Apr 17 07:49:54.255: INFO: Got endpoints: latency-svc-xb55h [750.697444ms]
  Apr 17 07:49:54.257: INFO: Created: latency-svc-cqn8r
  Apr 17 07:49:54.305: INFO: Got endpoints: latency-svc-6qb6h [749.738576ms]
  Apr 17 07:49:54.307: INFO: Created: latency-svc-ntlgp
  Apr 17 07:49:54.354: INFO: Got endpoints: latency-svc-scwmp [749.381469ms]
  Apr 17 07:49:54.356: INFO: Created: latency-svc-g4xgl
  Apr 17 07:49:54.404: INFO: Got endpoints: latency-svc-hpwdl [750.189155ms]
  Apr 17 07:49:54.406: INFO: Created: latency-svc-rqjh2
  Apr 17 07:49:54.454: INFO: Got endpoints: latency-svc-9ltgr [750.101627ms]
  Apr 17 07:49:54.457: INFO: Created: latency-svc-wndsc
  Apr 17 07:49:54.504: INFO: Got endpoints: latency-svc-x86tz [749.297769ms]
  Apr 17 07:49:54.507: INFO: Created: latency-svc-ktq2g
  Apr 17 07:49:54.555: INFO: Got endpoints: latency-svc-zt547 [750.824048ms]
  Apr 17 07:49:54.558: INFO: Created: latency-svc-tfp6t
  Apr 17 07:49:54.604: INFO: Got endpoints: latency-svc-wmp9b [749.839922ms]
  Apr 17 07:49:54.607: INFO: Created: latency-svc-2fsxq
  Apr 17 07:49:54.654: INFO: Got endpoints: latency-svc-q794b [749.950456ms]
  Apr 17 07:49:54.657: INFO: Created: latency-svc-4pjrb
  Apr 17 07:49:54.704: INFO: Got endpoints: latency-svc-79gn4 [749.361611ms]
  Apr 17 07:49:54.707: INFO: Created: latency-svc-gq57j
  Apr 17 07:49:54.754: INFO: Got endpoints: latency-svc-hbchc [750.361136ms]
  Apr 17 07:49:54.757: INFO: Created: latency-svc-7vpwh
  Apr 17 07:49:54.804: INFO: Got endpoints: latency-svc-kqbk5 [749.300073ms]
  Apr 17 07:49:54.806: INFO: Created: latency-svc-mcsvm
  Apr 17 07:49:54.854: INFO: Got endpoints: latency-svc-8jrqh [749.250858ms]
  Apr 17 07:49:54.857: INFO: Created: latency-svc-brc2r
  Apr 17 07:49:54.904: INFO: Got endpoints: latency-svc-sggsb [749.723618ms]
  Apr 17 07:49:54.907: INFO: Created: latency-svc-5z585
  Apr 17 07:49:54.954: INFO: Got endpoints: latency-svc-vt598 [750.870156ms]
  Apr 17 07:49:54.957: INFO: Created: latency-svc-smm98
  Apr 17 07:49:55.005: INFO: Got endpoints: latency-svc-cqn8r [749.891141ms]
  Apr 17 07:49:55.007: INFO: Created: latency-svc-8qr2x
  Apr 17 07:49:55.054: INFO: Got endpoints: latency-svc-ntlgp [749.543982ms]
  Apr 17 07:49:55.057: INFO: Created: latency-svc-wtl27
  Apr 17 07:49:55.104: INFO: Got endpoints: latency-svc-g4xgl [750.53984ms]
  Apr 17 07:49:55.107: INFO: Created: latency-svc-v2hhf
  Apr 17 07:49:55.154: INFO: Got endpoints: latency-svc-rqjh2 [750.034557ms]
  Apr 17 07:49:55.156: INFO: Created: latency-svc-brc82
  Apr 17 07:49:55.204: INFO: Got endpoints: latency-svc-wndsc [750.148906ms]
  Apr 17 07:49:55.207: INFO: Created: latency-svc-sh54z
  Apr 17 07:49:55.254: INFO: Got endpoints: latency-svc-ktq2g [749.815915ms]
  Apr 17 07:49:55.256: INFO: Created: latency-svc-t2ntq
  Apr 17 07:49:55.304: INFO: Got endpoints: latency-svc-tfp6t [748.812393ms]
  Apr 17 07:49:55.306: INFO: Created: latency-svc-q4mrd
  Apr 17 07:49:55.355: INFO: Got endpoints: latency-svc-2fsxq [750.198612ms]
  Apr 17 07:49:55.357: INFO: Created: latency-svc-2zqvc
  Apr 17 07:49:55.405: INFO: Got endpoints: latency-svc-4pjrb [750.49343ms]
  Apr 17 07:49:55.417: INFO: Created: latency-svc-4r6sr
  Apr 17 07:49:55.455: INFO: Got endpoints: latency-svc-gq57j [750.569317ms]
  Apr 17 07:49:55.457: INFO: Created: latency-svc-t78rc
  Apr 17 07:49:55.505: INFO: Got endpoints: latency-svc-7vpwh [750.892158ms]
  Apr 17 07:49:55.508: INFO: Created: latency-svc-sgxqc
  Apr 17 07:49:55.554: INFO: Got endpoints: latency-svc-mcsvm [749.937861ms]
  Apr 17 07:49:55.557: INFO: Created: latency-svc-xv5kt
  Apr 17 07:49:55.605: INFO: Got endpoints: latency-svc-brc2r [750.478031ms]
  Apr 17 07:49:55.607: INFO: Created: latency-svc-2fz9r
  Apr 17 07:49:55.654: INFO: Got endpoints: latency-svc-5z585 [750.314426ms]
  Apr 17 07:49:55.657: INFO: Created: latency-svc-tlwr9
  Apr 17 07:49:55.704: INFO: Got endpoints: latency-svc-smm98 [749.712848ms]
  Apr 17 07:49:55.707: INFO: Created: latency-svc-4mdrb
  Apr 17 07:49:55.754: INFO: Got endpoints: latency-svc-8qr2x [749.385987ms]
  Apr 17 07:49:55.757: INFO: Created: latency-svc-ltjfj
  Apr 17 07:49:55.804: INFO: Got endpoints: latency-svc-wtl27 [749.447236ms]
  Apr 17 07:49:55.806: INFO: Created: latency-svc-vhwdb
  Apr 17 07:49:55.854: INFO: Got endpoints: latency-svc-v2hhf [750.151512ms]
  Apr 17 07:49:55.857: INFO: Created: latency-svc-wbw8n
  Apr 17 07:49:55.905: INFO: Got endpoints: latency-svc-brc82 [751.243395ms]
  Apr 17 07:49:55.908: INFO: Created: latency-svc-ttg58
  Apr 17 07:49:55.954: INFO: Got endpoints: latency-svc-sh54z [749.586624ms]
  Apr 17 07:49:55.957: INFO: Created: latency-svc-4ztdb
  Apr 17 07:49:56.005: INFO: Got endpoints: latency-svc-t2ntq [751.268072ms]
  Apr 17 07:49:56.008: INFO: Created: latency-svc-q8zcv
  Apr 17 07:49:56.055: INFO: Got endpoints: latency-svc-q4mrd [751.12658ms]
  Apr 17 07:49:56.057: INFO: Created: latency-svc-czlnx
  Apr 17 07:49:56.104: INFO: Got endpoints: latency-svc-2zqvc [749.598017ms]
  Apr 17 07:49:56.109: INFO: Created: latency-svc-nndxp
  Apr 17 07:49:56.154: INFO: Got endpoints: latency-svc-4r6sr [748.886587ms]
  Apr 17 07:49:56.156: INFO: Created: latency-svc-sbdf8
  Apr 17 07:49:56.204: INFO: Got endpoints: latency-svc-t78rc [749.781631ms]
  Apr 17 07:49:56.207: INFO: Created: latency-svc-mzzvq
  Apr 17 07:49:56.255: INFO: Got endpoints: latency-svc-sgxqc [749.565003ms]
  Apr 17 07:49:56.257: INFO: Created: latency-svc-qqqk5
  Apr 17 07:49:56.304: INFO: Got endpoints: latency-svc-xv5kt [750.322652ms]
  Apr 17 07:49:56.307: INFO: Created: latency-svc-2nmfk
  Apr 17 07:49:56.354: INFO: Got endpoints: latency-svc-2fz9r [749.768835ms]
  Apr 17 07:49:56.357: INFO: Created: latency-svc-hz6sz
  Apr 17 07:49:56.404: INFO: Got endpoints: latency-svc-tlwr9 [749.456514ms]
  Apr 17 07:49:56.406: INFO: Created: latency-svc-lf24h
  Apr 17 07:49:56.455: INFO: Got endpoints: latency-svc-4mdrb [750.601599ms]
  Apr 17 07:49:56.457: INFO: Created: latency-svc-c67rg
  Apr 17 07:49:56.505: INFO: Got endpoints: latency-svc-ltjfj [750.44056ms]
  Apr 17 07:49:56.507: INFO: Created: latency-svc-mtzzl
  Apr 17 07:49:56.554: INFO: Got endpoints: latency-svc-vhwdb [750.493201ms]
  Apr 17 07:49:56.557: INFO: Created: latency-svc-85cq5
  Apr 17 07:49:56.604: INFO: Got endpoints: latency-svc-wbw8n [749.839271ms]
  Apr 17 07:49:56.607: INFO: Created: latency-svc-dccvf
  Apr 17 07:49:56.655: INFO: Got endpoints: latency-svc-ttg58 [749.451555ms]
  Apr 17 07:49:56.657: INFO: Created: latency-svc-ll9lk
  Apr 17 07:49:56.704: INFO: Got endpoints: latency-svc-4ztdb [750.213812ms]
  Apr 17 07:49:56.707: INFO: Created: latency-svc-8rvtd
  Apr 17 07:49:56.754: INFO: Got endpoints: latency-svc-q8zcv [749.530467ms]
  Apr 17 07:49:56.757: INFO: Created: latency-svc-477ws
  Apr 17 07:49:56.804: INFO: Got endpoints: latency-svc-czlnx [749.559492ms]
  Apr 17 07:49:56.807: INFO: Created: latency-svc-lrc2k
  Apr 17 07:49:56.855: INFO: Got endpoints: latency-svc-nndxp [750.786724ms]
  Apr 17 07:49:56.857: INFO: Created: latency-svc-t6jpk
  Apr 17 07:49:56.904: INFO: Got endpoints: latency-svc-sbdf8 [750.443745ms]
  Apr 17 07:49:56.907: INFO: Created: latency-svc-hswzk
  Apr 17 07:49:56.954: INFO: Got endpoints: latency-svc-mzzvq [749.461372ms]
  Apr 17 07:49:56.956: INFO: Created: latency-svc-9v8fq
  Apr 17 07:49:57.003: INFO: Got endpoints: latency-svc-qqqk5 [748.886215ms]
  Apr 17 07:49:57.006: INFO: Created: latency-svc-mq2lz
  Apr 17 07:49:57.054: INFO: Got endpoints: latency-svc-2nmfk [749.726182ms]
  Apr 17 07:49:57.056: INFO: Created: latency-svc-d6rhq
  Apr 17 07:49:57.104: INFO: Got endpoints: latency-svc-hz6sz [749.242521ms]
  Apr 17 07:49:57.106: INFO: Created: latency-svc-frmwl
  Apr 17 07:49:57.154: INFO: Got endpoints: latency-svc-lf24h [749.774495ms]
  Apr 17 07:49:57.156: INFO: Created: latency-svc-jglds
  Apr 17 07:49:57.204: INFO: Got endpoints: latency-svc-c67rg [749.502752ms]
  Apr 17 07:49:57.207: INFO: Created: latency-svc-nnbpf
  Apr 17 07:49:57.255: INFO: Got endpoints: latency-svc-mtzzl [750.570048ms]
  Apr 17 07:49:57.258: INFO: Created: latency-svc-cxzxw
  Apr 17 07:49:57.304: INFO: Got endpoints: latency-svc-85cq5 [749.596393ms]
  Apr 17 07:49:57.306: INFO: Created: latency-svc-8577f
  Apr 17 07:49:57.354: INFO: Got endpoints: latency-svc-dccvf [749.927861ms]
  Apr 17 07:49:57.357: INFO: Created: latency-svc-bb29v
  Apr 17 07:49:57.404: INFO: Got endpoints: latency-svc-ll9lk [748.984274ms]
  Apr 17 07:49:57.406: INFO: Created: latency-svc-8nqhp
  Apr 17 07:49:57.454: INFO: Got endpoints: latency-svc-8rvtd [750.004359ms]
  Apr 17 07:49:57.457: INFO: Created: latency-svc-bmvgw
  Apr 17 07:49:57.504: INFO: Got endpoints: latency-svc-477ws [749.382591ms]
  Apr 17 07:49:57.506: INFO: Created: latency-svc-h5tbf
  Apr 17 07:49:57.555: INFO: Got endpoints: latency-svc-lrc2k [750.217529ms]
  Apr 17 07:49:57.557: INFO: Created: latency-svc-qvxbk
  Apr 17 07:49:57.604: INFO: Got endpoints: latency-svc-t6jpk [748.813495ms]
  Apr 17 07:49:57.606: INFO: Created: latency-svc-szhqf
  Apr 17 07:49:57.654: INFO: Got endpoints: latency-svc-hswzk [750.219232ms]
  Apr 17 07:49:57.657: INFO: Created: latency-svc-bsx44
  Apr 17 07:49:57.704: INFO: Got endpoints: latency-svc-9v8fq [749.644986ms]
  Apr 17 07:49:57.706: INFO: Created: latency-svc-4n48p
  Apr 17 07:49:57.754: INFO: Got endpoints: latency-svc-mq2lz [750.84098ms]
  Apr 17 07:49:57.757: INFO: Created: latency-svc-rprg4
  Apr 17 07:49:57.804: INFO: Got endpoints: latency-svc-d6rhq [749.892884ms]
  Apr 17 07:49:57.806: INFO: Created: latency-svc-jz5zh
  Apr 17 07:49:57.854: INFO: Got endpoints: latency-svc-frmwl [750.127355ms]
  Apr 17 07:49:57.856: INFO: Created: latency-svc-922sf
  Apr 17 07:49:57.904: INFO: Got endpoints: latency-svc-jglds [750.484844ms]
  Apr 17 07:49:57.906: INFO: Created: latency-svc-ltlgf
  Apr 17 07:49:57.955: INFO: Got endpoints: latency-svc-nnbpf [750.454205ms]
  Apr 17 07:49:57.957: INFO: Created: latency-svc-mddm5
  Apr 17 07:49:58.004: INFO: Got endpoints: latency-svc-cxzxw [749.048968ms]
  Apr 17 07:49:58.007: INFO: Created: latency-svc-cm9s8
  Apr 17 07:49:58.054: INFO: Got endpoints: latency-svc-8577f [750.682615ms]
  Apr 17 07:49:58.057: INFO: Created: latency-svc-526mj
  Apr 17 07:49:58.105: INFO: Got endpoints: latency-svc-bb29v [750.48298ms]
  Apr 17 07:49:58.107: INFO: Created: latency-svc-8bggv
  Apr 17 07:49:58.154: INFO: Got endpoints: latency-svc-8nqhp [750.496647ms]
  Apr 17 07:49:58.157: INFO: Created: latency-svc-7qsx4
  Apr 17 07:49:58.204: INFO: Got endpoints: latency-svc-bmvgw [750.09908ms]
  Apr 17 07:49:58.207: INFO: Created: latency-svc-wvqnx
  Apr 17 07:49:58.255: INFO: Got endpoints: latency-svc-h5tbf [751.09531ms]
  Apr 17 07:49:58.257: INFO: Created: latency-svc-87pxr
  Apr 17 07:49:58.305: INFO: Got endpoints: latency-svc-qvxbk [750.173805ms]
  Apr 17 07:49:58.307: INFO: Created: latency-svc-g9798
  Apr 17 07:49:58.354: INFO: Got endpoints: latency-svc-szhqf [750.369973ms]
  Apr 17 07:49:58.357: INFO: Created: latency-svc-wsrkq
  Apr 17 07:49:58.404: INFO: Got endpoints: latency-svc-bsx44 [749.990032ms]
  Apr 17 07:49:58.407: INFO: Created: latency-svc-px2w7
  Apr 17 07:49:58.454: INFO: Got endpoints: latency-svc-4n48p [750.531374ms]
  Apr 17 07:49:58.456: INFO: Created: latency-svc-dspfp
  Apr 17 07:49:58.504: INFO: Got endpoints: latency-svc-rprg4 [750.006253ms]
  Apr 17 07:49:58.507: INFO: Created: latency-svc-c89q9
  Apr 17 07:49:58.554: INFO: Got endpoints: latency-svc-jz5zh [750.473131ms]
  Apr 17 07:49:58.557: INFO: Created: latency-svc-tln8p
  Apr 17 07:49:58.603: INFO: Got endpoints: latency-svc-922sf [749.581585ms]
  Apr 17 07:49:58.606: INFO: Created: latency-svc-jtmnl
  Apr 17 07:49:58.654: INFO: Got endpoints: latency-svc-ltlgf [749.566596ms]
  Apr 17 07:49:58.656: INFO: Created: latency-svc-rl5n9
  Apr 17 07:49:58.704: INFO: Got endpoints: latency-svc-mddm5 [749.802661ms]
  Apr 17 07:49:58.707: INFO: Created: latency-svc-2x79s
  Apr 17 07:49:58.755: INFO: Got endpoints: latency-svc-cm9s8 [750.772298ms]
  Apr 17 07:49:58.757: INFO: Created: latency-svc-6z998
  Apr 17 07:49:58.805: INFO: Got endpoints: latency-svc-526mj [750.144429ms]
  Apr 17 07:49:58.807: INFO: Created: latency-svc-rtzkv
  Apr 17 07:49:58.854: INFO: Got endpoints: latency-svc-8bggv [749.523573ms]
  Apr 17 07:49:58.857: INFO: Created: latency-svc-kj2j8
  Apr 17 07:49:58.904: INFO: Got endpoints: latency-svc-7qsx4 [749.78657ms]
  Apr 17 07:49:58.906: INFO: Created: latency-svc-j72tc
  Apr 17 07:49:58.955: INFO: Got endpoints: latency-svc-wvqnx [750.217549ms]
  Apr 17 07:49:58.957: INFO: Created: latency-svc-q7rxg
  Apr 17 07:49:59.004: INFO: Got endpoints: latency-svc-87pxr [749.478345ms]
  Apr 17 07:49:59.007: INFO: Created: latency-svc-hn5jc
  Apr 17 07:49:59.054: INFO: Got endpoints: latency-svc-g9798 [749.089106ms]
  Apr 17 07:49:59.056: INFO: Created: latency-svc-qcd58
  Apr 17 07:49:59.104: INFO: Got endpoints: latency-svc-wsrkq [749.766459ms]
  Apr 17 07:49:59.107: INFO: Created: latency-svc-mdgr2
  Apr 17 07:49:59.154: INFO: Got endpoints: latency-svc-px2w7 [749.998226ms]
  Apr 17 07:49:59.157: INFO: Created: latency-svc-bgn2j
  Apr 17 07:49:59.205: INFO: Got endpoints: latency-svc-dspfp [750.47809ms]
  Apr 17 07:49:59.207: INFO: Created: latency-svc-4hsxv
  Apr 17 07:49:59.254: INFO: Got endpoints: latency-svc-c89q9 [749.6215ms]
  Apr 17 07:49:59.259: INFO: Created: latency-svc-x687q
  Apr 17 07:49:59.304: INFO: Got endpoints: latency-svc-tln8p [749.316643ms]
  Apr 17 07:49:59.306: INFO: Created: latency-svc-z2wxt
  Apr 17 07:49:59.354: INFO: Got endpoints: latency-svc-jtmnl [750.086326ms]
  Apr 17 07:49:59.356: INFO: Created: latency-svc-75pcm
  Apr 17 07:49:59.404: INFO: Got endpoints: latency-svc-rl5n9 [750.705448ms]
  Apr 17 07:49:59.407: INFO: Created: latency-svc-67j4h
  Apr 17 07:49:59.454: INFO: Got endpoints: latency-svc-2x79s [749.724679ms]
  Apr 17 07:49:59.457: INFO: Created: latency-svc-9ht8g
  Apr 17 07:49:59.504: INFO: Got endpoints: latency-svc-6z998 [748.602528ms]
  Apr 17 07:49:59.506: INFO: Created: latency-svc-lw92j
  Apr 17 07:49:59.555: INFO: Got endpoints: latency-svc-rtzkv [750.14056ms]
  Apr 17 07:49:59.557: INFO: Created: latency-svc-bslh8
  Apr 17 07:49:59.604: INFO: Got endpoints: latency-svc-kj2j8 [749.964912ms]
  Apr 17 07:49:59.607: INFO: Created: latency-svc-w8vnf
  Apr 17 07:49:59.654: INFO: Got endpoints: latency-svc-j72tc [750.461719ms]
  Apr 17 07:49:59.657: INFO: Created: latency-svc-l5cqv
  Apr 17 07:49:59.704: INFO: Got endpoints: latency-svc-q7rxg [749.456012ms]
  Apr 17 07:49:59.707: INFO: Created: latency-svc-bxlh5
  Apr 17 07:49:59.755: INFO: Got endpoints: latency-svc-hn5jc [750.494162ms]
  Apr 17 07:49:59.758: INFO: Created: latency-svc-lwmj4
  Apr 17 07:49:59.804: INFO: Got endpoints: latency-svc-qcd58 [750.1713ms]
  Apr 17 07:49:59.807: INFO: Created: latency-svc-bh522
  Apr 17 07:49:59.854: INFO: Got endpoints: latency-svc-mdgr2 [749.939854ms]
  Apr 17 07:49:59.856: INFO: Created: latency-svc-9n4vh
  Apr 17 07:49:59.904: INFO: Got endpoints: latency-svc-bgn2j [749.648392ms]
  Apr 17 07:49:59.907: INFO: Created: latency-svc-wdhwb
  Apr 17 07:49:59.955: INFO: Got endpoints: latency-svc-4hsxv [750.308563ms]
  Apr 17 07:49:59.958: INFO: Created: latency-svc-2gjjb
  Apr 17 07:50:00.005: INFO: Got endpoints: latency-svc-x687q [750.526693ms]
  Apr 17 07:50:00.007: INFO: Created: latency-svc-9t8dr
  Apr 17 07:50:00.055: INFO: Got endpoints: latency-svc-z2wxt [750.963574ms]
  Apr 17 07:50:00.057: INFO: Created: latency-svc-9w8w9
  Apr 17 07:50:00.104: INFO: Got endpoints: latency-svc-75pcm [750.502056ms]
  Apr 17 07:50:00.107: INFO: Created: latency-svc-xrw8q
  Apr 17 07:50:00.154: INFO: Got endpoints: latency-svc-67j4h [749.929884ms]
  Apr 17 07:50:00.157: INFO: Created: latency-svc-4knl5
  Apr 17 07:50:00.203: INFO: Got endpoints: latency-svc-9ht8g [749.228734ms]
  Apr 17 07:50:00.206: INFO: Created: latency-svc-858bt
  Apr 17 07:50:00.254: INFO: Got endpoints: latency-svc-lw92j [750.846419ms]
  Apr 17 07:50:00.257: INFO: Created: latency-svc-db4hq
  Apr 17 07:50:00.304: INFO: Got endpoints: latency-svc-bslh8 [749.656898ms]
  Apr 17 07:50:00.354: INFO: Got endpoints: latency-svc-w8vnf [749.775917ms]
  Apr 17 07:50:00.404: INFO: Got endpoints: latency-svc-l5cqv [749.95392ms]
  Apr 17 07:50:00.455: INFO: Got endpoints: latency-svc-bxlh5 [750.724152ms]
  Apr 17 07:50:00.504: INFO: Got endpoints: latency-svc-lwmj4 [749.389914ms]
  Apr 17 07:50:00.554: INFO: Got endpoints: latency-svc-bh522 [750.284596ms]
  Apr 17 07:50:00.605: INFO: Got endpoints: latency-svc-9n4vh [750.813535ms]
  Apr 17 07:50:00.654: INFO: Got endpoints: latency-svc-wdhwb [750.464763ms]
  Apr 17 07:50:00.704: INFO: Got endpoints: latency-svc-2gjjb [749.093614ms]
  Apr 17 07:50:00.754: INFO: Got endpoints: latency-svc-9t8dr [749.891139ms]
  Apr 17 07:50:00.804: INFO: Got endpoints: latency-svc-9w8w9 [749.068375ms]
  Apr 17 07:50:00.854: INFO: Got endpoints: latency-svc-xrw8q [749.909565ms]
  Apr 17 07:50:00.904: INFO: Got endpoints: latency-svc-4knl5 [750.006321ms]
  Apr 17 07:50:00.955: INFO: Got endpoints: latency-svc-858bt [751.087834ms]
  Apr 17 07:50:01.005: INFO: Got endpoints: latency-svc-db4hq [750.089902ms]
  Apr 17 07:50:01.005: INFO: Latencies: [4.240496ms 4.348934ms 4.891399ms 5.460195ms 6.249334ms 6.545194ms 7.42048ms 7.939941ms 8.950987ms 10.684235ms 11.814161ms 13.356661ms 14.370253ms 15.848881ms 16.000402ms 17.715616ms 18.109685ms 21.144408ms 22.972178ms 23.697775ms 24.901714ms 25.279561ms 25.524373ms 27.093746ms 28.619363ms 30.577093ms 31.283784ms 33.407514ms 33.829977ms 34.219147ms 67.981202ms 116.508522ms 166.681081ms 216.196724ms 266.766528ms 315.966403ms 365.116031ms 415.519894ms 464.146967ms 514.189945ms 563.751267ms 612.437834ms 661.73642ms 710.20155ms 748.602528ms 748.812393ms 748.813495ms 748.814498ms 748.886215ms 748.886587ms 748.984274ms 749.048968ms 749.068375ms 749.089106ms 749.093614ms 749.114054ms 749.161777ms 749.228734ms 749.242521ms 749.250858ms 749.297769ms 749.300073ms 749.316643ms 749.361611ms 749.381469ms 749.382591ms 749.385987ms 749.389914ms 749.447236ms 749.451555ms 749.456012ms 749.456514ms 749.461372ms 749.464309ms 749.478345ms 749.502752ms 749.523573ms 749.530467ms 749.543982ms 749.559492ms 749.565003ms 749.566596ms 749.581585ms 749.586624ms 749.596393ms 749.598017ms 749.6215ms 749.644986ms 749.648392ms 749.656898ms 749.712848ms 749.723618ms 749.724679ms 749.726182ms 749.738576ms 749.766459ms 749.768835ms 749.774495ms 749.775917ms 749.781631ms 749.78657ms 749.802661ms 749.815915ms 749.825474ms 749.839271ms 749.839922ms 749.891139ms 749.891141ms 749.892884ms 749.909565ms 749.927861ms 749.929884ms 749.937861ms 749.939854ms 749.943541ms 749.94775ms 749.950456ms 749.95392ms 749.964912ms 749.990032ms 749.998226ms 750.004359ms 750.006253ms 750.006321ms 750.017183ms 750.034557ms 750.075556ms 750.086326ms 750.089332ms 750.089902ms 750.09908ms 750.101627ms 750.123337ms 750.127355ms 750.14056ms 750.144429ms 750.147895ms 750.148906ms 750.151512ms 750.1713ms 750.173805ms 750.177172ms 750.189155ms 750.196599ms 750.198612ms 750.213812ms 750.217529ms 750.217549ms 750.219232ms 750.284596ms 750.286673ms 750.308563ms 750.314426ms 750.321018ms 750.322652ms 750.359714ms 750.361136ms 750.369973ms 750.44056ms 750.443745ms 750.454205ms 750.461719ms 750.464763ms 750.473131ms 750.478031ms 750.47809ms 750.48298ms 750.484844ms 750.493201ms 750.49343ms 750.494162ms 750.496647ms 750.502056ms 750.526693ms 750.531374ms 750.53984ms 750.569317ms 750.570048ms 750.601599ms 750.682615ms 750.697444ms 750.705448ms 750.723173ms 750.724152ms 750.772298ms 750.786724ms 750.813535ms 750.824048ms 750.831472ms 750.84098ms 750.846419ms 750.870156ms 750.892158ms 750.963574ms 750.980489ms 751.087834ms 751.09531ms 751.12658ms 751.243395ms 751.268072ms]
  Apr 17 07:50:01.005: INFO: 50 %ile: 749.78657ms
  Apr 17 07:50:01.005: INFO: 90 %ile: 750.697444ms
  Apr 17 07:50:01.005: INFO: 99 %ile: 751.243395ms
  Apr 17 07:50:01.005: INFO: Total sample count: 200
  Apr 17 07:50:01.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-1932" for this suite. @ 04/17/23 07:50:01.007
â€¢ [10.721 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]
test/e2e/apimachinery/webhook.go:198
  STEP: Creating a kubernetes client @ 04/17/23 07:50:01.009
  Apr 17 07:50:01.009: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 07:50:01.009
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:50:01.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:50:01.014
  STEP: Setting up server cert @ 04/17/23 07:50:01.02
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 07:50:01.182
  STEP: Deploying the webhook pod @ 04/17/23 07:50:01.185
  STEP: Wait for the deployment to be ready @ 04/17/23 07:50:01.189
  Apr 17 07:50:01.191: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 07:50:03.195
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 07:50:03.198
  Apr 17 07:50:04.198: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/17/23 07:50:04.2
  Apr 17 07:50:04.206: INFO: Waiting for webhook configuration to be ready...
  Apr 17 07:50:14.310: INFO: Waiting for webhook configuration to be ready...
  STEP: create a pod that should be denied by the webhook @ 04/17/23 07:50:14.412
  STEP: create a pod that causes the webhook to hang @ 04/17/23 07:50:14.417
  STEP: create a configmap that should be denied by the webhook @ 04/17/23 07:50:24.42
  STEP: create a configmap that should be admitted by the webhook @ 04/17/23 07:50:24.426
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/17/23 07:50:24.429
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/17/23 07:50:24.431
  STEP: create a namespace that bypass the webhook @ 04/17/23 07:50:24.434
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 04/17/23 07:50:24.438
  Apr 17 07:50:24.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9094" for this suite. @ 04/17/23 07:50:24.453
  STEP: Destroying namespace "webhook-markers-6166" for this suite. @ 04/17/23 07:50:24.456
  STEP: Destroying namespace "exempted-namespace-6727" for this suite. @ 04/17/23 07:50:24.458
â€¢ [23.451 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:147
  STEP: Creating a kubernetes client @ 04/17/23 07:50:24.46
  Apr 17 07:50:24.460: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 07:50:24.46
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:50:24.463
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:50:24.464
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/17/23 07:50:24.465
  STEP: Saw pod success @ 04/17/23 07:50:28.474
  Apr 17 07:50:28.475: INFO: Trying to get logs from node c3-worker pod pod-857e21e8-7cf4-4f72-a817-889f90d9e4ab container test-container: <nil>
  STEP: delete the pod @ 04/17/23 07:50:28.477
  Apr 17 07:50:28.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-524" for this suite. @ 04/17/23 07:50:28.483
â€¢ [4.024 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:167
  STEP: Creating a kubernetes client @ 04/17/23 07:50:28.485
  Apr 17 07:50:28.485: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 07:50:28.485
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:50:28.489
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:50:28.49
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/17/23 07:50:28.491
  STEP: Saw pod success @ 04/17/23 07:50:32.499
  Apr 17 07:50:32.500: INFO: Trying to get logs from node c3-worker pod pod-17097fc0-68bd-4ed0-9607-502f5ace138e container test-container: <nil>
  STEP: delete the pod @ 04/17/23 07:50:32.503
  Apr 17 07:50:32.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3891" for this suite. @ 04/17/23 07:50:32.508
â€¢ [4.025 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]
test/e2e/apps/statefulset.go:912
  STEP: Creating a kubernetes client @ 04/17/23 07:50:32.51
  Apr 17 07:50:32.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename statefulset @ 04/17/23 07:50:32.511
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:50:32.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:50:32.516
  STEP: Creating service test in namespace statefulset-4805 @ 04/17/23 07:50:32.517
  Apr 17 07:50:32.521: INFO: Found 0 stateful pods, waiting for 1
  Apr 17 07:50:42.523: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 04/17/23 07:50:42.525
  W0417 07:50:42.531014      30 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Apr 17 07:50:42.532: INFO: Found 1 stateful pods, waiting for 2
  Apr 17 07:50:52.534: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 17 07:50:52.534: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 04/17/23 07:50:52.536
  STEP: Delete all of the StatefulSets @ 04/17/23 07:50:52.537
  STEP: Verify that StatefulSets have been deleted @ 04/17/23 07:50:52.539
  Apr 17 07:50:52.540: INFO: Deleting all statefulset in ns statefulset-4805
  Apr 17 07:50:52.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4805" for this suite. @ 04/17/23 07:50:52.544
â€¢ [20.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:124
  STEP: Creating a kubernetes client @ 04/17/23 07:50:52.546
  Apr 17 07:50:52.547: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pod-network-test @ 04/17/23 07:50:52.547
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:50:52.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:50:52.552
  STEP: Performing setup for networking test in namespace pod-network-test-9819 @ 04/17/23 07:50:52.553
  STEP: creating a selector @ 04/17/23 07:50:52.553
  STEP: Creating the service pods in kubernetes @ 04/17/23 07:50:52.553
  Apr 17 07:50:52.553: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 04/17/23 07:51:14.591
  Apr 17 07:51:16.601: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Apr 17 07:51:16.601: INFO: Going to poll 10.244.1.74 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  Apr 17 07:51:16.602: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.74 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9819 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:51:16.602: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:51:16.602: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:51:16.602: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9819/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.1.74+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 17 07:51:17.672: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 17 07:51:17.672: INFO: Going to poll 10.244.2.233 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  Apr 17 07:51:17.674: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.233 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9819 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:51:17.674: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:51:17.674: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:51:17.674: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9819/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.2.233+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 17 07:51:18.743: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 17 07:51:18.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-9819" for this suite. @ 04/17/23 07:51:18.744
â€¢ [26.200 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]
test/e2e/apimachinery/resource_quota.go:101
  STEP: Creating a kubernetes client @ 04/17/23 07:51:18.746
  Apr 17 07:51:18.746: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename resourcequota @ 04/17/23 07:51:18.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:51:18.751
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:51:18.752
  STEP: Counting existing ResourceQuota @ 04/17/23 07:51:18.753
  STEP: Creating a ResourceQuota @ 04/17/23 07:51:23.756
  STEP: Ensuring resource quota status is calculated @ 04/17/23 07:51:23.758
  STEP: Creating a Service @ 04/17/23 07:51:25.76
  STEP: Creating a NodePort Service @ 04/17/23 07:51:25.765
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 04/17/23 07:51:25.771
  STEP: Ensuring resource quota status captures service creation @ 04/17/23 07:51:25.776
  STEP: Deleting Services @ 04/17/23 07:51:27.778
  STEP: Ensuring resource quota status released usage @ 04/17/23 07:51:27.785
  Apr 17 07:51:29.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9290" for this suite. @ 04/17/23 07:51:29.788
â€¢ [11.044 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 04/17/23 07:51:29.79
  Apr 17 07:51:29.790: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/17/23 07:51:29.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:51:29.796
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:51:29.797
  Apr 17 07:51:29.798: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 04/17/23 07:51:30.989
  Apr 17 07:51:30.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 --namespace=crd-publish-openapi-4237 create -f -'
  Apr 17 07:51:31.367: INFO: stderr: ""
  Apr 17 07:51:31.367: INFO: stdout: "e2e-test-crd-publish-openapi-5177-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 17 07:51:31.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 --namespace=crd-publish-openapi-4237 delete e2e-test-crd-publish-openapi-5177-crds test-foo'
  Apr 17 07:51:31.409: INFO: stderr: ""
  Apr 17 07:51:31.409: INFO: stdout: "e2e-test-crd-publish-openapi-5177-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Apr 17 07:51:31.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 --namespace=crd-publish-openapi-4237 apply -f -'
  Apr 17 07:51:31.540: INFO: stderr: ""
  Apr 17 07:51:31.540: INFO: stdout: "e2e-test-crd-publish-openapi-5177-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 17 07:51:31.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 --namespace=crd-publish-openapi-4237 delete e2e-test-crd-publish-openapi-5177-crds test-foo'
  Apr 17 07:51:31.582: INFO: stderr: ""
  Apr 17 07:51:31.582: INFO: stdout: "e2e-test-crd-publish-openapi-5177-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 04/17/23 07:51:31.582
  Apr 17 07:51:31.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 --namespace=crd-publish-openapi-4237 create -f -'
  Apr 17 07:51:31.688: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 04/17/23 07:51:31.688
  Apr 17 07:51:31.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 --namespace=crd-publish-openapi-4237 create -f -'
  Apr 17 07:51:31.794: INFO: rc: 1
  Apr 17 07:51:31.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 --namespace=crd-publish-openapi-4237 apply -f -'
  Apr 17 07:51:31.917: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 04/17/23 07:51:31.917
  Apr 17 07:51:31.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 --namespace=crd-publish-openapi-4237 create -f -'
  Apr 17 07:51:32.037: INFO: rc: 1
  Apr 17 07:51:32.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 --namespace=crd-publish-openapi-4237 apply -f -'
  Apr 17 07:51:32.162: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 04/17/23 07:51:32.162
  Apr 17 07:51:32.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 explain e2e-test-crd-publish-openapi-5177-crds'
  Apr 17 07:51:32.283: INFO: stderr: ""
  Apr 17 07:51:32.283: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5177-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 04/17/23 07:51:32.283
  Apr 17 07:51:32.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 explain e2e-test-crd-publish-openapi-5177-crds.metadata'
  Apr 17 07:51:32.410: INFO: stderr: ""
  Apr 17 07:51:32.410: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5177-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Apr 17 07:51:32.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 explain e2e-test-crd-publish-openapi-5177-crds.spec'
  Apr 17 07:51:32.532: INFO: stderr: ""
  Apr 17 07:51:32.532: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5177-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Apr 17 07:51:32.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 explain e2e-test-crd-publish-openapi-5177-crds.spec.bars'
  Apr 17 07:51:32.650: INFO: stderr: ""
  Apr 17 07:51:32.650: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-5177-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 04/17/23 07:51:32.65
  Apr 17 07:51:32.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-4237 explain e2e-test-crd-publish-openapi-5177-crds.spec.bars2'
  Apr 17 07:51:32.770: INFO: rc: 1
  Apr 17 07:51:33.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4237" for this suite. @ 04/17/23 07:51:33.963
â€¢ [4.175 seconds]
------------------------------
SSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 04/17/23 07:51:33.965
  Apr 17 07:51:33.965: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename containers @ 04/17/23 07:51:33.966
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:51:33.97
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:51:33.971
  Apr 17 07:51:35.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5357" for this suite. @ 04/17/23 07:51:35.983
â€¢ [2.019 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 04/17/23 07:51:35.985
  Apr 17 07:51:35.985: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename watch @ 04/17/23 07:51:35.985
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:51:35.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:51:35.991
  STEP: creating a watch on configmaps with label A @ 04/17/23 07:51:35.992
  STEP: creating a watch on configmaps with label B @ 04/17/23 07:51:35.992
  STEP: creating a watch on configmaps with label A or B @ 04/17/23 07:51:35.993
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 04/17/23 07:51:35.993
  Apr 17 07:51:35.994: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-729  ec639947-de4a-46ad-9b63-5b38d01316e6 64418 0 2023-04-17 07:51:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-17 07:51:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 07:51:35.994: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-729  ec639947-de4a-46ad-9b63-5b38d01316e6 64418 0 2023-04-17 07:51:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-17 07:51:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 04/17/23 07:51:35.994
  Apr 17 07:51:35.996: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-729  ec639947-de4a-46ad-9b63-5b38d01316e6 64419 0 2023-04-17 07:51:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-17 07:51:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 07:51:35.996: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-729  ec639947-de4a-46ad-9b63-5b38d01316e6 64419 0 2023-04-17 07:51:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-17 07:51:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 04/17/23 07:51:35.996
  Apr 17 07:51:35.999: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-729  ec639947-de4a-46ad-9b63-5b38d01316e6 64420 0 2023-04-17 07:51:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-17 07:51:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 07:51:35.999: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-729  ec639947-de4a-46ad-9b63-5b38d01316e6 64420 0 2023-04-17 07:51:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-17 07:51:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 04/17/23 07:51:35.999
  Apr 17 07:51:36.000: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-729  ec639947-de4a-46ad-9b63-5b38d01316e6 64421 0 2023-04-17 07:51:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-17 07:51:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 07:51:36.000: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-729  ec639947-de4a-46ad-9b63-5b38d01316e6 64421 0 2023-04-17 07:51:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-17 07:51:35 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 04/17/23 07:51:36
  Apr 17 07:51:36.001: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-729  4205a383-16f4-45cc-a8c6-59ee8f7a3d85 64422 0 2023-04-17 07:51:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-17 07:51:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 07:51:36.001: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-729  4205a383-16f4-45cc-a8c6-59ee8f7a3d85 64422 0 2023-04-17 07:51:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-17 07:51:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 04/17/23 07:51:46.001
  Apr 17 07:51:46.004: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-729  4205a383-16f4-45cc-a8c6-59ee8f7a3d85 64456 0 2023-04-17 07:51:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-17 07:51:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 07:51:46.004: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-729  4205a383-16f4-45cc-a8c6-59ee8f7a3d85 64456 0 2023-04-17 07:51:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-17 07:51:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 07:51:56.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-729" for this suite. @ 04/17/23 07:51:56.006
â€¢ [20.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]
test/e2e/apps/rc.go:94
  STEP: Creating a kubernetes client @ 04/17/23 07:51:56.009
  Apr 17 07:51:56.009: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename replication-controller @ 04/17/23 07:51:56.009
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:51:56.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:51:56.014
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 04/17/23 07:51:56.015
  STEP: When a replication controller with a matching selector is created @ 04/17/23 07:51:58.022
  STEP: Then the orphan pod is adopted @ 04/17/23 07:51:58.024
  Apr 17 07:51:59.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-1700" for this suite. @ 04/17/23 07:51:59.028
â€¢ [3.021 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:152
  STEP: Creating a kubernetes client @ 04/17/23 07:51:59.03
  Apr 17 07:51:59.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/17/23 07:51:59.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:51:59.034
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:51:59.035
  STEP: create the container to handle the HTTPGet hook request. @ 04/17/23 07:51:59.038
  STEP: create the pod with lifecycle hook @ 04/17/23 07:52:01.045
  STEP: delete the pod with lifecycle hook @ 04/17/23 07:52:03.051
  STEP: check prestop hook @ 04/17/23 07:52:05.056
  Apr 17 07:52:05.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4245" for this suite. @ 04/17/23 07:52:05.062
â€¢ [6.034 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 04/17/23 07:52:05.064
  Apr 17 07:52:05.064: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-probe @ 04/17/23 07:52:05.065
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:52:05.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:52:05.07
  STEP: Creating pod liveness-448b4157-f130-4129-a19a-596dd14ee79e in namespace container-probe-2233 @ 04/17/23 07:52:05.071
  Apr 17 07:52:07.076: INFO: Started pod liveness-448b4157-f130-4129-a19a-596dd14ee79e in namespace container-probe-2233
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/17/23 07:52:07.076
  Apr 17 07:52:07.077: INFO: Initial restart count of pod liveness-448b4157-f130-4129-a19a-596dd14ee79e is 0
  Apr 17 07:52:27.102: INFO: Restart count of pod container-probe-2233/liveness-448b4157-f130-4129-a19a-596dd14ee79e is now 1 (20.024676384s elapsed)
  Apr 17 07:52:27.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 07:52:27.103
  STEP: Destroying namespace "container-probe-2233" for this suite. @ 04/17/23 07:52:27.107
â€¢ [22.044 seconds]
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:95
  STEP: Creating a kubernetes client @ 04/17/23 07:52:27.109
  Apr 17 07:52:27.109: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pod-network-test @ 04/17/23 07:52:27.109
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:52:27.113
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:52:27.114
  STEP: Performing setup for networking test in namespace pod-network-test-9724 @ 04/17/23 07:52:27.115
  STEP: creating a selector @ 04/17/23 07:52:27.115
  STEP: Creating the service pods in kubernetes @ 04/17/23 07:52:27.115
  Apr 17 07:52:27.115: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 04/17/23 07:52:39.142
  Apr 17 07:52:41.148: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Apr 17 07:52:41.148: INFO: Breadth first check of 10.244.1.80 on host 172.18.0.3...
  Apr 17 07:52:41.149: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.81:9080/dial?request=hostname&protocol=udp&host=10.244.1.80&port=8081&tries=1'] Namespace:pod-network-test-9724 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:52:41.149: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:52:41.149: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:52:41.149: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9724/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.81%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.1.80%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 17 07:52:41.217: INFO: Waiting for responses: map[]
  Apr 17 07:52:41.217: INFO: reached 10.244.1.80 after 0/1 tries
  Apr 17 07:52:41.217: INFO: Breadth first check of 10.244.2.235 on host 172.18.0.4...
  Apr 17 07:52:41.218: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.81:9080/dial?request=hostname&protocol=udp&host=10.244.2.235&port=8081&tries=1'] Namespace:pod-network-test-9724 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:52:41.218: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:52:41.218: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:52:41.219: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9724/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.81%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.2.235%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 17 07:52:41.267: INFO: Waiting for responses: map[]
  Apr 17 07:52:41.267: INFO: reached 10.244.2.235 after 0/1 tries
  Apr 17 07:52:41.267: INFO: Going to retry 0 out of 2 pods....
  Apr 17 07:52:41.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-9724" for this suite. @ 04/17/23 07:52:41.268
â€¢ [14.161 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 04/17/23 07:52:41.27
  Apr 17 07:52:41.270: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename disruption @ 04/17/23 07:52:41.271
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:52:41.275
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:52:41.277
  STEP: Waiting for the pdb to be processed @ 04/17/23 07:52:41.279
  STEP: Waiting for all pods to be running @ 04/17/23 07:52:43.29
  Apr 17 07:52:43.291: INFO: running pods: 0 < 3
  Apr 17 07:52:45.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8321" for this suite. @ 04/17/23 07:52:45.297
â€¢ [4.028 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/configmap_volume.go:504
  STEP: Creating a kubernetes client @ 04/17/23 07:52:45.299
  Apr 17 07:52:45.299: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 07:52:45.299
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:52:45.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:52:45.304
  Apr 17 07:52:45.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-408" for this suite. @ 04/17/23 07:52:45.317
â€¢ [0.020 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:131
  STEP: Creating a kubernetes client @ 04/17/23 07:52:45.319
  Apr 17 07:52:45.319: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:52:45.319
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:52:45.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:52:45.324
  STEP: Creating the pod @ 04/17/23 07:52:45.325
  Apr 17 07:52:47.843: INFO: Successfully updated pod "labelsupdate1e733728-e507-4c84-9ddc-416f3e4d411c"
  Apr 17 07:52:51.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5094" for this suite. @ 04/17/23 07:52:51.853
â€¢ [6.536 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:55
  STEP: Creating a kubernetes client @ 04/17/23 07:52:51.855
  Apr 17 07:52:51.855: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename runtimeclass @ 04/17/23 07:52:51.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:52:51.859
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:52:51.86
  Apr 17 07:52:51.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9296" for this suite. @ 04/17/23 07:52:51.865
â€¢ [0.011 seconds]
------------------------------
S
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 04/17/23 07:52:51.867
  Apr 17 07:52:51.867: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename proxy @ 04/17/23 07:52:51.867
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:52:51.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:52:51.871
  Apr 17 07:52:51.872: INFO: Creating pod...
  Apr 17 07:52:53.879: INFO: Creating service...
  Apr 17 07:52:53.881: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/pods/agnhost/proxy/some/path/with/DELETE
  Apr 17 07:52:53.883: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 17 07:52:53.883: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/pods/agnhost/proxy/some/path/with/GET
  Apr 17 07:52:53.884: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 17 07:52:53.884: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/pods/agnhost/proxy/some/path/with/HEAD
  Apr 17 07:52:53.885: INFO: http.Client request:HEAD | StatusCode:200
  Apr 17 07:52:53.885: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/pods/agnhost/proxy/some/path/with/OPTIONS
  Apr 17 07:52:53.886: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 17 07:52:53.886: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/pods/agnhost/proxy/some/path/with/PATCH
  Apr 17 07:52:53.887: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 17 07:52:53.887: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/pods/agnhost/proxy/some/path/with/POST
  Apr 17 07:52:53.888: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 17 07:52:53.888: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/pods/agnhost/proxy/some/path/with/PUT
  Apr 17 07:52:53.888: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 17 07:52:53.888: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/services/test-service/proxy/some/path/with/DELETE
  Apr 17 07:52:53.889: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 17 07:52:53.890: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/services/test-service/proxy/some/path/with/GET
  Apr 17 07:52:53.891: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 17 07:52:53.891: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/services/test-service/proxy/some/path/with/HEAD
  Apr 17 07:52:53.892: INFO: http.Client request:HEAD | StatusCode:200
  Apr 17 07:52:53.892: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/services/test-service/proxy/some/path/with/OPTIONS
  Apr 17 07:52:53.893: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 17 07:52:53.893: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/services/test-service/proxy/some/path/with/PATCH
  Apr 17 07:52:53.894: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 17 07:52:53.894: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/services/test-service/proxy/some/path/with/POST
  Apr 17 07:52:53.895: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 17 07:52:53.895: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-4387/services/test-service/proxy/some/path/with/PUT
  Apr 17 07:52:53.896: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 17 07:52:53.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-4387" for this suite. @ 04/17/23 07:52:53.897
â€¢ [2.032 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:194
  STEP: Creating a kubernetes client @ 04/17/23 07:52:53.899
  Apr 17 07:52:53.899: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 07:52:53.9
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:52:53.905
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:52:53.906
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 07:52:53.907
  STEP: Saw pod success @ 04/17/23 07:52:57.915
  Apr 17 07:52:57.916: INFO: Trying to get logs from node c3-worker pod downwardapi-volume-e0e76868-0eca-4786-bb85-30ee46b0196a container client-container: <nil>
  STEP: delete the pod @ 04/17/23 07:52:57.918
  Apr 17 07:52:57.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3094" for this suite. @ 04/17/23 07:52:57.924
â€¢ [4.027 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:123
  STEP: Creating a kubernetes client @ 04/17/23 07:52:57.926
  Apr 17 07:52:57.926: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename sysctl @ 04/17/23 07:52:57.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:52:57.93
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:52:57.932
  STEP: Creating a pod with one valid and two invalid sysctls @ 04/17/23 07:52:57.933
  Apr 17 07:52:57.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-3176" for this suite. @ 04/17/23 07:52:57.936
â€¢ [0.012 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]
test/e2e/apimachinery/webhook.go:314
  STEP: Creating a kubernetes client @ 04/17/23 07:52:57.938
  Apr 17 07:52:57.938: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 07:52:57.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:52:57.943
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:52:57.944
  STEP: Setting up server cert @ 04/17/23 07:52:57.95
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 07:52:58.181
  STEP: Deploying the webhook pod @ 04/17/23 07:52:58.183
  STEP: Wait for the deployment to be ready @ 04/17/23 07:52:58.186
  Apr 17 07:52:58.189: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/17/23 07:53:00.194
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 07:53:00.197
  Apr 17 07:53:01.198: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 17 07:53:01.200: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9238-crds.webhook.example.com via the AdmissionRegistration API @ 04/17/23 07:53:01.704
  STEP: Creating a custom resource while v1 is storage version @ 04/17/23 07:53:01.711
  STEP: Patching Custom Resource Definition to set v2 as storage @ 04/17/23 07:53:03.733
  STEP: Patching the custom resource while v2 is storage version @ 04/17/23 07:53:03.752
  Apr 17 07:53:03.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6594" for this suite. @ 04/17/23 07:53:04.287
  STEP: Destroying namespace "webhook-markers-1476" for this suite. @ 04/17/23 07:53:04.289
â€¢ [6.352 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance]
test/e2e/apps/job.go:642
  STEP: Creating a kubernetes client @ 04/17/23 07:53:04.291
  Apr 17 07:53:04.291: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename job @ 04/17/23 07:53:04.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:53:04.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:53:04.297
  STEP: Creating a job @ 04/17/23 07:53:04.298
  STEP: Ensure pods equal to parallelism count is attached to the job @ 04/17/23 07:53:04.3
  STEP: patching /status @ 04/17/23 07:53:06.302
  STEP: updating /status @ 04/17/23 07:53:06.305
  STEP: get /status @ 04/17/23 07:53:06.308
  Apr 17 07:53:06.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5473" for this suite. @ 04/17/23 07:53:06.31
â€¢ [2.021 seconds]
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance]
test/e2e/instrumentation/core_events.go:175
  STEP: Creating a kubernetes client @ 04/17/23 07:53:06.312
  Apr 17 07:53:06.312: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename events @ 04/17/23 07:53:06.312
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:53:06.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:53:06.317
  STEP: Create set of events @ 04/17/23 07:53:06.318
  Apr 17 07:53:06.319: INFO: created test-event-1
  Apr 17 07:53:06.320: INFO: created test-event-2
  Apr 17 07:53:06.321: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 04/17/23 07:53:06.321
  STEP: delete collection of events @ 04/17/23 07:53:06.322
  Apr 17 07:53:06.322: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/17/23 07:53:06.326
  Apr 17 07:53:06.326: INFO: requesting list of events to confirm quantity
  Apr 17 07:53:06.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8815" for this suite. @ 04/17/23 07:53:06.328
â€¢ [0.018 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 04/17/23 07:53:06.33
  Apr 17 07:53:06.330: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename events @ 04/17/23 07:53:06.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:53:06.333
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:53:06.334
  STEP: Create set of events @ 04/17/23 07:53:06.335
  STEP: get a list of Events with a label in the current namespace @ 04/17/23 07:53:06.339
  STEP: delete a list of events @ 04/17/23 07:53:06.34
  Apr 17 07:53:06.340: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/17/23 07:53:06.344
  Apr 17 07:53:06.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6879" for this suite. @ 04/17/23 07:53:06.346
â€¢ [0.018 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:141
  STEP: Creating a kubernetes client @ 04/17/23 07:53:06.348
  Apr 17 07:53:06.348: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename crd-webhook @ 04/17/23 07:53:06.348
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:53:06.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:53:06.353
  STEP: Setting up server cert @ 04/17/23 07:53:06.354
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/17/23 07:53:06.487
  STEP: Deploying the custom resource conversion webhook pod @ 04/17/23 07:53:06.489
  STEP: Wait for the deployment to be ready @ 04/17/23 07:53:06.493
  Apr 17 07:53:06.495: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/17/23 07:53:08.5
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 07:53:08.503
  Apr 17 07:53:09.503: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 17 07:53:09.504: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Creating a v1 custom resource @ 04/17/23 07:53:12.036
  STEP: v2 custom resource should be converted @ 04/17/23 07:53:12.038
  Apr 17 07:53:12.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-1683" for this suite. @ 04/17/23 07:53:12.555
â€¢ [6.208 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 04/17/23 07:53:12.556
  Apr 17 07:53:12.556: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:53:12.557
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:53:12.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:53:12.561
  STEP: Creating projection with secret that has name projected-secret-test-209b9384-1bb4-4368-8b78-f821f67240cd @ 04/17/23 07:53:12.562
  STEP: Creating a pod to test consume secrets @ 04/17/23 07:53:12.564
  STEP: Saw pod success @ 04/17/23 07:53:16.572
  Apr 17 07:53:16.573: INFO: Trying to get logs from node c3-worker pod pod-projected-secrets-aaf6cdc9-02f0-4bbb-9147-2bb846674c3e container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 07:53:16.575
  Apr 17 07:53:16.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7395" for this suite. @ 04/17/23 07:53:16.579
â€¢ [4.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance]
test/e2e/network/service.go:3322
  STEP: Creating a kubernetes client @ 04/17/23 07:53:16.581
  Apr 17 07:53:16.582: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 07:53:16.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:53:16.586
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:53:16.587
  STEP: creating a Service @ 04/17/23 07:53:16.589
  STEP: watching for the Service to be added @ 04/17/23 07:53:16.591
  Apr 17 07:53:16.592: INFO: Found Service test-service-bdtwg in namespace services-1622 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
  Apr 17 07:53:16.592: INFO: Service test-service-bdtwg created
  STEP: Getting /status @ 04/17/23 07:53:16.592
  Apr 17 07:53:16.593: INFO: Service test-service-bdtwg has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 04/17/23 07:53:16.593
  STEP: watching for the Service to be patched @ 04/17/23 07:53:16.595
  Apr 17 07:53:16.596: INFO: observed Service test-service-bdtwg in namespace services-1622 with annotations: map[] & LoadBalancer: {[]}
  Apr 17 07:53:16.596: INFO: Found Service test-service-bdtwg in namespace services-1622 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
  Apr 17 07:53:16.596: INFO: Service test-service-bdtwg has service status patched
  STEP: updating the ServiceStatus @ 04/17/23 07:53:16.596
  Apr 17 07:53:16.600: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 04/17/23 07:53:16.6
  Apr 17 07:53:16.600: INFO: Observed Service test-service-bdtwg in namespace services-1622 with annotations: map[] & Conditions: {[]}
  Apr 17 07:53:16.600: INFO: Observed event: &Service{ObjectMeta:{test-service-bdtwg  services-1622  51e7c0b7-48d5-4f75-b53a-2e00a426e449 65188 0 2023-04-17 07:53:16 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-17 07:53:16 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-17 07:53:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.96.181.61,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.96.181.61],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Apr 17 07:53:16.600: INFO: Found Service test-service-bdtwg in namespace services-1622 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 17 07:53:16.600: INFO: Service test-service-bdtwg has service status updated
  STEP: patching the service @ 04/17/23 07:53:16.6
  STEP: watching for the Service to be patched @ 04/17/23 07:53:16.607
  Apr 17 07:53:16.607: INFO: observed Service test-service-bdtwg in namespace services-1622 with labels: map[test-service-static:true]
  Apr 17 07:53:16.607: INFO: observed Service test-service-bdtwg in namespace services-1622 with labels: map[test-service-static:true]
  Apr 17 07:53:16.607: INFO: observed Service test-service-bdtwg in namespace services-1622 with labels: map[test-service-static:true]
  Apr 17 07:53:16.607: INFO: Found Service test-service-bdtwg in namespace services-1622 with labels: map[test-service:patched test-service-static:true]
  Apr 17 07:53:16.607: INFO: Service test-service-bdtwg patched
  STEP: deleting the service @ 04/17/23 07:53:16.607
  STEP: watching for the Service to be deleted @ 04/17/23 07:53:16.611
  Apr 17 07:53:16.611: INFO: Observed event: ADDED
  Apr 17 07:53:16.611: INFO: Observed event: MODIFIED
  Apr 17 07:53:16.611: INFO: Observed event: MODIFIED
  Apr 17 07:53:16.611: INFO: Observed event: MODIFIED
  Apr 17 07:53:16.611: INFO: Found Service test-service-bdtwg in namespace services-1622 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Apr 17 07:53:16.611: INFO: Service test-service-bdtwg deleted
  Apr 17 07:53:16.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1622" for this suite. @ 04/17/23 07:53:16.613
â€¢ [0.033 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 04/17/23 07:53:16.615
  Apr 17 07:53:16.615: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename proxy @ 04/17/23 07:53:16.615
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:53:16.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:53:16.619
  Apr 17 07:53:16.621: INFO: Creating pod...
  Apr 17 07:53:18.626: INFO: Creating service...
  Apr 17 07:53:18.629: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/pods/agnhost/proxy?method=DELETE
  Apr 17 07:53:18.631: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 17 07:53:18.631: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/pods/agnhost/proxy?method=OPTIONS
  Apr 17 07:53:18.632: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 17 07:53:18.632: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/pods/agnhost/proxy?method=PATCH
  Apr 17 07:53:18.633: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 17 07:53:18.633: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/pods/agnhost/proxy?method=POST
  Apr 17 07:53:18.634: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 17 07:53:18.634: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/pods/agnhost/proxy?method=PUT
  Apr 17 07:53:18.635: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 17 07:53:18.635: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/services/e2e-proxy-test-service/proxy?method=DELETE
  Apr 17 07:53:18.636: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 17 07:53:18.636: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Apr 17 07:53:18.637: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 17 07:53:18.637: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/services/e2e-proxy-test-service/proxy?method=PATCH
  Apr 17 07:53:18.638: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 17 07:53:18.638: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/services/e2e-proxy-test-service/proxy?method=POST
  Apr 17 07:53:18.639: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 17 07:53:18.639: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/services/e2e-proxy-test-service/proxy?method=PUT
  Apr 17 07:53:18.640: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 17 07:53:18.640: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/pods/agnhost/proxy?method=GET
  Apr 17 07:53:18.641: INFO: http.Client request:GET StatusCode:301
  Apr 17 07:53:18.641: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/services/e2e-proxy-test-service/proxy?method=GET
  Apr 17 07:53:18.642: INFO: http.Client request:GET StatusCode:301
  Apr 17 07:53:18.642: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/pods/agnhost/proxy?method=HEAD
  Apr 17 07:53:18.643: INFO: http.Client request:HEAD StatusCode:301
  Apr 17 07:53:18.643: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-2606/services/e2e-proxy-test-service/proxy?method=HEAD
  Apr 17 07:53:18.644: INFO: http.Client request:HEAD StatusCode:301
  Apr 17 07:53:18.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-2606" for this suite. @ 04/17/23 07:53:18.645
â€¢ [2.032 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 04/17/23 07:53:18.647
  Apr 17 07:53:18.647: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename sched-pred @ 04/17/23 07:53:18.647
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:53:18.651
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:53:18.652
  Apr 17 07:53:18.653: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 17 07:53:18.655: INFO: Waiting for terminating namespaces to be deleted...
  Apr 17 07:53:18.656: INFO: 
  Logging pods the apiserver thinks is on node c3-worker before test
  Apr 17 07:53:18.658: INFO: suspend-false-to-true-8qvfv from job-5473 started at 2023-04-17 07:53:04 +0000 UTC (1 container statuses recorded)
  Apr 17 07:53:18.658: INFO: 	Container c ready: true, restart count 0
  Apr 17 07:53:18.658: INFO: suspend-false-to-true-snhc6 from job-5473 started at 2023-04-17 07:53:04 +0000 UTC (1 container statuses recorded)
  Apr 17 07:53:18.658: INFO: 	Container c ready: true, restart count 0
  Apr 17 07:53:18.658: INFO: kindnet-plq69 from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 07:53:18.658: INFO: 	Container kindnet-cni ready: true, restart count 0
  Apr 17 07:53:18.658: INFO: kube-proxy-6r2kb from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 07:53:18.658: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 17 07:53:18.658: INFO: sonobuoy from sonobuoy started at 2023-04-17 06:33:09 +0000 UTC (1 container statuses recorded)
  Apr 17 07:53:18.658: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 17 07:53:18.658: INFO: sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-7tzl9 from sonobuoy started at 2023-04-17 06:33:10 +0000 UTC (2 container statuses recorded)
  Apr 17 07:53:18.658: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 07:53:18.658: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 17 07:53:18.658: INFO: 
  Logging pods the apiserver thinks is on node c3-worker2 before test
  Apr 17 07:53:18.660: INFO: kindnet-br9l4 from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 07:53:18.660: INFO: 	Container kindnet-cni ready: true, restart count 0
  Apr 17 07:53:18.660: INFO: kube-proxy-stm68 from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 07:53:18.660: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 17 07:53:18.660: INFO: agnhost from proxy-2606 started at 2023-04-17 07:53:16 +0000 UTC (1 container statuses recorded)
  Apr 17 07:53:18.660: INFO: 	Container agnhost ready: true, restart count 0
  Apr 17 07:53:18.660: INFO: sonobuoy-e2e-job-e91f319b048a45eb from sonobuoy started at 2023-04-17 06:33:10 +0000 UTC (2 container statuses recorded)
  Apr 17 07:53:18.660: INFO: 	Container e2e ready: true, restart count 0
  Apr 17 07:53:18.660: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 07:53:18.660: INFO: sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-svr2p from sonobuoy started at 2023-04-17 06:33:10 +0000 UTC (2 container statuses recorded)
  Apr 17 07:53:18.660: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 07:53:18.660: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/17/23 07:53:18.66
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/17/23 07:53:20.667
  STEP: Trying to apply a random label on the found node. @ 04/17/23 07:53:20.671
  STEP: verifying the node has the label kubernetes.io/e2e-fd731f97-759d-498e-bd9d-101501be995c 95 @ 04/17/23 07:53:20.674
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 04/17/23 07:53:20.675
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.18.0.3 on the node which pod4 resides and expect not scheduled @ 04/17/23 07:53:22.681
  STEP: removing the label kubernetes.io/e2e-fd731f97-759d-498e-bd9d-101501be995c off the node c3-worker @ 04/17/23 07:58:22.685
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-fd731f97-759d-498e-bd9d-101501be995c @ 04/17/23 07:58:22.69
  Apr 17 07:58:22.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-6002" for this suite. @ 04/17/23 07:58:22.692
â€¢ [304.047 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2224
  STEP: Creating a kubernetes client @ 04/17/23 07:58:22.694
  Apr 17 07:58:22.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 07:58:22.694
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:58:22.698
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:58:22.699
  STEP: creating service in namespace services-1702 @ 04/17/23 07:58:22.701
  STEP: creating service affinity-nodeport-transition in namespace services-1702 @ 04/17/23 07:58:22.701
  STEP: creating replication controller affinity-nodeport-transition in namespace services-1702 @ 04/17/23 07:58:22.705
  I0417 07:58:22.707376      30 runners.go:194] Created replication controller with name: affinity-nodeport-transition, namespace: services-1702, replica count: 3
  I0417 07:58:25.760126      30 runners.go:194] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 17 07:58:25.764: INFO: Creating new exec pod
  Apr 17 07:58:28.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-1702 exec execpod-affinitysrx4v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  Apr 17 07:58:28.884: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Apr 17 07:58:28.884: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:58:28.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-1702 exec execpod-affinitysrx4v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.244.255 80'
  Apr 17 07:58:28.995: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.244.255 80\nConnection to 10.96.244.255 80 port [tcp/http] succeeded!\n"
  Apr 17 07:58:28.995: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:58:28.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-1702 exec execpod-affinitysrx4v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.18.0.3 31414'
  Apr 17 07:58:29.124: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.18.0.3 31414\nConnection to 172.18.0.3 31414 port [tcp/*] succeeded!\n"
  Apr 17 07:58:29.124: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:58:29.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-1702 exec execpod-affinitysrx4v -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.18.0.4 31414'
  Apr 17 07:58:29.232: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.18.0.4 31414\nConnection to 172.18.0.4 31414 port [tcp/*] succeeded!\n"
  Apr 17 07:58:29.233: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 07:58:29.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-1702 exec execpod-affinitysrx4v -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.18.0.3:31414/ ; done'
  Apr 17 07:58:29.378: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n"
  Apr 17 07:58:29.378: INFO: stdout: "\naffinity-nodeport-transition-pf6hg\naffinity-nodeport-transition-pf6hg\naffinity-nodeport-transition-c2k2z\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-c2k2z\naffinity-nodeport-transition-c2k2z\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-c2k2z\naffinity-nodeport-transition-pf6hg\naffinity-nodeport-transition-pf6hg\naffinity-nodeport-transition-pf6hg\naffinity-nodeport-transition-c2k2z\naffinity-nodeport-transition-c2k2z\naffinity-nodeport-transition-pf6hg\naffinity-nodeport-transition-c2k2z\naffinity-nodeport-transition-pf6hg"
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-pf6hg
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-pf6hg
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-c2k2z
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-c2k2z
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-c2k2z
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-c2k2z
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-pf6hg
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-pf6hg
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-pf6hg
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-c2k2z
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-c2k2z
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-pf6hg
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-c2k2z
  Apr 17 07:58:29.378: INFO: Received response from host: affinity-nodeport-transition-pf6hg
  Apr 17 07:58:29.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-1702 exec execpod-affinitysrx4v -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.18.0.3:31414/ ; done'
  Apr 17 07:58:29.544: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.18.0.3:31414/\n"
  Apr 17 07:58:29.544: INFO: stdout: "\naffinity-nodeport-transition-pf6hg\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq\naffinity-nodeport-transition-w9vxq"
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-pf6hg
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Received response from host: affinity-nodeport-transition-w9vxq
  Apr 17 07:58:29.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 17 07:58:29.546: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-1702, will wait for the garbage collector to delete the pods @ 04/17/23 07:58:29.55
  Apr 17 07:58:29.604: INFO: Deleting ReplicationController affinity-nodeport-transition took: 2.268126ms
  Apr 17 07:58:29.705: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.676293ms
  STEP: Destroying namespace "services-1702" for this suite. @ 04/17/23 07:58:31.511
â€¢ [8.819 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 04/17/23 07:58:31.513
  Apr 17 07:58:31.513: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 07:58:31.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:58:31.517
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:58:31.518
  STEP: Creating secret with name secret-test-df79a020-fffd-4f0d-a938-129033cb00af @ 04/17/23 07:58:31.524
  STEP: Creating a pod to test consume secrets @ 04/17/23 07:58:31.525
  STEP: Saw pod success @ 04/17/23 07:58:35.533
  Apr 17 07:58:35.534: INFO: Trying to get logs from node c3-worker pod pod-secrets-b1be6be7-cbcc-4319-8be7-a3d529c9316a container secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 07:58:35.544
  Apr 17 07:58:35.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1254" for this suite. @ 04/17/23 07:58:35.549
  STEP: Destroying namespace "secret-namespace-6861" for this suite. @ 04/17/23 07:58:35.551
â€¢ [4.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:168
  STEP: Creating a kubernetes client @ 04/17/23 07:58:35.554
  Apr 17 07:58:35.554: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/17/23 07:58:35.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:58:35.558
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:58:35.559
  STEP: create the container to handle the HTTPGet hook request. @ 04/17/23 07:58:35.561
  STEP: create the pod with lifecycle hook @ 04/17/23 07:58:37.567
  STEP: check poststart hook @ 04/17/23 07:58:39.573
  STEP: delete the pod with lifecycle hook @ 04/17/23 07:58:39.582
  Apr 17 07:58:41.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-3370" for this suite. @ 04/17/23 07:58:41.588
â€¢ [6.036 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]
test/e2e/apimachinery/webhook.go:220
  STEP: Creating a kubernetes client @ 04/17/23 07:58:41.589
  Apr 17 07:58:41.589: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 07:58:41.59
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:58:41.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:58:41.595
  STEP: Setting up server cert @ 04/17/23 07:58:41.601
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 07:58:42.078
  STEP: Deploying the webhook pod @ 04/17/23 07:58:42.08
  STEP: Wait for the deployment to be ready @ 04/17/23 07:58:42.084
  Apr 17 07:58:42.086: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 07:58:44.09
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 07:58:44.093
  Apr 17 07:58:45.093: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 17 07:58:45.095: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 04/17/23 07:58:45.599
  STEP: Creating a custom resource that should be denied by the webhook @ 04/17/23 07:58:45.605
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 04/17/23 07:58:47.618
  STEP: Updating the custom resource with disallowed data should be denied @ 04/17/23 07:58:47.621
  STEP: Deleting the custom resource should be denied @ 04/17/23 07:58:47.624
  STEP: Remove the offending key and value from the custom resource data @ 04/17/23 07:58:47.626
  STEP: Deleting the updated custom resource should be successful @ 04/17/23 07:58:47.629
  Apr 17 07:58:47.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6331" for this suite. @ 04/17/23 07:58:48.145
  STEP: Destroying namespace "webhook-markers-3400" for this suite. @ 04/17/23 07:58:48.147
â€¢ [6.560 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 04/17/23 07:58:48.15
  Apr 17 07:58:48.150: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-runtime @ 04/17/23 07:58:48.151
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:58:48.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:58:48.156
  STEP: create the container @ 04/17/23 07:58:48.157
  W0417 07:58:48.160224      30 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 04/17/23 07:58:48.16
  STEP: get the container status @ 04/17/23 07:58:51.166
  STEP: the container should be terminated @ 04/17/23 07:58:51.167
  STEP: the termination message should be set @ 04/17/23 07:58:51.167
  Apr 17 07:58:51.167: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 04/17/23 07:58:51.167
  Apr 17 07:58:51.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1366" for this suite. @ 04/17/23 07:58:51.173
â€¢ [3.024 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]
test/e2e/kubectl/kubectl.go:1640
  STEP: Creating a kubernetes client @ 04/17/23 07:58:51.175
  Apr 17 07:58:51.175: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 07:58:51.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:58:51.179
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:58:51.18
  STEP: creating Agnhost RC @ 04/17/23 07:58:51.182
  Apr 17 07:58:51.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1643 create -f -'
  Apr 17 07:58:51.634: INFO: stderr: ""
  Apr 17 07:58:51.634: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/17/23 07:58:51.634
  Apr 17 07:58:52.636: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 17 07:58:52.636: INFO: Found 1 / 1
  Apr 17 07:58:52.636: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 04/17/23 07:58:52.636
  Apr 17 07:58:52.637: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 17 07:58:52.637: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 17 07:58:52.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1643 patch pod agnhost-primary-cvtml -p {"metadata":{"annotations":{"x":"y"}}}'
  Apr 17 07:58:52.681: INFO: stderr: ""
  Apr 17 07:58:52.681: INFO: stdout: "pod/agnhost-primary-cvtml patched\n"
  STEP: checking annotations @ 04/17/23 07:58:52.681
  Apr 17 07:58:52.682: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 17 07:58:52.682: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 17 07:58:52.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1643" for this suite. @ 04/17/23 07:58:52.683
â€¢ [1.510 seconds]
------------------------------
SSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]
test/e2e/common/node/podtemplates.go:53
  STEP: Creating a kubernetes client @ 04/17/23 07:58:52.685
  Apr 17 07:58:52.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename podtemplate @ 04/17/23 07:58:52.686
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:58:52.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:58:52.69
  Apr 17 07:58:52.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-7148" for this suite. @ 04/17/23 07:58:52.7
â€¢ [0.017 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 04/17/23 07:58:52.704
  Apr 17 07:58:52.704: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 04/17/23 07:58:52.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:58:52.708
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:58:52.709
  STEP: Setting up the test @ 04/17/23 07:58:52.71
  STEP: Creating hostNetwork=false pod @ 04/17/23 07:58:52.71
  STEP: Creating hostNetwork=true pod @ 04/17/23 07:58:54.716
  STEP: Running the test @ 04/17/23 07:58:56.723
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 04/17/23 07:58:56.723
  Apr 17 07:58:56.723: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4942 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:58:56.723: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:58:56.723: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:58:56.723: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4942/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 17 07:58:56.786: INFO: Exec stderr: ""
  Apr 17 07:58:56.786: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4942 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:58:56.786: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:58:56.787: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:58:56.787: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4942/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 17 07:58:56.829: INFO: Exec stderr: ""
  Apr 17 07:58:56.829: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4942 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:58:56.829: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:58:56.830: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:58:56.830: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4942/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 17 07:58:56.873: INFO: Exec stderr: ""
  Apr 17 07:58:56.873: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4942 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:58:56.873: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:58:56.873: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:58:56.873: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4942/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 17 07:58:56.938: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 04/17/23 07:58:56.938
  Apr 17 07:58:56.938: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4942 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:58:56.938: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:58:56.939: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:58:56.939: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4942/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 17 07:58:56.980: INFO: Exec stderr: ""
  Apr 17 07:58:56.980: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4942 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:58:56.980: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:58:56.980: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:58:56.980: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4942/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 17 07:58:57.053: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 04/17/23 07:58:57.053
  Apr 17 07:58:57.053: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4942 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:58:57.053: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:58:57.054: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:58:57.054: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4942/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 17 07:58:57.093: INFO: Exec stderr: ""
  Apr 17 07:58:57.093: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4942 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:58:57.093: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:58:57.093: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:58:57.093: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4942/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 17 07:58:57.133: INFO: Exec stderr: ""
  Apr 17 07:58:57.133: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4942 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:58:57.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:58:57.134: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:58:57.134: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4942/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 17 07:58:57.157: INFO: Exec stderr: ""
  Apr 17 07:58:57.157: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4942 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 07:58:57.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 07:58:57.157: INFO: ExecWithOptions: Clientset creation
  Apr 17 07:58:57.157: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4942/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 17 07:58:57.196: INFO: Exec stderr: ""
  Apr 17 07:58:57.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-4942" for this suite. @ 04/17/23 07:58:57.198
â€¢ [4.495 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:85
  STEP: Creating a kubernetes client @ 04/17/23 07:58:57.2
  Apr 17 07:58:57.200: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 07:58:57.201
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:58:57.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:58:57.206
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 07:58:57.207
  STEP: Saw pod success @ 04/17/23 07:59:01.215
  Apr 17 07:59:01.216: INFO: Trying to get logs from node c3-worker2 pod downwardapi-volume-7b50a2a2-4551-4ce8-9125-b3caaf4ac7b1 container client-container: <nil>
  STEP: delete the pod @ 04/17/23 07:59:01.218
  Apr 17 07:59:01.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3060" for this suite. @ 04/17/23 07:59:01.223
â€¢ [4.024 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]
test/e2e/storage/subpath.go:70
  STEP: Creating a kubernetes client @ 04/17/23 07:59:01.224
  Apr 17 07:59:01.224: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename subpath @ 04/17/23 07:59:01.225
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:59:01.229
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:59:01.23
  STEP: Setting up data @ 04/17/23 07:59:01.231
  STEP: Creating pod pod-subpath-test-configmap-gwf2 @ 04/17/23 07:59:01.233
  STEP: Creating a pod to test atomic-volume-subpath @ 04/17/23 07:59:01.233
  STEP: Saw pod success @ 04/17/23 07:59:25.266
  Apr 17 07:59:25.267: INFO: Trying to get logs from node c3-worker2 pod pod-subpath-test-configmap-gwf2 container test-container-subpath-configmap-gwf2: <nil>
  STEP: delete the pod @ 04/17/23 07:59:25.269
  STEP: Deleting pod pod-subpath-test-configmap-gwf2 @ 04/17/23 07:59:25.272
  Apr 17 07:59:25.273: INFO: Deleting pod "pod-subpath-test-configmap-gwf2" in namespace "subpath-9963"
  Apr 17 07:59:25.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9963" for this suite. @ 04/17/23 07:59:25.275
â€¢ [24.052 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:129
  STEP: Creating a kubernetes client @ 04/17/23 07:59:25.276
  Apr 17 07:59:25.276: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename runtimeclass @ 04/17/23 07:59:25.277
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:59:25.28
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:59:25.281
  Apr 17 07:59:27.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-7287" for this suite. @ 04/17/23 07:59:27.291
â€¢ [2.017 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 04/17/23 07:59:27.294
  Apr 17 07:59:27.294: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pods @ 04/17/23 07:59:27.294
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:59:27.298
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:59:27.299
  Apr 17 07:59:27.300: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: creating the pod @ 04/17/23 07:59:27.301
  STEP: submitting the pod to kubernetes @ 04/17/23 07:59:27.301
  Apr 17 07:59:29.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1979" for this suite. @ 04/17/23 07:59:29.402
â€¢ [2.110 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 04/17/23 07:59:29.403
  Apr 17 07:59:29.403: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pods @ 04/17/23 07:59:29.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:59:29.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:59:29.408
  STEP: creating the pod @ 04/17/23 07:59:29.41
  STEP: submitting the pod to kubernetes @ 04/17/23 07:59:29.41
  STEP: verifying the pod is in kubernetes @ 04/17/23 07:59:31.415
  STEP: updating the pod @ 04/17/23 07:59:31.416
  Apr 17 07:59:31.921: INFO: Successfully updated pod "pod-update-12426b64-d9f9-4761-a920-fb7dd2dc70ea"
  STEP: verifying the updated pod is in kubernetes @ 04/17/23 07:59:31.922
  Apr 17 07:59:31.923: INFO: Pod update OK
  Apr 17 07:59:31.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5555" for this suite. @ 04/17/23 07:59:31.924
â€¢ [2.522 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 04/17/23 07:59:31.926
  Apr 17 07:59:31.926: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename sched-preemption @ 04/17/23 07:59:31.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 07:59:31.93
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 07:59:31.931
  Apr 17 07:59:31.938: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 17 08:00:31.952: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/17/23 08:00:31.953
  Apr 17 08:00:31.953: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/17/23 08:00:31.953
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:00:31.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:00:31.958
  STEP: Finding an available node @ 04/17/23 08:00:31.959
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/17/23 08:00:31.959
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/17/23 08:00:33.965
  Apr 17 08:00:33.967: INFO: found a healthy node: c3-worker
  Apr 17 08:00:39.992: INFO: pods created so far: [1 1 1]
  Apr 17 08:00:39.992: INFO: length of pods created so far: 3
  Apr 17 08:00:41.997: INFO: pods created so far: [2 2 1]
  Apr 17 08:00:49.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 17 08:00:49.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-8787" for this suite. @ 04/17/23 08:00:49.022
  STEP: Destroying namespace "sched-preemption-6817" for this suite. @ 04/17/23 08:00:49.023
â€¢ [77.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 04/17/23 08:00:49.025
  Apr 17 08:00:49.025: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 08:00:49.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:00:49.03
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:00:49.031
  STEP: Creating secret with name secret-test-4b183208-ab24-44a6-bae8-a8d7e37d151b @ 04/17/23 08:00:49.032
  STEP: Creating a pod to test consume secrets @ 04/17/23 08:00:49.033
  STEP: Saw pod success @ 04/17/23 08:00:53.041
  Apr 17 08:00:53.042: INFO: Trying to get logs from node c3-worker2 pod pod-secrets-e5e962c5-c46e-4136-8cd4-fee2a2368d57 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 08:00:53.045
  Apr 17 08:00:53.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3482" for this suite. @ 04/17/23 08:00:53.049
â€¢ [4.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 04/17/23 08:00:53.051
  Apr 17 08:00:53.051: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename watch @ 04/17/23 08:00:53.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:00:53.055
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:00:53.056
  STEP: creating a new configmap @ 04/17/23 08:00:53.057
  STEP: modifying the configmap once @ 04/17/23 08:00:53.059
  STEP: modifying the configmap a second time @ 04/17/23 08:00:53.061
  STEP: deleting the configmap @ 04/17/23 08:00:53.063
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 04/17/23 08:00:53.064
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 04/17/23 08:00:53.065
  Apr 17 08:00:53.065: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1534  e3756116-26fd-4a45-acfc-7e3fd0b9aabc 66678 0 2023-04-17 08:00:53 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-17 08:00:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 08:00:53.065: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1534  e3756116-26fd-4a45-acfc-7e3fd0b9aabc 66679 0 2023-04-17 08:00:53 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-17 08:00:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 17 08:00:53.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1534" for this suite. @ 04/17/23 08:00:53.066
â€¢ [0.016 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:174
  STEP: Creating a kubernetes client @ 04/17/23 08:00:53.068
  Apr 17 08:00:53.068: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 08:00:53.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:00:53.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:00:53.072
  STEP: Creating configMap with name cm-test-opt-del-f018335e-b962-4cab-92e2-59ddb284160a @ 04/17/23 08:00:53.074
  STEP: Creating configMap with name cm-test-opt-upd-7fbada36-c032-4972-94d2-51d0b3981ee1 @ 04/17/23 08:00:53.076
  STEP: Creating the pod @ 04/17/23 08:00:53.077
  STEP: Deleting configmap cm-test-opt-del-f018335e-b962-4cab-92e2-59ddb284160a @ 04/17/23 08:00:55.094
  STEP: Updating configmap cm-test-opt-upd-7fbada36-c032-4972-94d2-51d0b3981ee1 @ 04/17/23 08:00:55.096
  STEP: Creating configMap with name cm-test-opt-create-2a0a52f1-3471-486e-84c6-4c980fa96566 @ 04/17/23 08:00:55.097
  STEP: waiting to observe update in volume @ 04/17/23 08:00:55.099
  Apr 17 08:00:59.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6105" for this suite. @ 04/17/23 08:00:59.113
â€¢ [6.048 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
test/e2e/apimachinery/garbage_collector.go:713
  STEP: Creating a kubernetes client @ 04/17/23 08:00:59.115
  Apr 17 08:00:59.115: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename gc @ 04/17/23 08:00:59.116
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:00:59.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:00:59.121
  STEP: create the rc1 @ 04/17/23 08:00:59.124
  STEP: create the rc2 @ 04/17/23 08:00:59.125
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 04/17/23 08:01:05.13
  STEP: delete the rc simpletest-rc-to-be-deleted @ 04/17/23 08:01:05.254
  STEP: wait for the rc to be deleted @ 04/17/23 08:01:05.282
  Apr 17 08:01:10.291: INFO: 69 pods remaining
  Apr 17 08:01:10.291: INFO: 69 pods has nil DeletionTimestamp
  Apr 17 08:01:10.291: INFO: 
  STEP: Gathering metrics @ 04/17/23 08:01:15.29
  Apr 17 08:01:15.341: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 17 08:01:15.341: INFO: Deleting pod "simpletest-rc-to-be-deleted-29rzf" in namespace "gc-5749"
  Apr 17 08:01:15.345: INFO: Deleting pod "simpletest-rc-to-be-deleted-29w95" in namespace "gc-5749"
  Apr 17 08:01:15.347: INFO: Deleting pod "simpletest-rc-to-be-deleted-2d8pt" in namespace "gc-5749"
  Apr 17 08:01:15.350: INFO: Deleting pod "simpletest-rc-to-be-deleted-2tqwm" in namespace "gc-5749"
  Apr 17 08:01:15.353: INFO: Deleting pod "simpletest-rc-to-be-deleted-2wd7z" in namespace "gc-5749"
  Apr 17 08:01:15.355: INFO: Deleting pod "simpletest-rc-to-be-deleted-2zfrj" in namespace "gc-5749"
  Apr 17 08:01:15.358: INFO: Deleting pod "simpletest-rc-to-be-deleted-4sxbv" in namespace "gc-5749"
  Apr 17 08:01:15.361: INFO: Deleting pod "simpletest-rc-to-be-deleted-5b5dk" in namespace "gc-5749"
  Apr 17 08:01:15.363: INFO: Deleting pod "simpletest-rc-to-be-deleted-5l92h" in namespace "gc-5749"
  Apr 17 08:01:15.366: INFO: Deleting pod "simpletest-rc-to-be-deleted-5llf8" in namespace "gc-5749"
  Apr 17 08:01:15.368: INFO: Deleting pod "simpletest-rc-to-be-deleted-5snj2" in namespace "gc-5749"
  Apr 17 08:01:15.370: INFO: Deleting pod "simpletest-rc-to-be-deleted-5v8v4" in namespace "gc-5749"
  Apr 17 08:01:15.373: INFO: Deleting pod "simpletest-rc-to-be-deleted-655g2" in namespace "gc-5749"
  Apr 17 08:01:15.376: INFO: Deleting pod "simpletest-rc-to-be-deleted-66zxz" in namespace "gc-5749"
  Apr 17 08:01:15.378: INFO: Deleting pod "simpletest-rc-to-be-deleted-67t7m" in namespace "gc-5749"
  Apr 17 08:01:15.381: INFO: Deleting pod "simpletest-rc-to-be-deleted-6qc26" in namespace "gc-5749"
  Apr 17 08:01:15.384: INFO: Deleting pod "simpletest-rc-to-be-deleted-6wlbt" in namespace "gc-5749"
  Apr 17 08:01:15.387: INFO: Deleting pod "simpletest-rc-to-be-deleted-6z5pg" in namespace "gc-5749"
  Apr 17 08:01:15.390: INFO: Deleting pod "simpletest-rc-to-be-deleted-74tqj" in namespace "gc-5749"
  Apr 17 08:01:15.393: INFO: Deleting pod "simpletest-rc-to-be-deleted-7mwmk" in namespace "gc-5749"
  Apr 17 08:01:15.396: INFO: Deleting pod "simpletest-rc-to-be-deleted-8stc8" in namespace "gc-5749"
  Apr 17 08:01:15.398: INFO: Deleting pod "simpletest-rc-to-be-deleted-8wvwv" in namespace "gc-5749"
  Apr 17 08:01:15.401: INFO: Deleting pod "simpletest-rc-to-be-deleted-97q9f" in namespace "gc-5749"
  Apr 17 08:01:15.406: INFO: Deleting pod "simpletest-rc-to-be-deleted-9h5f7" in namespace "gc-5749"
  Apr 17 08:01:15.409: INFO: Deleting pod "simpletest-rc-to-be-deleted-9s9vp" in namespace "gc-5749"
  Apr 17 08:01:15.412: INFO: Deleting pod "simpletest-rc-to-be-deleted-9x497" in namespace "gc-5749"
  Apr 17 08:01:15.415: INFO: Deleting pod "simpletest-rc-to-be-deleted-b22nr" in namespace "gc-5749"
  Apr 17 08:01:15.418: INFO: Deleting pod "simpletest-rc-to-be-deleted-bs67m" in namespace "gc-5749"
  Apr 17 08:01:15.421: INFO: Deleting pod "simpletest-rc-to-be-deleted-bzkfz" in namespace "gc-5749"
  Apr 17 08:01:15.423: INFO: Deleting pod "simpletest-rc-to-be-deleted-c9n7b" in namespace "gc-5749"
  Apr 17 08:01:15.426: INFO: Deleting pod "simpletest-rc-to-be-deleted-cnc2z" in namespace "gc-5749"
  Apr 17 08:01:15.428: INFO: Deleting pod "simpletest-rc-to-be-deleted-cx8r2" in namespace "gc-5749"
  Apr 17 08:01:15.431: INFO: Deleting pod "simpletest-rc-to-be-deleted-d6drc" in namespace "gc-5749"
  Apr 17 08:01:15.433: INFO: Deleting pod "simpletest-rc-to-be-deleted-dxnrf" in namespace "gc-5749"
  Apr 17 08:01:15.436: INFO: Deleting pod "simpletest-rc-to-be-deleted-fbgj2" in namespace "gc-5749"
  Apr 17 08:01:15.438: INFO: Deleting pod "simpletest-rc-to-be-deleted-fmpnc" in namespace "gc-5749"
  Apr 17 08:01:15.440: INFO: Deleting pod "simpletest-rc-to-be-deleted-fq7rn" in namespace "gc-5749"
  Apr 17 08:01:15.443: INFO: Deleting pod "simpletest-rc-to-be-deleted-fqnc4" in namespace "gc-5749"
  Apr 17 08:01:15.446: INFO: Deleting pod "simpletest-rc-to-be-deleted-frdc5" in namespace "gc-5749"
  Apr 17 08:01:15.448: INFO: Deleting pod "simpletest-rc-to-be-deleted-fxq6q" in namespace "gc-5749"
  Apr 17 08:01:15.451: INFO: Deleting pod "simpletest-rc-to-be-deleted-ggtdm" in namespace "gc-5749"
  Apr 17 08:01:15.454: INFO: Deleting pod "simpletest-rc-to-be-deleted-h4rsb" in namespace "gc-5749"
  Apr 17 08:01:15.456: INFO: Deleting pod "simpletest-rc-to-be-deleted-h6tnh" in namespace "gc-5749"
  Apr 17 08:01:15.460: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjtcm" in namespace "gc-5749"
  Apr 17 08:01:15.463: INFO: Deleting pod "simpletest-rc-to-be-deleted-hlstv" in namespace "gc-5749"
  Apr 17 08:01:15.465: INFO: Deleting pod "simpletest-rc-to-be-deleted-hpnrw" in namespace "gc-5749"
  Apr 17 08:01:15.467: INFO: Deleting pod "simpletest-rc-to-be-deleted-hshg2" in namespace "gc-5749"
  Apr 17 08:01:15.470: INFO: Deleting pod "simpletest-rc-to-be-deleted-ht5pd" in namespace "gc-5749"
  Apr 17 08:01:15.472: INFO: Deleting pod "simpletest-rc-to-be-deleted-jcm5r" in namespace "gc-5749"
  Apr 17 08:01:15.488: INFO: Deleting pod "simpletest-rc-to-be-deleted-jgmlh" in namespace "gc-5749"
  Apr 17 08:01:15.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5749" for this suite. @ 04/17/23 08:01:15.587
â€¢ [16.522 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:122
  STEP: Creating a kubernetes client @ 04/17/23 08:01:15.638
  Apr 17 08:01:15.638: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename discovery @ 04/17/23 08:01:15.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:01:15.643
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:01:15.644
  STEP: Setting up server cert @ 04/17/23 08:01:15.645
  Apr 17 08:01:15.835: INFO: Checking APIGroup: apiregistration.k8s.io
  Apr 17 08:01:15.836: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Apr 17 08:01:15.836: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Apr 17 08:01:15.836: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Apr 17 08:01:15.836: INFO: Checking APIGroup: apps
  Apr 17 08:01:15.836: INFO: PreferredVersion.GroupVersion: apps/v1
  Apr 17 08:01:15.836: INFO: Versions found [{apps/v1 v1}]
  Apr 17 08:01:15.836: INFO: apps/v1 matches apps/v1
  Apr 17 08:01:15.836: INFO: Checking APIGroup: events.k8s.io
  Apr 17 08:01:15.837: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Apr 17 08:01:15.837: INFO: Versions found [{events.k8s.io/v1 v1}]
  Apr 17 08:01:15.837: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Apr 17 08:01:15.837: INFO: Checking APIGroup: authentication.k8s.io
  Apr 17 08:01:15.838: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Apr 17 08:01:15.838: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Apr 17 08:01:15.838: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Apr 17 08:01:15.838: INFO: Checking APIGroup: authorization.k8s.io
  Apr 17 08:01:15.838: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Apr 17 08:01:15.838: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Apr 17 08:01:15.838: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Apr 17 08:01:15.838: INFO: Checking APIGroup: autoscaling
  Apr 17 08:01:15.839: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Apr 17 08:01:15.839: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Apr 17 08:01:15.839: INFO: autoscaling/v2 matches autoscaling/v2
  Apr 17 08:01:15.839: INFO: Checking APIGroup: batch
  Apr 17 08:01:15.839: INFO: PreferredVersion.GroupVersion: batch/v1
  Apr 17 08:01:15.839: INFO: Versions found [{batch/v1 v1}]
  Apr 17 08:01:15.839: INFO: batch/v1 matches batch/v1
  Apr 17 08:01:15.839: INFO: Checking APIGroup: certificates.k8s.io
  Apr 17 08:01:15.839: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Apr 17 08:01:15.839: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Apr 17 08:01:15.839: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Apr 17 08:01:15.839: INFO: Checking APIGroup: networking.k8s.io
  Apr 17 08:01:15.840: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Apr 17 08:01:15.840: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Apr 17 08:01:15.840: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Apr 17 08:01:15.840: INFO: Checking APIGroup: policy
  Apr 17 08:01:15.840: INFO: PreferredVersion.GroupVersion: policy/v1
  Apr 17 08:01:15.840: INFO: Versions found [{policy/v1 v1}]
  Apr 17 08:01:15.840: INFO: policy/v1 matches policy/v1
  Apr 17 08:01:15.840: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Apr 17 08:01:15.840: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Apr 17 08:01:15.840: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Apr 17 08:01:15.840: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Apr 17 08:01:15.840: INFO: Checking APIGroup: storage.k8s.io
  Apr 17 08:01:15.841: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Apr 17 08:01:15.841: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Apr 17 08:01:15.841: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Apr 17 08:01:15.841: INFO: Checking APIGroup: admissionregistration.k8s.io
  Apr 17 08:01:15.841: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Apr 17 08:01:15.841: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Apr 17 08:01:15.841: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Apr 17 08:01:15.841: INFO: Checking APIGroup: apiextensions.k8s.io
  Apr 17 08:01:15.841: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Apr 17 08:01:15.841: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Apr 17 08:01:15.841: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Apr 17 08:01:15.841: INFO: Checking APIGroup: scheduling.k8s.io
  Apr 17 08:01:15.842: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Apr 17 08:01:15.842: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Apr 17 08:01:15.842: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Apr 17 08:01:15.842: INFO: Checking APIGroup: coordination.k8s.io
  Apr 17 08:01:15.842: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Apr 17 08:01:15.842: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Apr 17 08:01:15.842: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Apr 17 08:01:15.842: INFO: Checking APIGroup: node.k8s.io
  Apr 17 08:01:15.843: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Apr 17 08:01:15.843: INFO: Versions found [{node.k8s.io/v1 v1}]
  Apr 17 08:01:15.843: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Apr 17 08:01:15.843: INFO: Checking APIGroup: discovery.k8s.io
  Apr 17 08:01:15.843: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Apr 17 08:01:15.843: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Apr 17 08:01:15.843: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Apr 17 08:01:15.843: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Apr 17 08:01:15.843: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
  Apr 17 08:01:15.843: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
  Apr 17 08:01:15.843: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
  Apr 17 08:01:15.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-3940" for this suite. @ 04/17/23 08:01:15.845
â€¢ [0.209 seconds]
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/replica_set.go:111
  STEP: Creating a kubernetes client @ 04/17/23 08:01:15.847
  Apr 17 08:01:15.847: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename replicaset @ 04/17/23 08:01:15.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:01:15.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:01:15.853
  Apr 17 08:01:15.854: INFO: Creating ReplicaSet my-hostname-basic-4ca2a43e-ca7c-4b10-936e-bd659abcccf9
  Apr 17 08:01:15.857: INFO: Pod name my-hostname-basic-4ca2a43e-ca7c-4b10-936e-bd659abcccf9: Found 0 pods out of 1
  Apr 17 08:01:20.859: INFO: Pod name my-hostname-basic-4ca2a43e-ca7c-4b10-936e-bd659abcccf9: Found 1 pods out of 1
  Apr 17 08:01:20.859: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-4ca2a43e-ca7c-4b10-936e-bd659abcccf9" is running
  Apr 17 08:01:20.860: INFO: Pod "my-hostname-basic-4ca2a43e-ca7c-4b10-936e-bd659abcccf9-68bsr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 08:01:15 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 08:01:16 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 08:01:16 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-17 08:01:15 +0000 UTC Reason: Message:}])
  Apr 17 08:01:20.860: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/17/23 08:01:20.86
  Apr 17 08:01:20.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-861" for this suite. @ 04/17/23 08:01:20.864
â€¢ [5.020 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:546
  STEP: Creating a kubernetes client @ 04/17/23 08:01:20.867
  Apr 17 08:01:20.867: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-probe @ 04/17/23 08:01:20.867
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:01:20.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:01:20.871
  STEP: Creating pod test-grpc-826f76c8-fa0a-41cf-bc80-3781f3ce2c3e in namespace container-probe-3549 @ 04/17/23 08:01:20.873
  Apr 17 08:01:22.879: INFO: Started pod test-grpc-826f76c8-fa0a-41cf-bc80-3781f3ce2c3e in namespace container-probe-3549
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/17/23 08:01:22.879
  Apr 17 08:01:22.880: INFO: Initial restart count of pod test-grpc-826f76c8-fa0a-41cf-bc80-3781f3ce2c3e is 0
  Apr 17 08:02:26.955: INFO: Restart count of pod container-probe-3549/test-grpc-826f76c8-fa0a-41cf-bc80-3781f3ce2c3e is now 1 (1m4.075279851s elapsed)
  Apr 17 08:02:26.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 08:02:26.956
  STEP: Destroying namespace "container-probe-3549" for this suite. @ 04/17/23 08:02:26.96
â€¢ [66.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:479
  STEP: Creating a kubernetes client @ 04/17/23 08:02:26.962
  Apr 17 08:02:26.962: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename gc @ 04/17/23 08:02:26.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:02:26.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:02:26.967
  STEP: create the deployment @ 04/17/23 08:02:26.968
  W0417 08:02:26.970437      30 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/17/23 08:02:26.97
  STEP: delete the deployment @ 04/17/23 08:02:27.473
  STEP: wait for all rs to be garbage collected @ 04/17/23 08:02:27.475
  STEP: expected 0 pods, got 2 pods @ 04/17/23 08:02:27.476
  STEP: expected 0 rs, got 1 rs @ 04/17/23 08:02:27.478
  STEP: Gathering metrics @ 04/17/23 08:02:27.982
  Apr 17 08:02:28.025: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 17 08:02:28.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5148" for this suite. @ 04/17/23 08:02:28.027
â€¢ [1.067 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 04/17/23 08:02:28.029
  Apr 17 08:02:28.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename certificates @ 04/17/23 08:02:28.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:02:28.034
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:02:28.035
  STEP: getting /apis @ 04/17/23 08:02:28.262
  STEP: getting /apis/certificates.k8s.io @ 04/17/23 08:02:28.264
  STEP: getting /apis/certificates.k8s.io/v1 @ 04/17/23 08:02:28.264
  STEP: creating @ 04/17/23 08:02:28.265
  STEP: getting @ 04/17/23 08:02:28.27
  STEP: listing @ 04/17/23 08:02:28.271
  STEP: watching @ 04/17/23 08:02:28.272
  Apr 17 08:02:28.272: INFO: starting watch
  STEP: patching @ 04/17/23 08:02:28.272
  STEP: updating @ 04/17/23 08:02:28.274
  Apr 17 08:02:28.276: INFO: waiting for watch events with expected annotations
  Apr 17 08:02:28.276: INFO: saw patched and updated annotations
  STEP: getting /approval @ 04/17/23 08:02:28.276
  STEP: patching /approval @ 04/17/23 08:02:28.277
  STEP: updating /approval @ 04/17/23 08:02:28.279
  STEP: getting /status @ 04/17/23 08:02:28.281
  STEP: patching /status @ 04/17/23 08:02:28.282
  STEP: updating /status @ 04/17/23 08:02:28.285
  STEP: deleting @ 04/17/23 08:02:28.288
  STEP: deleting a collection @ 04/17/23 08:02:28.291
  Apr 17 08:02:28.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-8186" for this suite. @ 04/17/23 08:02:28.296
â€¢ [0.268 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]
test/e2e/apimachinery/namespace.go:303
  STEP: Creating a kubernetes client @ 04/17/23 08:02:28.297
  Apr 17 08:02:28.297: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename namespaces @ 04/17/23 08:02:28.298
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:02:28.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:02:28.302
  STEP: Read namespace status @ 04/17/23 08:02:28.303
  Apr 17 08:02:28.304: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 04/17/23 08:02:28.304
  Apr 17 08:02:28.305: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 04/17/23 08:02:28.305
  Apr 17 08:02:28.307: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Apr 17 08:02:28.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1382" for this suite. @ 04/17/23 08:02:28.309
â€¢ [0.013 seconds]
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]
test/e2e/scheduling/limit_range.go:239
  STEP: Creating a kubernetes client @ 04/17/23 08:02:28.31
  Apr 17 08:02:28.310: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename limitrange @ 04/17/23 08:02:28.31
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:02:28.314
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:02:28.314
  STEP: Creating LimitRange "e2e-limitrange-w4tbq" in namespace "limitrange-3167" @ 04/17/23 08:02:28.315
  STEP: Creating another limitRange in another namespace @ 04/17/23 08:02:28.317
  Apr 17 08:02:28.320: INFO: Namespace "e2e-limitrange-w4tbq-5883" created
  Apr 17 08:02:28.320: INFO: Creating LimitRange "e2e-limitrange-w4tbq" in namespace "e2e-limitrange-w4tbq-5883"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-w4tbq" @ 04/17/23 08:02:28.321
  Apr 17 08:02:28.322: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-w4tbq" in "limitrange-3167" namespace @ 04/17/23 08:02:28.322
  Apr 17 08:02:28.325: INFO: LimitRange "e2e-limitrange-w4tbq" has been patched
  STEP: Delete LimitRange "e2e-limitrange-w4tbq" by Collection with labelSelector: "e2e-limitrange-w4tbq=patched" @ 04/17/23 08:02:28.325
  STEP: Confirm that the limitRange "e2e-limitrange-w4tbq" has been deleted @ 04/17/23 08:02:28.326
  Apr 17 08:02:28.326: INFO: Requesting list of LimitRange to confirm quantity
  Apr 17 08:02:28.327: INFO: Found 0 LimitRange with label "e2e-limitrange-w4tbq=patched"
  Apr 17 08:02:28.327: INFO: LimitRange "e2e-limitrange-w4tbq" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-w4tbq" @ 04/17/23 08:02:28.327
  Apr 17 08:02:28.328: INFO: Found 1 limitRange
  Apr 17 08:02:28.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-3167" for this suite. @ 04/17/23 08:02:28.329
  STEP: Destroying namespace "e2e-limitrange-w4tbq-5883" for this suite. @ 04/17/23 08:02:28.331
â€¢ [0.022 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]
test/e2e/apimachinery/resource_quota.go:161
  STEP: Creating a kubernetes client @ 04/17/23 08:02:28.333
  Apr 17 08:02:28.333: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename resourcequota @ 04/17/23 08:02:28.333
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:02:28.336
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:02:28.337
  STEP: Discovering how many secrets are in namespace by default @ 04/17/23 08:02:28.338
  STEP: Counting existing ResourceQuota @ 04/17/23 08:02:33.34
  STEP: Creating a ResourceQuota @ 04/17/23 08:02:38.342
  STEP: Ensuring resource quota status is calculated @ 04/17/23 08:02:38.343
  STEP: Creating a Secret @ 04/17/23 08:02:40.345
  STEP: Ensuring resource quota status captures secret creation @ 04/17/23 08:02:40.35
  STEP: Deleting a secret @ 04/17/23 08:02:42.352
  STEP: Ensuring resource quota status released usage @ 04/17/23 08:02:42.354
  Apr 17 08:02:44.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3140" for this suite. @ 04/17/23 08:02:44.357
â€¢ [16.026 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]
test/e2e/storage/subpath.go:80
  STEP: Creating a kubernetes client @ 04/17/23 08:02:44.359
  Apr 17 08:02:44.359: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename subpath @ 04/17/23 08:02:44.36
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:02:44.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:02:44.365
  STEP: Setting up data @ 04/17/23 08:02:44.366
  STEP: Creating pod pod-subpath-test-configmap-4qtw @ 04/17/23 08:02:44.369
  STEP: Creating a pod to test atomic-volume-subpath @ 04/17/23 08:02:44.369
  STEP: Saw pod success @ 04/17/23 08:03:08.402
  Apr 17 08:03:08.404: INFO: Trying to get logs from node c3-worker pod pod-subpath-test-configmap-4qtw container test-container-subpath-configmap-4qtw: <nil>
  STEP: delete the pod @ 04/17/23 08:03:08.414
  STEP: Deleting pod pod-subpath-test-configmap-4qtw @ 04/17/23 08:03:08.418
  Apr 17 08:03:08.418: INFO: Deleting pod "pod-subpath-test-configmap-4qtw" in namespace "subpath-2092"
  Apr 17 08:03:08.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-2092" for this suite. @ 04/17/23 08:03:08.42
â€¢ [24.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]
test/e2e/storage/subpath.go:60
  STEP: Creating a kubernetes client @ 04/17/23 08:03:08.422
  Apr 17 08:03:08.422: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename subpath @ 04/17/23 08:03:08.422
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:03:08.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:03:08.427
  STEP: Setting up data @ 04/17/23 08:03:08.428
  STEP: Creating pod pod-subpath-test-secret-9wx7 @ 04/17/23 08:03:08.43
  STEP: Creating a pod to test atomic-volume-subpath @ 04/17/23 08:03:08.43
  STEP: Saw pod success @ 04/17/23 08:03:32.462
  Apr 17 08:03:32.463: INFO: Trying to get logs from node c3-worker pod pod-subpath-test-secret-9wx7 container test-container-subpath-secret-9wx7: <nil>
  STEP: delete the pod @ 04/17/23 08:03:32.467
  STEP: Deleting pod pod-subpath-test-secret-9wx7 @ 04/17/23 08:03:32.47
  Apr 17 08:03:32.470: INFO: Deleting pod "pod-subpath-test-secret-9wx7" in namespace "subpath-7505"
  Apr 17 08:03:32.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7505" for this suite. @ 04/17/23 08:03:32.472
â€¢ [24.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]
test/e2e/kubectl/kubectl.go:1315
  STEP: Creating a kubernetes client @ 04/17/23 08:03:32.473
  Apr 17 08:03:32.473: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 08:03:32.474
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:03:32.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:03:32.479
  STEP: validating cluster-info @ 04/17/23 08:03:32.48
  Apr 17 08:03:32.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-4694 cluster-info'
  Apr 17 08:03:32.518: INFO: stderr: ""
  Apr 17 08:03:32.518: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Apr 17 08:03:32.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4694" for this suite. @ 04/17/23 08:03:32.519
â€¢ [0.047 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]
test/e2e/apimachinery/webhook.go:331
  STEP: Creating a kubernetes client @ 04/17/23 08:03:32.521
  Apr 17 08:03:32.521: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 08:03:32.521
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:03:32.525
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:03:32.526
  STEP: Setting up server cert @ 04/17/23 08:03:32.531
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 08:03:32.931
  STEP: Deploying the webhook pod @ 04/17/23 08:03:32.933
  STEP: Wait for the deployment to be ready @ 04/17/23 08:03:32.937
  Apr 17 08:03:32.939: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 08:03:34.944
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 08:03:34.947
  Apr 17 08:03:35.947: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 17 08:03:35.948: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7992-crds.webhook.example.com via the AdmissionRegistration API @ 04/17/23 08:03:36.453
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/17/23 08:03:36.459
  Apr 17 08:03:38.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6579" for this suite. @ 04/17/23 08:03:38.997
  STEP: Destroying namespace "webhook-markers-1072" for this suite. @ 04/17/23 08:03:38.999
â€¢ [6.480 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:222
  STEP: Creating a kubernetes client @ 04/17/23 08:03:39.001
  Apr 17 08:03:39.001: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 08:03:39.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:03:39.005
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:03:39.006
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 08:03:39.007
  STEP: Saw pod success @ 04/17/23 08:03:43.015
  Apr 17 08:03:43.016: INFO: Trying to get logs from node c3-worker2 pod downwardapi-volume-2e476981-2299-4169-9af9-049d054f064a container client-container: <nil>
  STEP: delete the pod @ 04/17/23 08:03:43.024
  Apr 17 08:03:43.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8073" for this suite. @ 04/17/23 08:03:43.029
â€¢ [4.030 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:145
  STEP: Creating a kubernetes client @ 04/17/23 08:03:43.032
  Apr 17 08:03:43.032: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/17/23 08:03:43.032
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:03:43.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:03:43.037
  Apr 17 08:03:43.038: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 08:03:43.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7533" for this suite. @ 04/17/23 08:03:43.554
â€¢ [0.524 seconds]
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]
test/e2e/common/node/configmap.go:169
  STEP: Creating a kubernetes client @ 04/17/23 08:03:43.556
  Apr 17 08:03:43.556: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 08:03:43.556
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:03:43.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:03:43.56
  STEP: creating a ConfigMap @ 04/17/23 08:03:43.561
  STEP: fetching the ConfigMap @ 04/17/23 08:03:43.563
  STEP: patching the ConfigMap @ 04/17/23 08:03:43.564
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 04/17/23 08:03:43.565
  STEP: deleting the ConfigMap by collection with a label selector @ 04/17/23 08:03:43.566
  STEP: listing all ConfigMaps in test namespace @ 04/17/23 08:03:43.568
  Apr 17 08:03:43.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7632" for this suite. @ 04/17/23 08:03:43.57
â€¢ [0.015 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 04/17/23 08:03:43.572
  Apr 17 08:03:43.572: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename deployment @ 04/17/23 08:03:43.572
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:03:43.575
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:03:43.576
  Apr 17 08:03:43.577: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Apr 17 08:03:43.580: INFO: Pod name sample-pod: Found 0 pods out of 1
  Apr 17 08:03:48.582: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/17/23 08:03:48.582
  Apr 17 08:03:48.582: INFO: Creating deployment "test-rolling-update-deployment"
  Apr 17 08:03:48.584: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Apr 17 08:03:48.586: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  Apr 17 08:03:50.589: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Apr 17 08:03:50.590: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Apr 17 08:03:50.593: INFO: Deployment "test-rolling-update-deployment":
  &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-9066  06249a29-8788-4beb-b08f-f520963f4862 69344 1 2023-04-17 08:03:48 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-17 08:03:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 08:03:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00535e188 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-17 08:03:48 +0000 UTC,LastTransitionTime:2023-04-17 08:03:48 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-656d657cd8" has successfully progressed.,LastUpdateTime:2023-04-17 08:03:49 +0000 UTC,LastTransitionTime:2023-04-17 08:03:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 17 08:03:50.593: INFO: New ReplicaSet "test-rolling-update-deployment-656d657cd8" of Deployment "test-rolling-update-deployment":
  &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-656d657cd8  deployment-9066  e18c7f8e-f974-45b3-8a41-cc9c8eec3300 69334 1 2023-04-17 08:03:48 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:656d657cd8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 06249a29-8788-4beb-b08f-f520963f4862 0xc00535e677 0xc00535e678}] [] [{kube-controller-manager Update apps/v1 2023-04-17 08:03:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06249a29-8788-4beb-b08f-f520963f4862\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 08:03:49 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 656d657cd8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:656d657cd8] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00535e728 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 17 08:03:50.593: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Apr 17 08:03:50.594: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-9066  506bd625-e3f3-4d3c-8d1d-b6fcc57c5ea0 69343 2 2023-04-17 08:03:43 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 06249a29-8788-4beb-b08f-f520963f4862 0xc00535e537 0xc00535e538}] [] [{e2e.test Update apps/v1 2023-04-17 08:03:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 08:03:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"06249a29-8788-4beb-b08f-f520963f4862\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-17 08:03:49 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00535e608 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 17 08:03:50.595: INFO: Pod "test-rolling-update-deployment-656d657cd8-8szhn" is available:
  &Pod{ObjectMeta:{test-rolling-update-deployment-656d657cd8-8szhn test-rolling-update-deployment-656d657cd8- deployment-9066  54aa71af-61c1-4791-ac55-2805168657e6 69333 0 2023-04-17 08:03:48 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:656d657cd8] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-656d657cd8 e18c7f8e-f974-45b3-8a41-cc9c8eec3300 0xc001c9d097 0xc001c9d098}] [] [{kube-controller-manager Update v1 2023-04-17 08:03:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e18c7f8e-f974-45b3-8a41-cc9c8eec3300\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 08:03:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.2.50\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5dkh6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5dkh6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 08:03:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 08:03:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 08:03:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 08:03:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:10.244.2.50,StartTime:2023-04-17 08:03:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-17 08:03:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://0dd45253c67ef7a2f9b3228750864aaba99b3e6d5944133ab6c05c2f39b77769,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.50,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 08:03:50.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9066" for this suite. @ 04/17/23 08:03:50.596
â€¢ [7.026 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:45
  STEP: Creating a kubernetes client @ 04/17/23 08:03:50.597
  Apr 17 08:03:50.597: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 08:03:50.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:03:50.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:03:50.603
  STEP: Creating a pod to test downward api env vars @ 04/17/23 08:03:50.604
  STEP: Saw pod success @ 04/17/23 08:03:54.613
  Apr 17 08:03:54.614: INFO: Trying to get logs from node c3-worker2 pod downward-api-ed47b552-71a3-4693-8f33-d4f4bdf51b50 container dapi-container: <nil>
  STEP: delete the pod @ 04/17/23 08:03:54.617
  Apr 17 08:03:54.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5686" for this suite. @ 04/17/23 08:03:54.622
â€¢ [4.026 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 04/17/23 08:03:54.624
  Apr 17 08:03:54.624: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/17/23 08:03:54.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:03:54.628
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:03:54.629
  Apr 17 08:03:54.630: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/17/23 08:03:55.838
  Apr 17 08:03:55.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-8436 --namespace=crd-publish-openapi-8436 create -f -'
  Apr 17 08:03:56.194: INFO: stderr: ""
  Apr 17 08:03:56.194: INFO: stdout: "e2e-test-crd-publish-openapi-5545-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 17 08:03:56.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-8436 --namespace=crd-publish-openapi-8436 delete e2e-test-crd-publish-openapi-5545-crds test-cr'
  Apr 17 08:03:56.239: INFO: stderr: ""
  Apr 17 08:03:56.239: INFO: stdout: "e2e-test-crd-publish-openapi-5545-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Apr 17 08:03:56.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-8436 --namespace=crd-publish-openapi-8436 apply -f -'
  Apr 17 08:03:56.365: INFO: stderr: ""
  Apr 17 08:03:56.365: INFO: stdout: "e2e-test-crd-publish-openapi-5545-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 17 08:03:56.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-8436 --namespace=crd-publish-openapi-8436 delete e2e-test-crd-publish-openapi-5545-crds test-cr'
  Apr 17 08:03:56.408: INFO: stderr: ""
  Apr 17 08:03:56.408: INFO: stdout: "e2e-test-crd-publish-openapi-5545-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 04/17/23 08:03:56.408
  Apr 17 08:03:56.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=crd-publish-openapi-8436 explain e2e-test-crd-publish-openapi-5545-crds'
  Apr 17 08:03:56.527: INFO: stderr: ""
  Apr 17 08:03:56.527: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-5545-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  Apr 17 08:03:57.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8436" for this suite. @ 04/17/23 08:03:57.723
â€¢ [3.101 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance]
test/e2e/apps/rc.go:103
  STEP: Creating a kubernetes client @ 04/17/23 08:03:57.725
  Apr 17 08:03:57.725: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename replication-controller @ 04/17/23 08:03:57.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:03:57.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:03:57.73
  STEP: Given a ReplicationController is created @ 04/17/23 08:03:57.731
  STEP: When the matched label of one of its pods change @ 04/17/23 08:03:57.733
  Apr 17 08:03:57.734: INFO: Pod name pod-release: Found 0 pods out of 1
  Apr 17 08:04:02.736: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/17/23 08:04:02.739
  Apr 17 08:04:03.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-4131" for this suite. @ 04/17/23 08:04:03.743
â€¢ [6.020 seconds]
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:69
  STEP: Creating a kubernetes client @ 04/17/23 08:04:03.744
  Apr 17 08:04:03.744: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 08:04:03.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:03.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:03.75
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 08:04:03.752
  STEP: Saw pod success @ 04/17/23 08:04:07.76
  Apr 17 08:04:07.761: INFO: Trying to get logs from node c3-worker2 pod downwardapi-volume-529aebd4-cf7d-4f9b-bdff-e7d5e0e76185 container client-container: <nil>
  STEP: delete the pod @ 04/17/23 08:04:07.763
  Apr 17 08:04:07.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7638" for this suite. @ 04/17/23 08:04:07.768
â€¢ [4.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]
test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 04/17/23 08:04:07.771
  Apr 17 08:04:07.771: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename sched-pred @ 04/17/23 08:04:07.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:07.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:07.777
  Apr 17 08:04:07.778: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 17 08:04:07.780: INFO: Waiting for terminating namespaces to be deleted...
  Apr 17 08:04:07.781: INFO: 
  Logging pods the apiserver thinks is on node c3-worker before test
  Apr 17 08:04:07.783: INFO: kindnet-plq69 from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 08:04:07.783: INFO: 	Container kindnet-cni ready: true, restart count 0
  Apr 17 08:04:07.783: INFO: kube-proxy-6r2kb from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 08:04:07.783: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 17 08:04:07.783: INFO: pod-release-2zngk from replication-controller-4131 started at 2023-04-17 08:03:57 +0000 UTC (1 container statuses recorded)
  Apr 17 08:04:07.783: INFO: 	Container pod-release ready: true, restart count 0
  Apr 17 08:04:07.783: INFO: sonobuoy from sonobuoy started at 2023-04-17 06:33:09 +0000 UTC (1 container statuses recorded)
  Apr 17 08:04:07.783: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 17 08:04:07.783: INFO: sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-7tzl9 from sonobuoy started at 2023-04-17 06:33:10 +0000 UTC (2 container statuses recorded)
  Apr 17 08:04:07.783: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 08:04:07.783: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 17 08:04:07.783: INFO: 
  Logging pods the apiserver thinks is on node c3-worker2 before test
  Apr 17 08:04:07.785: INFO: kindnet-br9l4 from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 08:04:07.785: INFO: 	Container kindnet-cni ready: true, restart count 0
  Apr 17 08:04:07.785: INFO: kube-proxy-stm68 from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 08:04:07.785: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 17 08:04:07.785: INFO: pod-release-pjf5x from replication-controller-4131 started at 2023-04-17 08:04:02 +0000 UTC (1 container statuses recorded)
  Apr 17 08:04:07.785: INFO: 	Container pod-release ready: true, restart count 0
  Apr 17 08:04:07.785: INFO: sonobuoy-e2e-job-e91f319b048a45eb from sonobuoy started at 2023-04-17 06:33:10 +0000 UTC (2 container statuses recorded)
  Apr 17 08:04:07.785: INFO: 	Container e2e ready: true, restart count 0
  Apr 17 08:04:07.785: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 08:04:07.785: INFO: sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-svr2p from sonobuoy started at 2023-04-17 06:33:10 +0000 UTC (2 container statuses recorded)
  Apr 17 08:04:07.785: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 08:04:07.785: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node c3-worker @ 04/17/23 08:04:07.794
  STEP: verifying the node has the label node c3-worker2 @ 04/17/23 08:04:07.798
  Apr 17 08:04:07.802: INFO: Pod kindnet-br9l4 requesting resource cpu=100m on Node c3-worker2
  Apr 17 08:04:07.802: INFO: Pod kindnet-plq69 requesting resource cpu=100m on Node c3-worker
  Apr 17 08:04:07.802: INFO: Pod kube-proxy-6r2kb requesting resource cpu=0m on Node c3-worker
  Apr 17 08:04:07.802: INFO: Pod kube-proxy-stm68 requesting resource cpu=0m on Node c3-worker2
  Apr 17 08:04:07.802: INFO: Pod pod-release-2zngk requesting resource cpu=0m on Node c3-worker
  Apr 17 08:04:07.802: INFO: Pod pod-release-pjf5x requesting resource cpu=0m on Node c3-worker2
  Apr 17 08:04:07.802: INFO: Pod sonobuoy requesting resource cpu=0m on Node c3-worker
  Apr 17 08:04:07.802: INFO: Pod sonobuoy-e2e-job-e91f319b048a45eb requesting resource cpu=0m on Node c3-worker2
  Apr 17 08:04:07.802: INFO: Pod sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-7tzl9 requesting resource cpu=0m on Node c3-worker
  Apr 17 08:04:07.802: INFO: Pod sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-svr2p requesting resource cpu=0m on Node c3-worker2
  STEP: Starting Pods to consume most of the cluster CPU. @ 04/17/23 08:04:07.802
  Apr 17 08:04:07.802: INFO: Creating a pod which consumes cpu=44730m on Node c3-worker2
  Apr 17 08:04:07.804: INFO: Creating a pod which consumes cpu=44730m on Node c3-worker
  STEP: Creating another pod that requires unavailable amount of CPU. @ 04/17/23 08:04:09.812
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-b8a3fc4f-6d49-4877-af20-993d17a2984a.1756aa3336eaf603], Reason = [Scheduled], Message = [Successfully assigned sched-pred-402/filler-pod-b8a3fc4f-6d49-4877-af20-993d17a2984a to c3-worker] @ 04/17/23 08:04:09.814
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-b8a3fc4f-6d49-4877-af20-993d17a2984a.1756aa3354a91a15], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/17/23 08:04:09.814
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-b8a3fc4f-6d49-4877-af20-993d17a2984a.1756aa3354f40418], Reason = [Created], Message = [Created container filler-pod-b8a3fc4f-6d49-4877-af20-993d17a2984a] @ 04/17/23 08:04:09.814
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-b8a3fc4f-6d49-4877-af20-993d17a2984a.1756aa335a5d95fe], Reason = [Started], Message = [Started container filler-pod-b8a3fc4f-6d49-4877-af20-993d17a2984a] @ 04/17/23 08:04:09.814
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-fd3bf9da-5eca-44c9-a73c-66a1e2c98764.1756aa3336c25d78], Reason = [Scheduled], Message = [Successfully assigned sched-pred-402/filler-pod-fd3bf9da-5eca-44c9-a73c-66a1e2c98764 to c3-worker2] @ 04/17/23 08:04:09.814
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-fd3bf9da-5eca-44c9-a73c-66a1e2c98764.1756aa33538ac0cc], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/17/23 08:04:09.814
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-fd3bf9da-5eca-44c9-a73c-66a1e2c98764.1756aa3353e5ae1b], Reason = [Created], Message = [Created container filler-pod-fd3bf9da-5eca-44c9-a73c-66a1e2c98764] @ 04/17/23 08:04:09.814
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-fd3bf9da-5eca-44c9-a73c-66a1e2c98764.1756aa3359ab4b5f], Reason = [Started], Message = [Started container filler-pod-fd3bf9da-5eca-44c9-a73c-66a1e2c98764] @ 04/17/23 08:04:09.814
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.1756aa33ae7a1464], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 2 Insufficient cpu. preemption: 0/3 nodes are available: 1 Preemption is not helpful for scheduling, 2 No preemption victims found for incoming pod..] @ 04/17/23 08:04:09.818
  STEP: removing the label node off the node c3-worker @ 04/17/23 08:04:10.818
  STEP: verifying the node doesn't have the label node @ 04/17/23 08:04:10.823
  STEP: removing the label node off the node c3-worker2 @ 04/17/23 08:04:10.824
  STEP: verifying the node doesn't have the label node @ 04/17/23 08:04:10.828
  Apr 17 08:04:10.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-402" for this suite. @ 04/17/23 08:04:10.83
â€¢ [3.062 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 04/17/23 08:04:10.832
  Apr 17 08:04:10.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pods @ 04/17/23 08:04:10.833
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:10.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:10.838
  Apr 17 08:04:10.839: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: creating the pod @ 04/17/23 08:04:10.839
  STEP: submitting the pod to kubernetes @ 04/17/23 08:04:10.839
  Apr 17 08:04:12.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7064" for this suite. @ 04/17/23 08:04:12.854
â€¢ [2.023 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2165
  STEP: Creating a kubernetes client @ 04/17/23 08:04:12.856
  Apr 17 08:04:12.856: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 08:04:12.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:12.859
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:12.86
  STEP: creating service in namespace services-8439 @ 04/17/23 08:04:12.861
  STEP: creating service affinity-clusterip in namespace services-8439 @ 04/17/23 08:04:12.861
  STEP: creating replication controller affinity-clusterip in namespace services-8439 @ 04/17/23 08:04:12.864
  I0417 08:04:12.865971      30 runners.go:194] Created replication controller with name: affinity-clusterip, namespace: services-8439, replica count: 3
  I0417 08:04:15.917219      30 runners.go:194] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 17 08:04:15.918: INFO: Creating new exec pod
  Apr 17 08:04:18.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-8439 exec execpod-affinity4zsd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Apr 17 08:04:19.029: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Apr 17 08:04:19.029: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 08:04:19.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-8439 exec execpod-affinity4zsd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.136.112 80'
  Apr 17 08:04:19.140: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.136.112 80\nConnection to 10.96.136.112 80 port [tcp/http] succeeded!\n"
  Apr 17 08:04:19.140: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 08:04:19.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-8439 exec execpod-affinity4zsd5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.136.112:80/ ; done'
  Apr 17 08:04:19.286: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.136.112:80/\n"
  Apr 17 08:04:19.286: INFO: stdout: "\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl\naffinity-clusterip-84gvl"
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Received response from host: affinity-clusterip-84gvl
  Apr 17 08:04:19.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 17 08:04:19.287: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-8439, will wait for the garbage collector to delete the pods @ 04/17/23 08:04:19.291
  Apr 17 08:04:19.344: INFO: Deleting ReplicationController affinity-clusterip took: 1.634096ms
  Apr 17 08:04:19.444: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.344905ms
  STEP: Destroying namespace "services-8439" for this suite. @ 04/17/23 08:04:23.149
â€¢ [10.295 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:645
  STEP: Creating a kubernetes client @ 04/17/23 08:04:23.151
  Apr 17 08:04:23.151: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 08:04:23.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:23.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:23.157
  STEP: Setting up server cert @ 04/17/23 08:04:23.163
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 08:04:23.454
  STEP: Deploying the webhook pod @ 04/17/23 08:04:23.457
  STEP: Wait for the deployment to be ready @ 04/17/23 08:04:23.46
  Apr 17 08:04:23.462: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/17/23 08:04:25.466
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 08:04:25.469
  Apr 17 08:04:26.469: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/17/23 08:04:26.487
  STEP: Creating a configMap that should be mutated @ 04/17/23 08:04:26.493
  STEP: Deleting the collection of validation webhooks @ 04/17/23 08:04:26.504
  STEP: Creating a configMap that should not be mutated @ 04/17/23 08:04:26.514
  Apr 17 08:04:26.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1496" for this suite. @ 04/17/23 08:04:26.528
  STEP: Destroying namespace "webhook-markers-3109" for this suite. @ 04/17/23 08:04:26.529
â€¢ [3.379 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]
test/e2e/kubectl/kubectl.go:996
  STEP: Creating a kubernetes client @ 04/17/23 08:04:26.531
  Apr 17 08:04:26.531: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 08:04:26.531
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:26.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:26.536
  STEP: create deployment with httpd image @ 04/17/23 08:04:26.537
  Apr 17 08:04:26.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-254 create -f -'
  Apr 17 08:04:26.914: INFO: stderr: ""
  Apr 17 08:04:26.914: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 04/17/23 08:04:26.914
  Apr 17 08:04:26.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-254 diff -f -'
  Apr 17 08:04:27.022: INFO: rc: 1
  Apr 17 08:04:27.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-254 delete -f -'
  Apr 17 08:04:27.063: INFO: stderr: ""
  Apr 17 08:04:27.063: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Apr 17 08:04:27.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-254" for this suite. @ 04/17/23 08:04:27.065
â€¢ [0.536 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]
test/e2e/apps/daemon_set.go:294
  STEP: Creating a kubernetes client @ 04/17/23 08:04:27.067
  Apr 17 08:04:27.067: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename daemonsets @ 04/17/23 08:04:27.067
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:27.071
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:27.072
  STEP: Creating a simple DaemonSet "daemon-set" @ 04/17/23 08:04:27.078
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/17/23 08:04:27.08
  Apr 17 08:04:27.081: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 08:04:27.082: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 08:04:27.082: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 08:04:28.084: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 08:04:28.085: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 17 08:04:28.085: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 08:04:29.083: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 08:04:29.084: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 17 08:04:29.084: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 04/17/23 08:04:29.085
  Apr 17 08:04:29.091: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 08:04:29.092: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 17 08:04:29.092: INFO: Node c3-worker2 is running 0 daemon pod, expected 1
  Apr 17 08:04:30.094: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 08:04:30.095: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 17 08:04:30.095: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 04/17/23 08:04:30.095
  STEP: Deleting DaemonSet "daemon-set" @ 04/17/23 08:04:30.097
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9212, will wait for the garbage collector to delete the pods @ 04/17/23 08:04:30.097
  Apr 17 08:04:30.151: INFO: Deleting DaemonSet.extensions daemon-set took: 2.154387ms
  Apr 17 08:04:30.251: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.510104ms
  Apr 17 08:04:32.053: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 08:04:32.053: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 17 08:04:32.054: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"69899"},"items":null}

  Apr 17 08:04:32.055: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"69899"},"items":null}

  Apr 17 08:04:32.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9212" for this suite. @ 04/17/23 08:04:32.059
â€¢ [4.993 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod  [Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 04/17/23 08:04:32.061
  Apr 17 08:04:32.061: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename prestop @ 04/17/23 08:04:32.062
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:32.065
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:32.066
  STEP: Creating server pod server in namespace prestop-9685 @ 04/17/23 08:04:32.067
  STEP: Waiting for pods to come up. @ 04/17/23 08:04:32.069
  STEP: Creating tester pod tester in namespace prestop-9685 @ 04/17/23 08:04:34.073
  STEP: Deleting pre-stop pod @ 04/17/23 08:04:36.078
  Apr 17 08:04:41.082: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  Apr 17 08:04:41.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Deleting the server pod @ 04/17/23 08:04:41.084
  STEP: Destroying namespace "prestop-9685" for this suite. @ 04/17/23 08:04:41.088
â€¢ [9.028 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:197
  STEP: Creating a kubernetes client @ 04/17/23 08:04:41.09
  Apr 17 08:04:41.090: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 08:04:41.09
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:41.094
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:41.095
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/17/23 08:04:41.096
  STEP: Saw pod success @ 04/17/23 08:04:45.105
  Apr 17 08:04:45.106: INFO: Trying to get logs from node c3-worker2 pod pod-4ac218ca-4e37-4bb7-9fd6-feca1297921d container test-container: <nil>
  STEP: delete the pod @ 04/17/23 08:04:45.108
  Apr 17 08:04:45.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8110" for this suite. @ 04/17/23 08:04:45.113
â€¢ [4.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 04/17/23 08:04:45.115
  Apr 17 08:04:45.115: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pods @ 04/17/23 08:04:45.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:45.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:45.12
  STEP: creating the pod @ 04/17/23 08:04:45.121
  STEP: setting up watch @ 04/17/23 08:04:45.121
  STEP: submitting the pod to kubernetes @ 04/17/23 08:04:45.223
  STEP: verifying the pod is in kubernetes @ 04/17/23 08:04:45.225
  STEP: verifying pod creation was observed @ 04/17/23 08:04:45.226
  STEP: deleting the pod gracefully @ 04/17/23 08:04:47.23
  STEP: verifying pod deletion was observed @ 04/17/23 08:04:47.232
  Apr 17 08:04:48.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8674" for this suite. @ 04/17/23 08:04:48.136
â€¢ [3.023 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:47
  STEP: Creating a kubernetes client @ 04/17/23 08:04:48.138
  Apr 17 08:04:48.138: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 08:04:48.138
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:48.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:48.143
  STEP: Creating configMap with name projected-configmap-test-volume-717b115b-c678-4240-85a0-086c45d6ee45 @ 04/17/23 08:04:48.144
  STEP: Creating a pod to test consume configMaps @ 04/17/23 08:04:48.145
  STEP: Saw pod success @ 04/17/23 08:04:52.153
  Apr 17 08:04:52.154: INFO: Trying to get logs from node c3-worker pod pod-projected-configmaps-a83cc4ba-7385-4810-b593-4615c677cded container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 08:04:52.156
  Apr 17 08:04:52.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3222" for this suite. @ 04/17/23 08:04:52.16
â€¢ [4.024 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]
test/e2e/kubectl/kubectl.go:1673
  STEP: Creating a kubernetes client @ 04/17/23 08:04:52.162
  Apr 17 08:04:52.162: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 08:04:52.162
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:52.166
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:52.167
  Apr 17 08:04:52.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-611 version'
  Apr 17 08:04:52.205: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
  Apr 17 08:04:52.205: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"27\", GitVersion:\"v1.27.0\", GitCommit:\"1b4df30b3cdfeaba6024e81e559a6cd09a089d65\", GitTreeState:\"clean\", BuildDate:\"2023-04-11T17:10:18Z\", GoVersion:\"go1.20.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v5.0.1\nServer Version: version.Info{Major:\"1\", Minor:\"27\", GitVersion:\"v1.27.0\", GitCommit:\"1b4df30b3cdfeaba6024e81e559a6cd09a089d65\", GitTreeState:\"clean\", BuildDate:\"2023-04-11T20:50:51Z\", GoVersion:\"go1.20.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
  Apr 17 08:04:52.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-611" for this suite. @ 04/17/23 08:04:52.206
â€¢ [0.045 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:398
  STEP: Creating a kubernetes client @ 04/17/23 08:04:52.208
  Apr 17 08:04:52.208: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename namespaces @ 04/17/23 08:04:52.208
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:52.211
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:52.212
  STEP: Creating namespace "e2e-ns-g2g7z" @ 04/17/23 08:04:52.213
  Apr 17 08:04:52.216: INFO: Namespace "e2e-ns-g2g7z-9825" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-g2g7z-9825" @ 04/17/23 08:04:52.216
  Apr 17 08:04:52.218: INFO: Namespace "e2e-ns-g2g7z-9825" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-g2g7z-9825" @ 04/17/23 08:04:52.218
  Apr 17 08:04:52.220: INFO: Namespace "e2e-ns-g2g7z-9825" has []v1.FinalizerName{"kubernetes"}
  Apr 17 08:04:52.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-5615" for this suite. @ 04/17/23 08:04:52.221
  STEP: Destroying namespace "e2e-ns-g2g7z-9825" for this suite. @ 04/17/23 08:04:52.222
â€¢ [0.016 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance]
test/e2e/network/service.go:3548
  STEP: Creating a kubernetes client @ 04/17/23 08:04:52.224
  Apr 17 08:04:52.224: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 08:04:52.224
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:52.227
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:52.228
  STEP: creating a collection of services @ 04/17/23 08:04:52.229
  Apr 17 08:04:52.229: INFO: Creating e2e-svc-a-g5x4d
  Apr 17 08:04:52.231: INFO: Creating e2e-svc-b-lhzkx
  Apr 17 08:04:52.241: INFO: Creating e2e-svc-c-j9qnb
  STEP: deleting service collection @ 04/17/23 08:04:52.246
  Apr 17 08:04:52.253: INFO: Collection of services has been deleted
  Apr 17 08:04:52.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8262" for this suite. @ 04/17/23 08:04:52.254
â€¢ [0.032 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]
test/e2e/kubectl/kubectl.go:1341
  STEP: Creating a kubernetes client @ 04/17/23 08:04:52.255
  Apr 17 08:04:52.255: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename kubectl @ 04/17/23 08:04:52.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:52.259
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:52.26
  Apr 17 08:04:52.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1437 create -f -'
  Apr 17 08:04:52.416: INFO: stderr: ""
  Apr 17 08:04:52.416: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Apr 17 08:04:52.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1437 create -f -'
  Apr 17 08:04:52.556: INFO: stderr: ""
  Apr 17 08:04:52.556: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/17/23 08:04:52.556
  Apr 17 08:04:53.559: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 17 08:04:53.559: INFO: Found 0 / 1
  Apr 17 08:04:54.559: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 17 08:04:54.559: INFO: Found 1 / 1
  Apr 17 08:04:54.559: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 17 08:04:54.560: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 17 08:04:54.560: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 17 08:04:54.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1437 describe pod agnhost-primary-8t9lr'
  Apr 17 08:04:54.605: INFO: stderr: ""
  Apr 17 08:04:54.605: INFO: stdout: "Name:             agnhost-primary-8t9lr\nNamespace:        kubectl-1437\nPriority:         0\nService Account:  default\nNode:             c3-worker2/172.18.0.4\nStart Time:       Mon, 17 Apr 2023 08:04:52 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.244.2.60\nIPs:\n  IP:           10.244.2.60\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://7eff5d600ff281a7fe8d4572dfc2f125ee42cc3c6a71016e82ce51dbfd7e0ff0\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.43\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 17 Apr 2023 08:04:53 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-8xlcp (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-8xlcp:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-1437/agnhost-primary-8t9lr to c3-worker2\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.43\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  Apr 17 08:04:54.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1437 describe rc agnhost-primary'
  Apr 17 08:04:54.651: INFO: stderr: ""
  Apr 17 08:04:54.651: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-1437\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.43\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-8t9lr\n"
  Apr 17 08:04:54.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1437 describe service agnhost-primary'
  Apr 17 08:04:54.694: INFO: stderr: ""
  Apr 17 08:04:54.694: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-1437\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.96.203.215\nIPs:               10.96.203.215\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.244.2.60:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Apr 17 08:04:54.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1437 describe node c3-control-plane'
  Apr 17 08:04:54.745: INFO: stderr: ""
  Apr 17 08:04:54.745: INFO: stdout: "Name:               c3-control-plane\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=c3-control-plane\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 16 Apr 2023 23:18:07 +0000\nTaints:             node-role.kubernetes.io/control-plane:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  c3-control-plane\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 17 Apr 2023 08:04:53 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 17 Apr 2023 08:00:43 +0000   Sun, 16 Apr 2023 23:18:05 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 17 Apr 2023 08:00:43 +0000   Sun, 16 Apr 2023 23:18:05 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 17 Apr 2023 08:00:43 +0000   Sun, 16 Apr 2023 23:18:05 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 17 Apr 2023 08:00:43 +0000   Sun, 16 Apr 2023 23:18:29 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.18.0.2\n  Hostname:    c3-control-plane\nCapacity:\n  cpu:                64\n  ephemeral-storage:  228077240Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             263527340Ki\n  pods:               110\nAllocatable:\n  cpu:                64\n  ephemeral-storage:  228077240Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             263527340Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 767839283df247938c9426a6b5ad4d25\n  System UUID:                51c9e800-a9ee-4c59-a6d9-4c838bece296\n  Boot ID:                    6c31530c-b1ee-4d7b-9f9a-cd7e74053a70\n  Kernel Version:             5.15.0-58-generic\n  OS Image:                   Ubuntu 22.04.2 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.19-46-g941215f49\n  Kubelet Version:            v1.27.0\n  Kube-Proxy Version:         v1.27.0\nPodCIDR:                      10.244.0.0/24\nPodCIDRs:                     10.244.0.0/24\nProviderID:                   kind://docker/c3/c3-control-plane\nNon-terminated Pods:          (10 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-5d78c9869d-gdmwj                                   100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)     8h\n  kube-system                 coredns-5d78c9869d-q9pjc                                   100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)     8h\n  kube-system                 etcd-c3-control-plane                                      100m (0%)     0 (0%)      100Mi (0%)       0 (0%)         8h\n  kube-system                 kindnet-qcvcz                                              100m (0%)     100m (0%)   50Mi (0%)        50Mi (0%)      8h\n  kube-system                 kube-apiserver-c3-control-plane                            250m (0%)     0 (0%)      0 (0%)           0 (0%)         8h\n  kube-system                 kube-controller-manager-c3-control-plane                   200m (0%)     0 (0%)      0 (0%)           0 (0%)         8h\n  kube-system                 kube-proxy-dqrpp                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         8h\n  kube-system                 kube-scheduler-c3-control-plane                            100m (0%)     0 (0%)      0 (0%)           0 (0%)         8h\n  local-path-storage          local-path-provisioner-5d7949c7d4-c5mv7                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         8h\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-b56js    0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                950m (1%)   100m (0%)\n  memory             290Mi (0%)  390Mi (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
  Apr 17 08:04:54.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=kubectl-1437 describe namespace kubectl-1437'
  Apr 17 08:04:54.787: INFO: stderr: ""
  Apr 17 08:04:54.787: INFO: stdout: "Name:         kubectl-1437\nLabels:       e2e-framework=kubectl\n              e2e-run=2f2b4a38-48a4-49d0-90b5-0f5f94ee4d80\n              kubernetes.io/metadata.name=kubectl-1437\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Apr 17 08:04:54.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1437" for this suite. @ 04/17/23 08:04:54.789
â€¢ [2.535 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 04/17/23 08:04:54.791
  Apr 17 08:04:54.791: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 08:04:54.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:54.794
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:54.795
  STEP: Creating configMap with name configmap-projected-all-test-volume-e2a0ec40-14e3-478b-86d5-6b81712e67b0 @ 04/17/23 08:04:54.796
  STEP: Creating secret with name secret-projected-all-test-volume-8927de04-cf7b-4a0c-9e2f-f0edac79eac0 @ 04/17/23 08:04:54.798
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 04/17/23 08:04:54.799
  STEP: Saw pod success @ 04/17/23 08:04:58.807
  Apr 17 08:04:58.808: INFO: Trying to get logs from node c3-worker2 pod projected-volume-b1d0d725-5e32-4caa-8f1b-2a7dd757dbe5 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 08:04:58.81
  Apr 17 08:04:58.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4324" for this suite. @ 04/17/23 08:04:58.815
â€¢ [4.026 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:117
  STEP: Creating a kubernetes client @ 04/17/23 08:04:58.817
  Apr 17 08:04:58.817: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 08:04:58.817
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:04:58.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:04:58.822
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/17/23 08:04:58.823
  STEP: Saw pod success @ 04/17/23 08:05:02.831
  Apr 17 08:05:02.832: INFO: Trying to get logs from node c3-worker pod pod-69a4f0c0-410f-48a9-ad46-dd450e783f50 container test-container: <nil>
  STEP: delete the pod @ 04/17/23 08:05:02.834
  Apr 17 08:05:02.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4557" for this suite. @ 04/17/23 08:05:02.84
â€¢ [4.025 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:207
  STEP: Creating a kubernetes client @ 04/17/23 08:05:02.842
  Apr 17 08:05:02.842: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename emptydir @ 04/17/23 08:05:02.842
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:05:02.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:05:02.848
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/17/23 08:05:02.849
  STEP: Saw pod success @ 04/17/23 08:05:06.858
  Apr 17 08:05:06.859: INFO: Trying to get logs from node c3-worker pod pod-89d0f863-857c-42c6-b5c4-e9f357b6994c container test-container: <nil>
  STEP: delete the pod @ 04/17/23 08:05:06.861
  Apr 17 08:05:06.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2469" for this suite. @ 04/17/23 08:05:06.866
â€¢ [4.025 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 04/17/23 08:05:06.868
  Apr 17 08:05:06.868: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-probe @ 04/17/23 08:05:06.869
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:05:06.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:05:06.874
  STEP: Creating pod busybox-8a2bdd16-ad57-4e00-b937-ec7e98d19952 in namespace container-probe-2112 @ 04/17/23 08:05:06.875
  Apr 17 08:05:08.880: INFO: Started pod busybox-8a2bdd16-ad57-4e00-b937-ec7e98d19952 in namespace container-probe-2112
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/17/23 08:05:08.88
  Apr 17 08:05:08.881: INFO: Initial restart count of pod busybox-8a2bdd16-ad57-4e00-b937-ec7e98d19952 is 0
  Apr 17 08:09:09.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 08:09:09.172
  STEP: Destroying namespace "container-probe-2112" for this suite. @ 04/17/23 08:09:09.178
â€¢ [242.312 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:344
  STEP: Creating a kubernetes client @ 04/17/23 08:09:09.181
  Apr 17 08:09:09.181: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename field-validation @ 04/17/23 08:09:09.182
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:09:09.185
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:09:09.186
  Apr 17 08:09:09.188: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  W0417 08:09:09.188383      30 field_validation.go:417] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc00225d520 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  W0417 08:09:11.717120      30 warnings.go:70] unknown field "alpha"
  W0417 08:09:11.717134      30 warnings.go:70] unknown field "beta"
  W0417 08:09:11.717137      30 warnings.go:70] unknown field "delta"
  W0417 08:09:11.717140      30 warnings.go:70] unknown field "epsilon"
  W0417 08:09:11.717143      30 warnings.go:70] unknown field "gamma"
  Apr 17 08:09:11.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8288" for this suite. @ 04/17/23 08:09:11.726
â€¢ [2.546 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]
test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 04/17/23 08:09:11.727
  Apr 17 08:09:11.727: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename sched-pred @ 04/17/23 08:09:11.728
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:09:11.731
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:09:11.733
  Apr 17 08:09:11.734: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 17 08:09:11.736: INFO: Waiting for terminating namespaces to be deleted...
  Apr 17 08:09:11.737: INFO: 
  Logging pods the apiserver thinks is on node c3-worker before test
  Apr 17 08:09:11.739: INFO: kindnet-plq69 from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 08:09:11.739: INFO: 	Container kindnet-cni ready: true, restart count 0
  Apr 17 08:09:11.739: INFO: kube-proxy-6r2kb from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 08:09:11.739: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 17 08:09:11.739: INFO: sonobuoy from sonobuoy started at 2023-04-17 06:33:09 +0000 UTC (1 container statuses recorded)
  Apr 17 08:09:11.739: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 17 08:09:11.739: INFO: sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-7tzl9 from sonobuoy started at 2023-04-17 06:33:10 +0000 UTC (2 container statuses recorded)
  Apr 17 08:09:11.739: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 08:09:11.739: INFO: 	Container systemd-logs ready: true, restart count 0
  Apr 17 08:09:11.739: INFO: 
  Logging pods the apiserver thinks is on node c3-worker2 before test
  Apr 17 08:09:11.741: INFO: kindnet-br9l4 from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 08:09:11.741: INFO: 	Container kindnet-cni ready: true, restart count 0
  Apr 17 08:09:11.741: INFO: kube-proxy-stm68 from kube-system started at 2023-04-16 23:18:32 +0000 UTC (1 container statuses recorded)
  Apr 17 08:09:11.741: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 17 08:09:11.741: INFO: sonobuoy-e2e-job-e91f319b048a45eb from sonobuoy started at 2023-04-17 06:33:10 +0000 UTC (2 container statuses recorded)
  Apr 17 08:09:11.741: INFO: 	Container e2e ready: true, restart count 0
  Apr 17 08:09:11.741: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 08:09:11.741: INFO: sonobuoy-systemd-logs-daemon-set-819b6971e2874ed6-svr2p from sonobuoy started at 2023-04-17 06:33:10 +0000 UTC (2 container statuses recorded)
  Apr 17 08:09:11.741: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Apr 17 08:09:11.741: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/17/23 08:09:11.741
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/17/23 08:09:13.748
  STEP: Trying to apply a random label on the found node. @ 04/17/23 08:09:13.751
  STEP: verifying the node has the label kubernetes.io/e2e-ec7775b1-204a-4446-b039-e3d1a6a02dce 42 @ 04/17/23 08:09:13.755
  STEP: Trying to relaunch the pod, now with labels. @ 04/17/23 08:09:13.756
  STEP: removing the label kubernetes.io/e2e-ec7775b1-204a-4446-b039-e3d1a6a02dce off the node c3-worker @ 04/17/23 08:09:15.762
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-ec7775b1-204a-4446-b039-e3d1a6a02dce @ 04/17/23 08:09:15.766
  Apr 17 08:09:15.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-712" for this suite. @ 04/17/23 08:09:15.768
â€¢ [4.043 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 04/17/23 08:09:15.77
  Apr 17 08:09:15.770: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename secrets @ 04/17/23 08:09:15.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:09:15.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:09:15.781
  STEP: Creating secret with name secret-test-map-0501804b-e9ae-4994-98a9-e41d214aa95a @ 04/17/23 08:09:15.782
  STEP: Creating a pod to test consume secrets @ 04/17/23 08:09:15.783
  STEP: Saw pod success @ 04/17/23 08:09:17.789
  Apr 17 08:09:17.790: INFO: Trying to get logs from node c3-worker pod pod-secrets-b64709b5-970c-4ffa-be14-4a8697842c90 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 08:09:17.798
  Apr 17 08:09:17.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3243" for this suite. @ 04/17/23 08:09:17.803
â€¢ [2.034 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]
test/e2e/apps/statefulset.go:981
  STEP: Creating a kubernetes client @ 04/17/23 08:09:17.805
  Apr 17 08:09:17.805: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename statefulset @ 04/17/23 08:09:17.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:09:17.809
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:09:17.81
  STEP: Creating service test in namespace statefulset-2090 @ 04/17/23 08:09:17.81
  STEP: Creating statefulset ss in namespace statefulset-2090 @ 04/17/23 08:09:17.813
  Apr 17 08:09:17.816: INFO: Found 0 stateful pods, waiting for 1
  Apr 17 08:09:27.819: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 04/17/23 08:09:27.821
  STEP: Getting /status @ 04/17/23 08:09:27.823
  Apr 17 08:09:27.824: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 04/17/23 08:09:27.824
  Apr 17 08:09:27.827: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 04/17/23 08:09:27.827
  Apr 17 08:09:27.828: INFO: Observed &StatefulSet event: ADDED
  Apr 17 08:09:27.828: INFO: Found Statefulset ss in namespace statefulset-2090 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 17 08:09:27.828: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 04/17/23 08:09:27.828
  Apr 17 08:09:27.828: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 17 08:09:27.830: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 04/17/23 08:09:27.83
  Apr 17 08:09:27.831: INFO: Observed &StatefulSet event: ADDED
  Apr 17 08:09:27.831: INFO: Deleting all statefulset in ns statefulset-2090
  Apr 17 08:09:27.832: INFO: Scaling statefulset ss to 0
  Apr 17 08:09:37.839: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 17 08:09:37.840: INFO: Deleting statefulset ss
  Apr 17 08:09:37.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2090" for this suite. @ 04/17/23 08:09:37.845
â€¢ [20.041 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]
test/e2e/apimachinery/field_validation.go:465
  STEP: Creating a kubernetes client @ 04/17/23 08:09:37.846
  Apr 17 08:09:37.846: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename field-validation @ 04/17/23 08:09:37.847
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:09:37.851
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:09:37.852
  Apr 17 08:09:37.853: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  W0417 08:09:40.376984      30 warnings.go:70] unknown field "alpha"
  W0417 08:09:40.376998      30 warnings.go:70] unknown field "beta"
  W0417 08:09:40.377001      30 warnings.go:70] unknown field "delta"
  W0417 08:09:40.377003      30 warnings.go:70] unknown field "epsilon"
  W0417 08:09:40.377007      30 warnings.go:70] unknown field "gamma"
  Apr 17 08:09:40.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6652" for this suite. @ 04/17/23 08:09:40.386
â€¢ [2.541 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:99
  STEP: Creating a kubernetes client @ 04/17/23 08:09:40.387
  Apr 17 08:09:40.387: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 08:09:40.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:09:40.392
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:09:40.393
  STEP: Creating configMap with name projected-configmap-test-volume-map-fbbb3e19-37b4-46a8-8148-7b42fffc7f94 @ 04/17/23 08:09:40.394
  STEP: Creating a pod to test consume configMaps @ 04/17/23 08:09:40.395
  STEP: Saw pod success @ 04/17/23 08:09:44.403
  Apr 17 08:09:44.404: INFO: Trying to get logs from node c3-worker pod pod-projected-configmaps-e82720fe-8f13-4047-bcc3-166b18916fa2 container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 08:09:44.407
  Apr 17 08:09:44.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5270" for this suite. @ 04/17/23 08:09:44.412
â€¢ [4.027 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]
test/e2e/apps/rc.go:424
  STEP: Creating a kubernetes client @ 04/17/23 08:09:44.414
  Apr 17 08:09:44.414: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename replication-controller @ 04/17/23 08:09:44.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:09:44.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:09:44.42
  STEP: Creating ReplicationController "e2e-rc-2hkwq" @ 04/17/23 08:09:44.421
  Apr 17 08:09:44.422: INFO: Get Replication Controller "e2e-rc-2hkwq" to confirm replicas
  Apr 17 08:09:45.423: INFO: Get Replication Controller "e2e-rc-2hkwq" to confirm replicas
  Apr 17 08:09:45.424: INFO: Found 1 replicas for "e2e-rc-2hkwq" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-2hkwq" @ 04/17/23 08:09:45.424
  STEP: Updating a scale subresource @ 04/17/23 08:09:45.425
  STEP: Verifying replicas where modified for replication controller "e2e-rc-2hkwq" @ 04/17/23 08:09:45.427
  Apr 17 08:09:45.427: INFO: Get Replication Controller "e2e-rc-2hkwq" to confirm replicas
  Apr 17 08:09:46.428: INFO: Get Replication Controller "e2e-rc-2hkwq" to confirm replicas
  Apr 17 08:09:46.429: INFO: Found 2 replicas for "e2e-rc-2hkwq" replication controller
  Apr 17 08:09:46.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8218" for this suite. @ 04/17/23 08:09:46.43
â€¢ [2.018 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance]
test/e2e/apps/job.go:713
  STEP: Creating a kubernetes client @ 04/17/23 08:09:46.432
  Apr 17 08:09:46.432: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename job @ 04/17/23 08:09:46.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:09:46.436
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:09:46.437
  STEP: Creating a suspended job @ 04/17/23 08:09:46.44
  STEP: Patching the Job @ 04/17/23 08:09:46.441
  STEP: Watching for Job to be patched @ 04/17/23 08:09:46.45
  Apr 17 08:09:46.450: INFO: Event ADDED observed for Job e2e-v9nx8 in namespace job-4816 with labels: map[e2e-job-label:e2e-v9nx8] and annotations: map[batch.kubernetes.io/job-tracking:]
  Apr 17 08:09:46.451: INFO: Event MODIFIED observed for Job e2e-v9nx8 in namespace job-4816 with labels: map[e2e-job-label:e2e-v9nx8] and annotations: map[batch.kubernetes.io/job-tracking:]
  Apr 17 08:09:46.451: INFO: Event MODIFIED found for Job e2e-v9nx8 in namespace job-4816 with labels: map[e2e-job-label:e2e-v9nx8 e2e-v9nx8:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
  STEP: Updating the job @ 04/17/23 08:09:46.451
  STEP: Watching for Job to be updated @ 04/17/23 08:09:46.453
  Apr 17 08:09:46.454: INFO: Event MODIFIED found for Job e2e-v9nx8 in namespace job-4816 with labels: map[e2e-job-label:e2e-v9nx8 e2e-v9nx8:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 17 08:09:46.454: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 04/17/23 08:09:46.454
  Apr 17 08:09:46.455: INFO: Job: e2e-v9nx8 as labels: map[e2e-job-label:e2e-v9nx8 e2e-v9nx8:patched]
  STEP: Waiting for job to complete @ 04/17/23 08:09:46.455
  STEP: Delete a job collection with a labelselector @ 04/17/23 08:09:54.459
  STEP: Watching for Job to be deleted @ 04/17/23 08:09:54.46
  Apr 17 08:09:54.461: INFO: Event MODIFIED observed for Job e2e-v9nx8 in namespace job-4816 with labels: map[e2e-job-label:e2e-v9nx8 e2e-v9nx8:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 17 08:09:54.461: INFO: Event MODIFIED observed for Job e2e-v9nx8 in namespace job-4816 with labels: map[e2e-job-label:e2e-v9nx8 e2e-v9nx8:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 17 08:09:54.461: INFO: Event MODIFIED observed for Job e2e-v9nx8 in namespace job-4816 with labels: map[e2e-job-label:e2e-v9nx8 e2e-v9nx8:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 17 08:09:54.461: INFO: Event MODIFIED observed for Job e2e-v9nx8 in namespace job-4816 with labels: map[e2e-job-label:e2e-v9nx8 e2e-v9nx8:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 17 08:09:54.462: INFO: Event MODIFIED observed for Job e2e-v9nx8 in namespace job-4816 with labels: map[e2e-job-label:e2e-v9nx8 e2e-v9nx8:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 17 08:09:54.462: INFO: Event DELETED found for Job e2e-v9nx8 in namespace job-4816 with labels: map[e2e-job-label:e2e-v9nx8 e2e-v9nx8:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  STEP: Relist jobs to confirm deletion @ 04/17/23 08:09:54.462
  Apr 17 08:09:54.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4816" for this suite. @ 04/17/23 08:09:54.465
â€¢ [8.035 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:163
  STEP: Creating a kubernetes client @ 04/17/23 08:09:54.467
  Apr 17 08:09:54.467: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 08:09:54.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:09:54.471
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:09:54.472
  STEP: Creating the pod @ 04/17/23 08:09:54.473
  Apr 17 08:09:56.986: INFO: Successfully updated pod "annotationupdate2cfa5791-bc1e-4a43-9532-3dab357318b1"
  Apr 17 08:10:00.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5646" for this suite. @ 04/17/23 08:10:00.997
â€¢ [6.531 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:57
  STEP: Creating a kubernetes client @ 04/17/23 08:10:00.999
  Apr 17 08:10:00.999: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 08:10:00.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:10:01.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:10:01.004
  STEP: Creating configMap with name configmap-test-volume-bae85e0a-a2f7-4942-bf28-8733f33acdaf @ 04/17/23 08:10:01.005
  STEP: Creating a pod to test consume configMaps @ 04/17/23 08:10:01.007
  STEP: Saw pod success @ 04/17/23 08:10:05.015
  Apr 17 08:10:05.016: INFO: Trying to get logs from node c3-worker2 pod pod-configmaps-69674448-5e43-4479-83e0-99ebe99e14b4 container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 08:10:05.025
  Apr 17 08:10:05.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6115" for this suite. @ 04/17/23 08:10:05.03
â€¢ [4.033 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]
test/e2e/apimachinery/field_validation.go:610
  STEP: Creating a kubernetes client @ 04/17/23 08:10:05.031
  Apr 17 08:10:05.031: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename field-validation @ 04/17/23 08:10:05.032
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:10:05.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:10:05.037
  Apr 17 08:10:05.038: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  W0417 08:10:07.569964      30 warnings.go:70] unknown field "alpha"
  W0417 08:10:07.569983      30 warnings.go:70] unknown field "beta"
  W0417 08:10:07.569986      30 warnings.go:70] unknown field "delta"
  W0417 08:10:07.569989      30 warnings.go:70] unknown field "epsilon"
  W0417 08:10:07.569992      30 warnings.go:70] unknown field "gamma"
  Apr 17 08:10:07.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1485" for this suite. @ 04/17/23 08:10:07.579
â€¢ [2.550 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:47
  STEP: Creating a kubernetes client @ 04/17/23 08:10:07.581
  Apr 17 08:10:07.581: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename configmap @ 04/17/23 08:10:07.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:10:07.586
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:10:07.587
  STEP: Creating configMap with name configmap-test-volume-549259af-a811-4054-9ddb-3dd89bbed9ce @ 04/17/23 08:10:07.588
  STEP: Creating a pod to test consume configMaps @ 04/17/23 08:10:07.589
  STEP: Saw pod success @ 04/17/23 08:10:11.597
  Apr 17 08:10:11.598: INFO: Trying to get logs from node c3-worker pod pod-configmaps-a962b432-46dd-4005-b776-c78be53be50c container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 08:10:11.6
  Apr 17 08:10:11.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6355" for this suite. @ 04/17/23 08:10:11.606
â€¢ [4.026 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]
test/e2e/apps/daemon_set.go:432
  STEP: Creating a kubernetes client @ 04/17/23 08:10:11.608
  Apr 17 08:10:11.608: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename daemonsets @ 04/17/23 08:10:11.608
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:10:11.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:10:11.613
  Apr 17 08:10:11.620: INFO: Create a RollingUpdate DaemonSet
  Apr 17 08:10:11.621: INFO: Check that daemon pods launch on every node of the cluster
  Apr 17 08:10:11.622: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 08:10:11.623: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 08:10:11.623: INFO: Node c3-worker is running 0 daemon pod, expected 1
  Apr 17 08:10:12.625: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 08:10:12.626: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 17 08:10:12.626: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  Apr 17 08:10:12.626: INFO: Update the DaemonSet to trigger a rollout
  Apr 17 08:10:12.629: INFO: Updating DaemonSet daemon-set
  Apr 17 08:10:14.635: INFO: Roll back the DaemonSet before rollout is complete
  Apr 17 08:10:14.638: INFO: Updating DaemonSet daemon-set
  Apr 17 08:10:14.638: INFO: Make sure DaemonSet rollback is complete
  Apr 17 08:10:14.639: INFO: Wrong image for pod: daemon-set-gsn4q. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Apr 17 08:10:14.639: INFO: Pod daemon-set-gsn4q is not available
  Apr 17 08:10:14.640: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 08:10:15.644: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 08:10:16.642: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 08:10:17.644: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 17 08:10:18.642: INFO: Pod daemon-set-9jk9j is not available
  Apr 17 08:10:18.643: INFO: DaemonSet pods can't tolerate node c3-control-plane with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 04/17/23 08:10:18.645
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3844, will wait for the garbage collector to delete the pods @ 04/17/23 08:10:18.645
  Apr 17 08:10:18.698: INFO: Deleting DaemonSet.extensions daemon-set took: 1.908124ms
  Apr 17 08:10:18.799: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.470993ms
  Apr 17 08:10:21.800: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 17 08:10:21.800: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 17 08:10:21.801: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"71288"},"items":null}

  Apr 17 08:10:21.802: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"71288"},"items":null}

  Apr 17 08:10:21.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3844" for this suite. @ 04/17/23 08:10:21.807
â€¢ [10.201 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:194
  STEP: Creating a kubernetes client @ 04/17/23 08:10:21.808
  Apr 17 08:10:21.808: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 08:10:21.809
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:10:21.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:10:21.814
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 08:10:21.815
  STEP: Saw pod success @ 04/17/23 08:10:25.824
  Apr 17 08:10:25.825: INFO: Trying to get logs from node c3-worker2 pod downwardapi-volume-dd673b70-56c0-4454-803e-b28fae8cc64e container client-container: <nil>
  STEP: delete the pod @ 04/17/23 08:10:25.828
  Apr 17 08:10:25.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3930" for this suite. @ 04/17/23 08:10:25.833
â€¢ [4.026 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]
test/e2e/apps/rc.go:112
  STEP: Creating a kubernetes client @ 04/17/23 08:10:25.835
  Apr 17 08:10:25.835: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename replication-controller @ 04/17/23 08:10:25.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:10:25.839
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:10:25.84
  STEP: creating a ReplicationController @ 04/17/23 08:10:25.842
  STEP: waiting for RC to be added @ 04/17/23 08:10:25.844
  STEP: waiting for available Replicas @ 04/17/23 08:10:25.844
  STEP: patching ReplicationController @ 04/17/23 08:10:26.584
  STEP: waiting for RC to be modified @ 04/17/23 08:10:26.588
  STEP: patching ReplicationController status @ 04/17/23 08:10:26.588
  STEP: waiting for RC to be modified @ 04/17/23 08:10:26.592
  STEP: waiting for available Replicas @ 04/17/23 08:10:26.592
  STEP: fetching ReplicationController status @ 04/17/23 08:10:26.594
  STEP: patching ReplicationController scale @ 04/17/23 08:10:26.596
  STEP: waiting for RC to be modified @ 04/17/23 08:10:26.597
  STEP: waiting for ReplicationController's scale to be the max amount @ 04/17/23 08:10:26.598
  STEP: fetching ReplicationController; ensuring that it's patched @ 04/17/23 08:10:27.457
  STEP: updating ReplicationController status @ 04/17/23 08:10:27.458
  STEP: waiting for RC to be modified @ 04/17/23 08:10:27.46
  STEP: listing all ReplicationControllers @ 04/17/23 08:10:27.461
  STEP: checking that ReplicationController has expected values @ 04/17/23 08:10:27.468
  STEP: deleting ReplicationControllers by collection @ 04/17/23 08:10:27.468
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 04/17/23 08:10:27.472
  Apr 17 08:10:27.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0417 08:10:27.496058      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-2453" for this suite. @ 04/17/23 08:10:27.497
â€¢ [1.663 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 04/17/23 08:10:27.499
  Apr 17 08:10:27.499: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename taint-single-pod @ 04/17/23 08:10:27.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:10:27.502
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:10:27.503
  Apr 17 08:10:27.504: INFO: Waiting up to 1m0s for all nodes to be ready
  E0417 08:10:28.496398      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:29.496540      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:30.496717      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:31.497158      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:32.497927      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:33.498183      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:34.498848      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:35.499123      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:36.499157      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:37.499325      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:38.500279      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:39.500518      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:40.501154      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:41.501530      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:42.501862      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:43.502066      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:44.502887      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:45.503094      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:46.503196      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:47.503348      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:48.503590      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:49.503761      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:50.503916      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:51.504250      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:52.505195      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:53.505306      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:54.506309      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:55.506479      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:56.506927      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:57.507171      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:58.507632      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:10:59.507901      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:00.508719      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:01.509213      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:02.509623      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:03.509615      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:04.509943      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:05.510039      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:06.510370      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:07.510643      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:08.511208      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:09.511351      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:10.511491      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:11.512154      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:12.512408      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:13.512863      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:14.513068      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:15.513910      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:16.514185      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:17.515164      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:18.515341      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:19.516152      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:20.516253      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:21.516804      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:22.516988      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:23.517662      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:24.517858      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:25.518075      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:26.518344      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:11:27.512: INFO: Waiting for terminating namespaces to be deleted...
  Apr 17 08:11:27.513: INFO: Starting informer...
  STEP: Starting pod... @ 04/17/23 08:11:27.513
  E0417 08:11:27.518954      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:11:27.718: INFO: Pod is running on c3-worker. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/17/23 08:11:27.718
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/17/23 08:11:27.722
  STEP: Waiting short time to make sure Pod is queued for deletion @ 04/17/23 08:11:27.723
  Apr 17 08:11:27.723: INFO: Pod wasn't evicted. Proceeding
  Apr 17 08:11:27.723: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/17/23 08:11:27.727
  STEP: Waiting some time to make sure that toleration time passed. @ 04/17/23 08:11:27.728
  E0417 08:11:28.519585      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:29.520341      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:30.520519      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:31.520994      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:32.521140      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:33.521318      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:34.521574      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:35.521822      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:36.522166      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:37.522397      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:38.522573      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:39.522727      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:40.522935      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:41.523406      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:42.523611      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:43.523758      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:44.523998      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:45.524219      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:46.524595      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:47.524744      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:48.524897      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:49.525097      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:50.525277      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:51.525638      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:52.525805      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:53.525959      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:54.526154      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:55.526351      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:56.526764      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:57.527260      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:58.527486      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:11:59.528003      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:00.528216      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:01.528576      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:02.528725      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:03.528881      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:04.529128      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:05.529324      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:06.529731      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:07.529931      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:08.530118      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:09.530776      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:10.530769      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:11.531232      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:12.531383      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:13.531525      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:14.531684      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:15.531844      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:16.532074      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:17.532212      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:18.532356      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:19.532454      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:20.532625      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:21.533051      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:22.533197      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:23.533326      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:24.533478      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:25.533644      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:26.533825      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:27.534501      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:28.534620      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:29.534911      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:30.535093      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:31.535460      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:32.535657      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:33.535826      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:34.536005      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:35.536188      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:36.536475      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:37.536720      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:38.536880      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:39.536980      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:40.537142      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:41.537465      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:42.537595      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:12:42.728: INFO: Pod wasn't evicted. Test successful
  Apr 17 08:12:42.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-6847" for this suite. @ 04/17/23 08:12:42.731
â€¢ [135.234 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 04/17/23 08:12:42.733
  Apr 17 08:12:42.733: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename disruption @ 04/17/23 08:12:42.734
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:12:42.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:12:42.739
  STEP: Waiting for the pdb to be processed @ 04/17/23 08:12:42.742
  E0417 08:12:43.538386      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:44.538689      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 04/17/23 08:12:44.745
  STEP: Waiting for all pods to be running @ 04/17/23 08:12:44.748
  Apr 17 08:12:44.749: INFO: running pods: 0 < 1
  E0417 08:12:45.539523      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:46.539844      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/17/23 08:12:46.752
  STEP: Waiting for the pdb to be processed @ 04/17/23 08:12:46.756
  STEP: Patching PodDisruptionBudget status @ 04/17/23 08:12:46.758
  STEP: Waiting for the pdb to be processed @ 04/17/23 08:12:46.761
  Apr 17 08:12:46.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9499" for this suite. @ 04/17/23 08:12:46.764
â€¢ [4.032 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service  [Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 04/17/23 08:12:46.766
  Apr 17 08:12:46.766: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 08:12:46.766
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:12:46.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:12:46.771
  Apr 17 08:12:46.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6859" for this suite. @ 04/17/23 08:12:46.775
â€¢ [0.011 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]
test/e2e/apimachinery/webhook.go:260
  STEP: Creating a kubernetes client @ 04/17/23 08:12:46.777
  Apr 17 08:12:46.777: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 08:12:46.777
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:12:46.781
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:12:46.782
  STEP: Setting up server cert @ 04/17/23 08:12:46.788
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 08:12:47.005
  STEP: Deploying the webhook pod @ 04/17/23 08:12:47.007
  STEP: Wait for the deployment to be ready @ 04/17/23 08:12:47.01
  Apr 17 08:12:47.012: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0417 08:12:47.540693      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:48.540844      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/17/23 08:12:49.017
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 08:12:49.02
  E0417 08:12:49.541039      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:12:50.020: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 04/17/23 08:12:50.022
  STEP: create a pod that should be updated by the webhook @ 04/17/23 08:12:50.029
  Apr 17 08:12:50.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-629" for this suite. @ 04/17/23 08:12:50.048
  STEP: Destroying namespace "webhook-markers-9522" for this suite. @ 04/17/23 08:12:50.049
â€¢ [3.274 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods  [Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 04/17/23 08:12:50.051
  Apr 17 08:12:50.051: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename services @ 04/17/23 08:12:50.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:12:50.055
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:12:50.056
  STEP: creating service endpoint-test2 in namespace services-4865 @ 04/17/23 08:12:50.057
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4865 to expose endpoints map[] @ 04/17/23 08:12:50.06
  Apr 17 08:12:50.061: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E0417 08:12:50.541887      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:12:51.064: INFO: successfully validated that service endpoint-test2 in namespace services-4865 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-4865 @ 04/17/23 08:12:51.064
  E0417 08:12:51.542294      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:52.542519      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4865 to expose endpoints map[pod1:[80]] @ 04/17/23 08:12:53.071
  Apr 17 08:12:53.074: INFO: successfully validated that service endpoint-test2 in namespace services-4865 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 04/17/23 08:12:53.074
  Apr 17 08:12:53.074: INFO: Creating new exec pod
  E0417 08:12:53.542668      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:54.542875      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:55.542969      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:12:56.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4865 exec execpodjlzqv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 17 08:12:56.196: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 17 08:12:56.196: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 08:12:56.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4865 exec execpodjlzqv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.244.15 80'
  Apr 17 08:12:56.308: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.244.15 80\nConnection to 10.96.244.15 80 port [tcp/http] succeeded!\n"
  Apr 17 08:12:56.308: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-4865 @ 04/17/23 08:12:56.308
  E0417 08:12:56.543411      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:12:57.543754      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4865 to expose endpoints map[pod1:[80] pod2:[80]] @ 04/17/23 08:12:58.315
  Apr 17 08:12:58.320: INFO: successfully validated that service endpoint-test2 in namespace services-4865 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 04/17/23 08:12:58.32
  E0417 08:12:58.544658      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:12:59.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4865 exec execpodjlzqv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 17 08:12:59.440: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 17 08:12:59.440: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 08:12:59.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4865 exec execpodjlzqv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.244.15 80'
  Apr 17 08:12:59.531: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.244.15 80\nConnection to 10.96.244.15 80 port [tcp/http] succeeded!\n"
  Apr 17 08:12:59.531: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-4865 @ 04/17/23 08:12:59.531
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4865 to expose endpoints map[pod2:[80]] @ 04/17/23 08:12:59.534
  Apr 17 08:12:59.538: INFO: successfully validated that service endpoint-test2 in namespace services-4865 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 04/17/23 08:12:59.538
  E0417 08:12:59.545143      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:13:00.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4865 exec execpodjlzqv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E0417 08:13:00.545680      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:13:00.649: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 17 08:13:00.649: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 17 08:13:00.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1944430999 --namespace=services-4865 exec execpodjlzqv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.244.15 80'
  Apr 17 08:13:00.730: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.244.15 80\nConnection to 10.96.244.15 80 port [tcp/http] succeeded!\n"
  Apr 17 08:13:00.730: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-4865 @ 04/17/23 08:13:00.73
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4865 to expose endpoints map[] @ 04/17/23 08:13:00.734
  E0417 08:13:01.546217      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:13:01.740: INFO: successfully validated that service endpoint-test2 in namespace services-4865 exposes endpoints map[]
  Apr 17 08:13:01.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4865" for this suite. @ 04/17/23 08:13:01.745
â€¢ [11.696 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]
test/e2e/apps/job.go:513
  STEP: Creating a kubernetes client @ 04/17/23 08:13:01.747
  Apr 17 08:13:01.747: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename job @ 04/17/23 08:13:01.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:13:01.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:13:01.753
  STEP: Creating a job @ 04/17/23 08:13:01.754
  STEP: Ensuring active pods == parallelism @ 04/17/23 08:13:01.756
  E0417 08:13:02.547285      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:03.547458      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 04/17/23 08:13:03.758
  Apr 17 08:13:04.263: INFO: Successfully updated pod "adopt-release-9qrkv"
  STEP: Checking that the Job readopts the Pod @ 04/17/23 08:13:04.263
  E0417 08:13:04.548486      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:05.548767      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 04/17/23 08:13:06.266
  E0417 08:13:06.549229      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:13:06.771: INFO: Successfully updated pod "adopt-release-9qrkv"
  STEP: Checking that the Job releases the Pod @ 04/17/23 08:13:06.771
  E0417 08:13:07.550087      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:08.550309      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:13:08.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-685" for this suite. @ 04/17/23 08:13:08.776
â€¢ [7.030 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 04/17/23 08:13:08.778
  Apr 17 08:13:08.778: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename deployment @ 04/17/23 08:13:08.779
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:13:08.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:13:08.783
  Apr 17 08:13:08.785: INFO: Creating deployment "test-recreate-deployment"
  Apr 17 08:13:08.786: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Apr 17 08:13:08.788: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
  E0417 08:13:09.551303      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:10.551595      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:13:10.791: INFO: Waiting deployment "test-recreate-deployment" to complete
  Apr 17 08:13:10.792: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Apr 17 08:13:10.794: INFO: Updating deployment test-recreate-deployment
  Apr 17 08:13:10.794: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Apr 17 08:13:10.815: INFO: Deployment "test-recreate-deployment":
  &Deployment{ObjectMeta:{test-recreate-deployment  deployment-9533  88713b95-4fea-44fa-b0aa-3e66ece969b3 71966 2 2023-04-17 08:13:08 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-17 08:13:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 08:13:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005602e98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-17 08:13:10 +0000 UTC,LastTransitionTime:2023-04-17 08:13:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-54757ffd6c" is progressing.,LastUpdateTime:2023-04-17 08:13:10 +0000 UTC,LastTransitionTime:2023-04-17 08:13:08 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

  Apr 17 08:13:10.816: INFO: New ReplicaSet "test-recreate-deployment-54757ffd6c" of Deployment "test-recreate-deployment":
  &ReplicaSet{ObjectMeta:{test-recreate-deployment-54757ffd6c  deployment-9533  14cc2261-cb37-43a0-a22b-fdde48362cf9 71963 1 2023-04-17 08:13:10 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:54757ffd6c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 88713b95-4fea-44fa-b0aa-3e66ece969b3 0xc0066926c7 0xc0066926c8}] [] [{kube-controller-manager Update apps/v1 2023-04-17 08:13:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"88713b95-4fea-44fa-b0aa-3e66ece969b3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 08:13:10 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 54757ffd6c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:54757ffd6c] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006692778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 17 08:13:10.816: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Apr 17 08:13:10.816: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-6c99bf8bf6  deployment-9533  7577e93e-a3f3-41bc-a41a-ec07c5ea3315 71955 2 2023-04-17 08:13:08 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:6c99bf8bf6] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 88713b95-4fea-44fa-b0aa-3e66ece969b3 0xc0066927e7 0xc0066927e8}] [] [{kube-controller-manager Update apps/v1 2023-04-17 08:13:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"88713b95-4fea-44fa-b0aa-3e66ece969b3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-17 08:13:10 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6c99bf8bf6,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:6c99bf8bf6] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0066928a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 17 08:13:10.817: INFO: Pod "test-recreate-deployment-54757ffd6c-6b94l" is not available:
  &Pod{ObjectMeta:{test-recreate-deployment-54757ffd6c-6b94l test-recreate-deployment-54757ffd6c- deployment-9533  9b7d3177-4320-4f11-935b-ea4f71559fe5 71967 0 2023-04-17 08:13:10 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:54757ffd6c] map[] [{apps/v1 ReplicaSet test-recreate-deployment-54757ffd6c 14cc2261-cb37-43a0-a22b-fdde48362cf9 0xc0055afcc7 0xc0055afcc8}] [] [{kube-controller-manager Update v1 2023-04-17 08:13:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"14cc2261-cb37-43a0-a22b-fdde48362cf9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-17 08:13:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ht4hc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ht4hc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:c3-worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 08:13:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 08:13:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 08:13:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-17 08:13:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.18.0.4,PodIP:,StartTime:2023-04-17 08:13:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 17 08:13:10.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9533" for this suite. @ 04/17/23 08:13:10.818
â€¢ [2.042 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 04/17/23 08:13:10.82
  Apr 17 08:13:10.820: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename var-expansion @ 04/17/23 08:13:10.82
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:13:10.823
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:13:10.824
  STEP: creating the pod @ 04/17/23 08:13:10.825
  STEP: waiting for pod running @ 04/17/23 08:13:10.828
  E0417 08:13:11.552138      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:12.552381      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 04/17/23 08:13:12.831
  Apr 17 08:13:12.832: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-220 PodName:var-expansion-bd2a5860-022a-4909-922e-9ca22aac24ca ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 08:13:12.832: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 08:13:12.832: INFO: ExecWithOptions: Clientset creation
  Apr 17 08:13:12.832: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-220/pods/var-expansion-bd2a5860-022a-4909-922e-9ca22aac24ca/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 04/17/23 08:13:12.894
  Apr 17 08:13:12.895: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-220 PodName:var-expansion-bd2a5860-022a-4909-922e-9ca22aac24ca ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 08:13:12.895: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 08:13:12.895: INFO: ExecWithOptions: Clientset creation
  Apr 17 08:13:12.895: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-220/pods/var-expansion-bd2a5860-022a-4909-922e-9ca22aac24ca/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 04/17/23 08:13:12.938
  Apr 17 08:13:13.444: INFO: Successfully updated pod "var-expansion-bd2a5860-022a-4909-922e-9ca22aac24ca"
  STEP: waiting for annotated pod running @ 04/17/23 08:13:13.444
  STEP: deleting the pod gracefully @ 04/17/23 08:13:13.445
  Apr 17 08:13:13.445: INFO: Deleting pod "var-expansion-bd2a5860-022a-4909-922e-9ca22aac24ca" in namespace "var-expansion-220"
  Apr 17 08:13:13.447: INFO: Wait up to 5m0s for pod "var-expansion-bd2a5860-022a-4909-922e-9ca22aac24ca" to be fully deleted
  E0417 08:13:13.553278      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:14.553457      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:15.554373      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:16.554644      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:17.555475      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:18.555720      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:19.556342      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:20.556515      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:21.557056      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:22.557232      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:23.557861      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:24.558059      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:25.558623      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:26.558984      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:27.559608      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:28.559747      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:29.560718      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:30.560890      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:31.561371      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:32.561562      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:33.562527      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:34.562716      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:35.563606      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:36.563836      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:37.564824      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:38.564993      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:39.565148      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:40.565301      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:41.565888      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:42.566098      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:43.566104      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:44.566287      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:13:45.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-220" for this suite. @ 04/17/23 08:13:45.484
â€¢ [34.666 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:54
  STEP: Creating a kubernetes client @ 04/17/23 08:13:45.486
  Apr 17 08:13:45.486: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename downward-api @ 04/17/23 08:13:45.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:13:45.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:13:45.492
  STEP: Creating a pod to test downward API volume plugin @ 04/17/23 08:13:45.493
  E0417 08:13:45.567185      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:46.567500      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:47.568272      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:48.568494      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/17/23 08:13:49.501
  Apr 17 08:13:49.503: INFO: Trying to get logs from node c3-worker pod downwardapi-volume-2476c525-7774-49aa-854f-a5bb77b03ef1 container client-container: <nil>
  STEP: delete the pod @ 04/17/23 08:13:49.51
  Apr 17 08:13:49.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2845" for this suite. @ 04/17/23 08:13:49.516
â€¢ [4.032 seconds]
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 04/17/23 08:13:49.518
  Apr 17 08:13:49.518: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename var-expansion @ 04/17/23 08:13:49.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:13:49.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:13:49.523
  STEP: creating the pod with failed condition @ 04/17/23 08:13:49.524
  E0417 08:13:49.569420      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:50.570195      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:51.570913      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:52.571090      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:53.571739      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:54.572088      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:55.572629      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:56.572780      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:57.573235      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:58.573391      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:13:59.574062      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:00.574305      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:01.575116      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:02.575265      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:03.575960      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:04.576103      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:05.576693      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:06.576941      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:07.577313      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:08.577452      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:09.578539      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:10.578743      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:11.579021      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:12.579138      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:13.579458      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:14.579758      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:15.580485      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:16.580818      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:17.581299      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:18.581463      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:19.582451      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:20.582588      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:21.583311      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:22.583456      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:23.584455      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:24.584645      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:25.585129      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:26.585390      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:27.585972      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:28.586475      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:29.587494      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:30.587645      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:31.588464      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:32.588600      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:33.589438      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:34.589547      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:35.589768      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:36.589976      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:37.590473      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:38.590617      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:39.591628      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:40.591804      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:41.592289      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:42.592431      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:43.593265      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:44.593507      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:45.594136      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:46.594427      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:47.595332      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:48.596412      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:49.596857      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:50.597028      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:51.597955      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:52.598155      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:53.598323      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:54.598473      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:55.598509      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:56.598857      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:57.599372      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:58.599572      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:14:59.599966      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:00.600102      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:01.600621      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:02.601042      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:03.601220      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:04.601313      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:05.601553      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:06.601614      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:07.601943      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:08.602741      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:09.602912      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:10.603082      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:11.603680      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:12.604297      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:13.604616      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:14.605227      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:15.605440      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:16.605418      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:17.605586      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:18.606232      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:19.606417      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:20.606555      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:21.607037      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:22.607588      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:23.607824      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:24.608554      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:25.608734      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:26.609742      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:27.609924      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:28.610698      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:29.610899      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:30.611718      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:31.612157      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:32.612873      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:33.613060      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:34.613500      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:35.613677      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:36.614598      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:37.614707      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:38.615565      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:39.615697      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:40.615822      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:41.616275      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:42.616946      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:43.617120      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:44.618080      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:45.618285      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:46.619260      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:47.619507      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:48.620063      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: updating the pod @ 04/17/23 08:15:49.528
  E0417 08:15:49.620377      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:15:50.034: INFO: Successfully updated pod "var-expansion-1714547f-2762-4894-b625-6626fa9757c0"
  STEP: waiting for pod running @ 04/17/23 08:15:50.034
  E0417 08:15:50.621214      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:51.621615      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 04/17/23 08:15:52.037
  Apr 17 08:15:52.037: INFO: Deleting pod "var-expansion-1714547f-2762-4894-b625-6626fa9757c0" in namespace "var-expansion-9928"
  Apr 17 08:15:52.039: INFO: Wait up to 5m0s for pod "var-expansion-1714547f-2762-4894-b625-6626fa9757c0" to be fully deleted
  E0417 08:15:52.621854      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:53.622354      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:54.623223      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:55.623422      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:56.624224      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:57.624445      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:58.624591      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:15:59.624804      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:00.625664      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:01.626111      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:02.626615      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:03.626760      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:04.627266      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:05.627463      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:06.627686      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:07.627843      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:08.628549      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:09.629212      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:10.629376      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:11.629760      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:12.630326      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:13.630496      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:14.630629      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:15.630864      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:16.631583      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:17.631692      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:18.631713      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:19.631886      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:20.632372      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:21.632764      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:22.633127      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:23.633266      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:16:24.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9928" for this suite. @ 04/17/23 08:16:24.076
â€¢ [154.560 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services  [Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 04/17/23 08:16:24.078
  Apr 17 08:16:24.078: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename dns @ 04/17/23 08:16:24.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:16:24.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:16:24.083
  STEP: Creating a test headless service @ 04/17/23 08:16:24.085
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2471.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2471.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2471.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2471.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2471.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2471.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2471.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2471.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2471.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2471.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2471.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2471.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 133.124.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.124.133_udp@PTR;check="$$(dig +tcp +noall +answer +search 133.124.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.124.133_tcp@PTR;sleep 1; done
   @ 04/17/23 08:16:24.09
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2471.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2471.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2471.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2471.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2471.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2471.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2471.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2471.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2471.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2471.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2471.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2471.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 133.124.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.124.133_udp@PTR;check="$$(dig +tcp +noall +answer +search 133.124.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.124.133_tcp@PTR;sleep 1; done
   @ 04/17/23 08:16:24.09
  STEP: creating a pod to probe DNS @ 04/17/23 08:16:24.09
  STEP: submitting the pod to kubernetes @ 04/17/23 08:16:24.09
  E0417 08:16:24.634109      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:25.634371      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/17/23 08:16:26.096
  STEP: looking for the results for each expected name from probers @ 04/17/23 08:16:26.098
  Apr 17 08:16:26.114: INFO: DNS probes using dns-2471/dns-test-b406f9da-2080-4144-8843-9f4bdeb384ba succeeded

  Apr 17 08:16:26.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 08:16:26.116
  STEP: deleting the test service @ 04/17/23 08:16:26.119
  STEP: deleting the test headless service @ 04/17/23 08:16:26.124
  STEP: Destroying namespace "dns-2471" for this suite. @ 04/17/23 08:16:26.126
â€¢ [2.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 04/17/23 08:16:26.128
  Apr 17 08:16:26.128: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-probe @ 04/17/23 08:16:26.129
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:16:26.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:16:26.133
  STEP: Creating pod busybox-19fbd3ab-e04e-4977-bdde-e08640f77591 in namespace container-probe-3256 @ 04/17/23 08:16:26.134
  E0417 08:16:26.634451      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:27.634718      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:16:28.140: INFO: Started pod busybox-19fbd3ab-e04e-4977-bdde-e08640f77591 in namespace container-probe-3256
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/17/23 08:16:28.14
  Apr 17 08:16:28.141: INFO: Initial restart count of pod busybox-19fbd3ab-e04e-4977-bdde-e08640f77591 is 0
  E0417 08:16:28.634883      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:29.635058      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:30.635982      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:31.636364      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:32.637001      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:33.637142      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:34.638025      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:35.638251      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:36.638858      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:37.638997      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:38.639571      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:39.639702      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:40.640443      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:41.640825      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:42.641743      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:43.641911      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:44.642206      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:45.642376      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:46.642675      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:47.643343      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:48.643746      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:49.643966      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:50.644418      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:51.644809      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:52.645127      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:53.645319      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:54.646109      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:55.646256      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:56.646277      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:57.646422      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:58.647441      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:16:59.647704      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:00.648378      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:01.648804      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:02.649334      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:03.649478      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:04.649601      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:05.649775      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:06.649782      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:07.649979      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:08.651008      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:09.651160      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:10.651393      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:11.651740      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:12.652683      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:13.652826      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:14.653791      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:15.653979      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:16.653940      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:17.654131      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:17:18.194: INFO: Restart count of pod container-probe-3256/busybox-19fbd3ab-e04e-4977-bdde-e08640f77591 is now 1 (50.052987794s elapsed)
  Apr 17 08:17:18.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/17/23 08:17:18.195
  STEP: Destroying namespace "container-probe-3256" for this suite. @ 04/17/23 08:17:18.198
â€¢ [52.071 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 04/17/23 08:17:18.2
  Apr 17 08:17:18.200: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 08:17:18.2
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:17:18.204
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:17:18.205
  STEP: Creating secret with name s-test-opt-del-68cb0306-755f-4792-8f30-55c05dcf98f6 @ 04/17/23 08:17:18.207
  STEP: Creating secret with name s-test-opt-upd-fb024759-e0db-4241-96e6-ab35bbf6e5d6 @ 04/17/23 08:17:18.208
  STEP: Creating the pod @ 04/17/23 08:17:18.209
  E0417 08:17:18.654507      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:19.654726      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-68cb0306-755f-4792-8f30-55c05dcf98f6 @ 04/17/23 08:17:20.23
  STEP: Updating secret s-test-opt-upd-fb024759-e0db-4241-96e6-ab35bbf6e5d6 @ 04/17/23 08:17:20.231
  STEP: Creating secret with name s-test-opt-create-acf71e15-9434-40b7-8298-72967ae0ac83 @ 04/17/23 08:17:20.232
  STEP: waiting to observe update in volume @ 04/17/23 08:17:20.234
  E0417 08:17:20.655758      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:21.656159      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:22.657060      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:23.657234      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:24.657970      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:25.658127      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:26.659081      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:27.659234      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:28.660075      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:29.660274      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:30.660796      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:31.661100      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:32.662063      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:33.662225      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:34.662586      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:35.662796      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:36.663091      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:37.663334      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:38.664044      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:39.664223      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:40.664347      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:41.664674      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:42.664819      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:43.664995      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:44.665188      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:45.665298      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:46.666204      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:47.666400      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:48.666452      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:49.666627      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:50.667021      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:51.667506      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:52.667639      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:53.667956      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:54.668096      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:55.668239      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:56.668781      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:57.668947      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:58.669778      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:17:59.669940      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:00.670851      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:01.671221      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:02.672046      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:03.672211      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:04.672731      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:05.672972      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:06.673565      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:07.673787      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:08.674544      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:09.674640      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:10.674862      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:11.675208      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:12.675720      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:13.675926      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:14.676541      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:15.676701      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:16.677199      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:17.677369      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:18.677959      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:19.678132      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:20.678204      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:21.678526      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:18:22.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2059" for this suite. @ 04/17/23 08:18:22.358
â€¢ [64.160 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 04/17/23 08:18:22.36
  Apr 17 08:18:22.360: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename projected @ 04/17/23 08:18:22.36
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:18:22.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:18:22.365
  STEP: Creating projection with secret that has name projected-secret-test-map-0673463d-de05-45b1-963e-796b4b37cbb7 @ 04/17/23 08:18:22.367
  STEP: Creating a pod to test consume secrets @ 04/17/23 08:18:22.368
  E0417 08:18:22.678774      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:23.678964      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:24.679592      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:25.679759      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/17/23 08:18:26.378
  Apr 17 08:18:26.379: INFO: Trying to get logs from node c3-worker pod pod-projected-secrets-8af04bd6-39e4-4864-b024-9e1979547b81 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/17/23 08:18:26.387
  Apr 17 08:18:26.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4012" for this suite. @ 04/17/23 08:18:26.393
â€¢ [4.035 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:571
  STEP: Creating a kubernetes client @ 04/17/23 08:18:26.395
  Apr 17 08:18:26.395: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename webhook @ 04/17/23 08:18:26.396
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:18:26.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:18:26.4
  STEP: Setting up server cert @ 04/17/23 08:18:26.406
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/17/23 08:18:26.626
  STEP: Deploying the webhook pod @ 04/17/23 08:18:26.629
  STEP: Wait for the deployment to be ready @ 04/17/23 08:18:26.632
  Apr 17 08:18:26.634: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0417 08:18:26.680096      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:27.680515      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/17/23 08:18:28.638
  STEP: Verifying the service has paired with the endpoint @ 04/17/23 08:18:28.641
  E0417 08:18:28.681551      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:18:29.641: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/17/23 08:18:29.659
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/17/23 08:18:29.677
  E0417 08:18:29.682567      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting the collection of validation webhooks @ 04/17/23 08:18:29.692
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/17/23 08:18:29.703
  Apr 17 08:18:29.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2743" for this suite. @ 04/17/23 08:18:29.717
  STEP: Destroying namespace "webhook-markers-5068" for this suite. @ 04/17/23 08:18:29.719
â€¢ [3.325 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
test/e2e/apps/job.go:370
  STEP: Creating a kubernetes client @ 04/17/23 08:18:29.721
  Apr 17 08:18:29.721: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename job @ 04/17/23 08:18:29.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:18:29.724
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:18:29.726
  STEP: Creating Indexed job @ 04/17/23 08:18:29.727
  STEP: Ensuring job reaches completions @ 04/17/23 08:18:29.729
  E0417 08:18:30.683253      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:31.683615      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:32.684155      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:33.684312      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:34.684843      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:35.685025      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:36.685770      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:37.685989      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 04/17/23 08:18:37.731
  Apr 17 08:18:37.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7175" for this suite. @ 04/17/23 08:18:37.734
â€¢ [8.015 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:104
  STEP: Creating a kubernetes client @ 04/17/23 08:18:37.737
  Apr 17 08:18:37.737: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename runtimeclass @ 04/17/23 08:18:37.737
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:18:37.742
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:18:37.743
  E0417 08:18:38.686416      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:39.686720      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:18:39.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-6326" for this suite. @ 04/17/23 08:18:39.754
â€¢ [2.019 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:84
  STEP: Creating a kubernetes client @ 04/17/23 08:18:39.756
  Apr 17 08:18:39.756: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename pod-network-test @ 04/17/23 08:18:39.756
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:18:39.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:18:39.761
  STEP: Performing setup for networking test in namespace pod-network-test-5373 @ 04/17/23 08:18:39.762
  STEP: creating a selector @ 04/17/23 08:18:39.762
  STEP: Creating the service pods in kubernetes @ 04/17/23 08:18:39.762
  Apr 17 08:18:39.762: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0417 08:18:40.686948      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:41.687480      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:42.688243      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:43.688913      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:44.689617      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:45.689965      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:46.690807      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:47.690983      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:48.691481      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:49.691628      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:50.692227      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:51.692560      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/17/23 08:18:51.785
  E0417 08:18:52.693439      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:53.693679      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:18:53.791: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Apr 17 08:18:53.791: INFO: Breadth first check of 10.244.1.201 on host 172.18.0.3...
  Apr 17 08:18:53.792: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.202:9080/dial?request=hostname&protocol=http&host=10.244.1.201&port=8083&tries=1'] Namespace:pod-network-test-5373 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 08:18:53.792: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 08:18:53.792: INFO: ExecWithOptions: Clientset creation
  Apr 17 08:18:53.792: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5373/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.202%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.1.201%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 17 08:18:53.852: INFO: Waiting for responses: map[]
  Apr 17 08:18:53.852: INFO: reached 10.244.1.201 after 0/1 tries
  Apr 17 08:18:53.852: INFO: Breadth first check of 10.244.2.81 on host 172.18.0.4...
  Apr 17 08:18:53.853: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.202:9080/dial?request=hostname&protocol=http&host=10.244.2.81&port=8083&tries=1'] Namespace:pod-network-test-5373 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 17 08:18:53.853: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  Apr 17 08:18:53.853: INFO: ExecWithOptions: Clientset creation
  Apr 17 08:18:53.853: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-5373/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.1.202%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.2.81%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 17 08:18:53.896: INFO: Waiting for responses: map[]
  Apr 17 08:18:53.896: INFO: reached 10.244.2.81 after 0/1 tries
  Apr 17 08:18:53.896: INFO: Going to retry 0 out of 2 pods....
  Apr 17 08:18:53.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-5373" for this suite. @ 04/17/23 08:18:53.898
â€¢ [14.144 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 04/17/23 08:18:53.9
  Apr 17 08:18:53.900: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename watch @ 04/17/23 08:18:53.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:18:53.904
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:18:53.905
  STEP: getting a starting resourceVersion @ 04/17/23 08:18:53.906
  STEP: starting a background goroutine to produce watch events @ 04/17/23 08:18:53.907
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 04/17/23 08:18:53.907
  E0417 08:18:54.693873      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:55.694315      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:56.695209      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:18:56.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7936" for this suite. @ 04/17/23 08:18:56.753
â€¢ [2.903 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 04/17/23 08:18:56.803
  Apr 17 08:18:56.803: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename container-probe @ 04/17/23 08:18:56.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:18:56.807
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:18:56.808
  E0417 08:18:57.695912      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:58.696341      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:18:59.696644      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:00.697391      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:01.698085      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:02.698421      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:03.698867      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:04.699377      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:05.699983      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:06.700661      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:07.701232      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:08.701521      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:09.701832      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:10.702131      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:11.702565      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:12.703080      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:13.703572      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:14.703968      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:15.704071      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:16.704435      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:17.704868      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:18.705346      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:19.706023      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:20.706461      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:21.707020      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:22.707654      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:23.708035      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:24.708677      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:25.709312      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:26.709688      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:27.710090      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:28.710689      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:29.711020      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:30.711486      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:31.711972      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:32.712615      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:33.713424      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:34.714101      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:35.714592      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:36.714931      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:37.715213      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:38.715662      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:39.716068      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:40.716535      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:41.717027      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:42.717828      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:43.718902      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:44.719501      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:45.719976      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:46.720470      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:47.720872      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:48.721261      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:49.721804      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:50.722361      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:51.722983      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:52.722971      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:53.723523      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:54.724237      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:55.725078      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:56.725447      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:19:56.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2327" for this suite. @ 04/17/23 08:19:56.819
â€¢ [60.022 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 04/17/23 08:19:56.826
  Apr 17 08:19:56.826: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename var-expansion @ 04/17/23 08:19:56.826
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:19:56.831
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:19:56.832
  E0417 08:19:57.725604      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:19:58.725947      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 17 08:19:58.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 17 08:19:58.841: INFO: Deleting pod "var-expansion-7f9141bb-b7f4-4ed7-b2eb-2d2b3ffe0659" in namespace "var-expansion-6372"
  Apr 17 08:19:58.843: INFO: Wait up to 5m0s for pod "var-expansion-7f9141bb-b7f4-4ed7-b2eb-2d2b3ffe0659" to be fully deleted
  E0417 08:19:59.726555      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:20:00.726747      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-6372" for this suite. @ 04/17/23 08:20:00.846
â€¢ [4.022 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance]
test/e2e/auth/service_accounts.go:275
  STEP: Creating a kubernetes client @ 04/17/23 08:20:00.848
  Apr 17 08:20:00.848: INFO: >>> kubeConfig: /tmp/kubeconfig-1944430999
  STEP: Building a namespace api object, basename svcaccounts @ 04/17/23 08:20:00.849
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/17/23 08:20:00.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/17/23 08:20:00.853
  STEP: Creating a pod to test service account token:  @ 04/17/23 08:20:00.855
  E0417 08:20:01.727322      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:20:02.727618      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:20:03.727708      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0417 08:20:04.727869      30 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/17/23 08:20:04.862
  Apr 17 08:20:04.863: INFO: Trying to get logs from node c3-worker pod test-pod-d53c859c-e9ed-4590-b689-5210d5fc9233 container agnhost-container: <nil>
  STEP: delete the pod @ 04/17/23 08:20:04.871
  Apr 17 08:20:04.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4322" for this suite. @ 04/17/23 08:20:04.876
â€¢ [4.030 seconds]
------------------------------
SSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Apr 17 08:20:04.879: INFO: Running AfterSuite actions on node 1
  Apr 17 08:20:04.879: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:152
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:593
[ReportAfterSuite] PASSED [0.033 seconds]
------------------------------

Summarizing 1 Failure:
  [FAIL] [sig-auth] ServiceAccounts [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:635

Ran 378 of 7207 Specs in 6413.956 seconds
FAIL! -- 377 Passed | 1 Failed | 0 Pending | 6829 Skipped
--- FAIL: TestE2E (6414.11s)
FAIL

Ginkgo ran 1 suite in 1h46m54.160631169s

Test Suite Failed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.9.1[0m

